# 人工智能中的文化偏见

> 原文：<https://thenewstack.io/cultural-bias-in-artificial-intelligence/>

[文化偏见在艾与卡米尔德](https://thenewstack.simplecast.com/episodes/culture-bias-in-ai-with-camille-eddy)

广告和白皮书可能会让人工智能看起来像是天上掉馅饼的命题，轻松的分析，深刻的见解，以及随处可见的公平算法。然而，现实是，人工智能可以暴露我们人类更黑暗的一面，更像一面镜子，而不是天上的馅饼。当[微软](http://www.microsoft.com)在[推特](https://www.twitter.com)上发布一个人工智能驱动的机器人时，我们看到了这一点，不料[不久之后它就发表了种族主义言论](https://thenewstack.io/requiem-tay-reactions-microsofts-teenaged-ai-gone-bad/)。

Camille Eddy 目前是博伊西州立大学机械工程学士学位的学生，已经在 Alphabet 和惠普等公司实习了很长时间。事实上，当她不在巡回演讲时，她目前在 Nvidia 实习。在 [OSCON](https://conferences.oreilly.com/oscon/oscon-or/public/schedule/speaker/313944) ，她做了关于认识人工智能中的文化偏见的演讲。

“我们看到的一些事情是错误分类或错误识别。例如，微软在 Twitter 上发布的机器人 Tay AI 很容易受到人们以种族主义和性别歧视的方式对它说话的影响，这反映了这一点。人们会说‘这是一个想法，你应该持有这个想法’，事实也的确如此。谈论它如何反映我们作为一个社会的偏见，以及这可能不是我们想要的东西，”埃迪说。

Eddy 对这个问题有长远的看法，希望这是一个长期的问题，只要有人工智能需要训练，团队就需要继续解决这个问题。“我不认为我们会成为一个生产永远不会有偏见的技术的社会，因为我们作为人类不像那样。我们总是会有某种类型的偏见。我真的很感兴趣，我们如何才能消除对技术的普遍偏见，并走向更广阔的领域，”埃迪说。

### 在这个版本中:

[0:48:](https://thenewstack.simplecast.com/episodes/culture-bias-in-ai-with-camille-eddy?t=0:48) 给我们讲讲 AI 已经浮出水面的一些问题。
[1:43:](https://thenewstack.simplecast.com/episodes/culture-bias-in-ai-with-camille-eddy?t=1:43) 我们如何为未来考虑这一点？
[5:59:](https://thenewstack.simplecast.com/episodes/culture-bias-in-ai-with-camille-eddy?t=5:59) 谁需要参与进来以确保这不会发生在软件项目中？
[7:02:](https://thenewstack.simplecast.com/episodes/culture-bias-in-ai-with-camille-eddy?t=7:02) 你是怎么对 AI 产生兴趣的？
[13:13:](https://thenewstack.simplecast.com/episodes/culture-bias-in-ai-with-camille-eddy?t=13:13) 这如何适用于新兴领域？
[14:08:](https://thenewstack.simplecast.com/episodes/culture-bias-in-ai-with-camille-eddy?t=14:08) 关于人工智能中的偏见，你在 OSCON 会议上真正想帮助谁沟通？

微软是新堆栈的赞助商。

詹姆斯·庞德在 [Unsplash](https://unsplash.com/search/photos/bias?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText) 上拍摄的特写图片。

<svg xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 0 68 31" version="1.1"><title>Group</title> <desc>Created with Sketch.</desc></svg>