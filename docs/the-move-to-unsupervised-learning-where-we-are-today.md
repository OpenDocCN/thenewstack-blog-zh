# 走向无监督学习:我们今天在哪里

> 原文：<https://thenewstack.io/the-move-to-unsupervised-learning-where-we-are-today/>

深度学习是机器学习的[子领域，它特别关注受人脑结构和功能启发的算法类别。这些算法使用人工神经网络(ann)从大量数据中学习，并将世界表示为分层的概念层次。](https://thenewstack.io/researchers-drop-the-zeroes-to-speed-deep-learning/)

例如，对于图像识别，首先检测亮区和暗区，然后是边缘，然后是形状和外形。人工神经网络在 50 年前就存在了，但在那时，它们只有两层深度，因为当时的处理能力只能处理这两层。现在，我们可以通过向人工神经网络添加越来越多的层来进行更深入的研究，我们可以更好地观察、理解复杂的事件并做出反应。于是，名字中的“深”。

## **常见深度学习应用**

深度学习的最大优势在于它能够从海量数据中学习复杂模式。在这方面，多层处理元素、利用大计算能力的更好能力和更好的训练程序共同赋予了深度学习算法。目前，深度学习最常见的一些应用是在图像和语音识别中。最有前景的应用包括自动驾驶汽车、虚拟助理、语音识别、药物发现、在线零售中的个性化推荐和图像处理。

几十年来，模仿和改善人类行为的技术一直是书籍和电影的主题。对于大多数公司来说，实现这样的解决方案是一个长期的追求，但深度学习的进步正在使许多企业开始实现这些愿望。

深度学习正在以各种方式显示其存在，从简单的日常任务，如对一个人的照片进行分类，到“登月”愿望，如安全的自动驾驶汽车和自动化的高精度手术。这里只是一些可以利用深度学习创新的商业部门的例子:

*   **医疗保健:**医疗保健行业拥有深度学习的巨大潜力。从药物发现到疾病预测和医疗诊断，各个领域都在取得进展。

*   **网络安全:**从历史上看，网络安全侧重于检测过去发生的攻击。技术的进步使得实时监控和攻击检测成为可能。在此基础上，深度学习可以利用数据并添加上下文和智能来检测以前从未见过的攻击，甚至预测下一次攻击可能在何时何地发生。

*   **制造:**制造商使用机器学习来简化生产的每个阶段，从采购到制造调度再到订单履行。深度学习应用将进一步增强制造商的能力，如设备的预测性维护，“体验中心”以模拟设计变化的影响，以及支持远程故障排除的虚拟环境。

*   **汽车:**汽车行业正经历着从传统汽车制造到先进技术应用，从核心设计到信息娱乐系统的转变。深度学习正在进一步推动驾驶辅助、事故预防和自动驾驶汽车和卡车的发展。

*   **零售业:**零售业可以访问与顾客行为和偏好相关的海量数据。深度学习为提供个性化体验、理解需求以及让产品和服务脱颖而出提供了巨大的可能性。

尽管有这些充满希望的机会，深度学习在行业中的采用仍然面临着几个挑战，主要挑战是缺乏“可解释性”(下文将详细介绍)以及需要标记的训练数据。

## **通过使深度学习变得可解释来增加深度学习的采用**

随着公司寻求将更高级别的深度学习嵌入到他们的数据管理系统中，让深度学习解决方案“可解释”是很重要的，这意味着该解决方案应该能够向业务用户解释为什么它预测了它所预测的东西。这种解释需要以易于理解和透明的方式传达，以获得用户的安慰和信心。

可解释性不仅建立了在生产中使用这些解决方案的团队的信任，而且还导致了对开发采用更负责任的方法。它帮助开发人员确保系统按预期运行，确认现有知识，并在必要时质疑它。

由于能够创建复杂的模型、处理高维空间和更好地捕捉特征交互，深度学习算法通常可以提供更高的操作准确性。然而，这种解决方案的缺点是缺乏可解释性，因为这些算法越来越复杂，很难推断算法是如何达到某个结果的。

事实上，这些解决方案往往变得非常复杂，甚至连创建它们的数据科学家都无法推断出算法是如何推导出特定结果的！这种缺乏可解释性会导致诸如虚假相关性、意外行为和潜在偏见或不公平等问题。

更广泛的人工智能解决方案可以大致分为“白盒”和“黑盒”模型。

白盒解决方案对于如何得出某个结论是透明的，用户能够查看和理解哪些因素影响了算法的决策以及算法的行为。决策树和线性回归是白盒算法的一些例子。这种算法通常不能导出复杂的关系或者处理高维空间，但是在它们的运行中提供了高度的透明性。

另一方面，黑盒算法在让用户知道某个结果是如何达到的方面远没有那么透明。深度神经网络是黑盒算法的一个例子，boosting 算法也是如此，它结合了许多更简单的学习算法，以迭代的方式提高精度。黑盒解决方案通常提供更高的准确性，因为它们能够更好地捕捉高维空间中复杂的特征交互，但这是以可解释性为代价的。

例如，考虑为一家电信公司预测客户流失的问题。创建一个模型来执行这种预测需要考虑许多特征，如客户年龄、性别、地理位置、使用模式、使用的计划等等。黑盒算法执行这种预测，而不透露它如何得出某个结论的细节。

这种算法的风险在于没有利用领域专家的帮助来防止任何不正确的推断，而白盒算法将提供一组特定的规则或条件，用于推断特定客户是留下还是离开。

事后可解释性提供了一条中间道路。白盒和黑盒解决方案在现实场景中都有它们的位置，但是有机会平衡和融合这两者，并且在这里白盒和黑盒解决方案之间有希望的中间道路以事后可解释方法的形式提供。

这些方法分析机器学习模型的响应，以解释模型背后的推理逻辑。这种方法的一个例子是局部可解释模型不可知解释(LIME ),它分析黑盒模型的输入和输出，并使用这些数据来构建更简单的模型，为为什么做出单个预测提供详细的解释。

另一种有前途的事后可解释性技术是沙普利附加解释(SHAP)，它分析每个特征对预测值推导的贡献大小的重要性，从而有助于提供对黑盒算法输出的解释。继续客户流失预测示例，部署 SHAP 将有助于推断哪些属性(例如，客户使用模式、每月账单或竞争)在预测客户流失方面发挥了重要作用。

在可解释性和准确性之间找到适当的平衡是很重要的。用户需要了解黑盒解决方案相对于白盒解决方案在精度上提高了多少，然后决定哪个选项最适合使用。

一个常见的行业实践是尽可能从白盒解决方案开始，然后只有当它提出一个令人信服的案例，要求关注准确性而不是可解释性时，才发展到黑盒解决方案。当使用黑盒解决方案时，应用如上所述的可解释性技术可以为建模带来更大的透明度，在过程中与涉众建立信任。

## **通过自我监督学习使深度学习可持续**

除了对可解释性的需求，深度学习广泛采用的另一个重大挑战是越来越依赖于对标记数据的需求，即在文本文件和图像等原始数据中添加标签，以识别它们，并提供机器学习模型可以识别和学习的上下文。近年来，监督学习取得了重大而令人印象深刻的进展，证明了从大量标记数据中学习的能力。

然而，单独使用监督学习，人工智能能够推进的程度是有限的。在许多现实场景中，大量标记数据的可用性是一个挑战，这要么是由于缺乏资源，要么是由于问题本身的固有性质。确保标记数据中的类平衡是另一个挑战，因为经常会出现这样的情况，一些类占了数据的很大一部分，而其他类可能没有得到充分的表示。

此外，确保标记数据的可信度可能是另一个挑战。如果我们分析我们作为人类是如何学习的，这并不完全基于我们过去收到的训练数据。多年来，我们发展了关于世界上各种概念的通用模型，好像是通过潜移默化，从经验中，形成我们所知的常识。这种常识有助于我们学习新概念，并在没有大量训练数据的情况下将这些概念放在上下文中。

多年来，开发类似这种常识的东西一直困扰着人工智能系统。也就是说，自我监督学习(SSL)在这一领域有着很好的发展，它试图开发这样的背景知识。

自我监督学习是一种范式，其中深度学习算法被输入未标记的数据作为输入，并自动生成数据标签，然后在后续迭代中使用。

这种无监督学习使用未标记的数据集，并致力于聚类和分组，而监督学习使用具有显式提供的标记数据集的数据集，并致力于更具结论性的任务，如分类和回归。自监督学习将未标记的数据作为输入，但在内部生成标签并在后续迭代中使用这些标签来学习，并朝着分类和回归等任务努力。因此，通过自动生成标签，将无监督的问题转化为有监督的行为。

自我监督的解决方案基于基于能量的模型(EBM)的概念。EBM 是一个可训练的系统，其中两个输入的兼容性，让我们称之为“x”和“y”，以能量的形式来测量。如果能量低，那么“x”和“y”被认为是兼容的。让我们考虑一个完成不完整句子的常见自然语言处理(NLP)问题。现在，为了解决这个问题，SSL 引擎将被提供大量未标记的文本数据集。

SSL 引擎将使用数据本身的结构进行训练，而不依赖于任何外部标签。然后，引擎可以计算单词之间的能量，以预测最适合句子中缺失或隐藏单词的单词。SSL 引擎为可能的输出计算预测分数，当不确定结果时给出低分数。类似的概念可被应用于训练音频和视频数据集，其中 SSL 引擎可在大量音频或视频数据集上被训练，以从输入的听觉/视觉部分预测输入的隐藏部分。

自监督学习在 NLP 和视觉领域取得了重大成功，用于从输入的任何未隐藏部分中识别输入的任何隐藏部分，例如，预测句子中缺失的单词，预测视频的过去或未来帧，或者预测图像的缺失部分。一些常见的应用是在医学图像分析、签名检测、图像彩色化和视频运动预测领域。

## **结论**

深度学习技术正在快速发展，让行业更好地了解他们今天的世界，并开启了影响未来方向的新的、令人兴奋的技术可能性。可解释性和自我监督学习的进步为基于特定用例应用的智能学习工具提供了更大的灵活性和选择。这些技术有望让基于深度学习的解决方案更接近类似人类的自主和情境化学习，释放人力资本，专注于其他运营领域的发展。

<svg xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 0 68 31" version="1.1"><title>Group</title> <desc>Created with Sketch.</desc></svg>