# 运营数据湖以提高业务绩效

> 原文：<https://thenewstack.io/operationalizing-data-lakes-better-business-performance/>

同样的故事不断出现在制造商、金融服务公司、医疗保健提供商和零售商身上:一个团体说他们的数据湖项目非常成功，因为他们创建了一个几乎所有企业数据的负担得起的中央存储库。但是另一组人声称他们还没有在他们的报告、仪表板和应用程序中利用这个新的存储库。这怎么可能？我们解释为什么会发生这种情况，以及如何修复它。

## 数据湖的早期用户期望什么？

 [蒙特兹韦本

蒙特·兹韦本是拼接机器公司的首席执行官。作为一名技术行业的资深人士，蒙特的早期职业生涯是在美国宇航局艾姆斯研究中心(NASA Ames Research Center)人工智能分部担任副主任。蒙特随后创建了红辣椒软件公司，并担任首席执行官，该公司于 1996 年与 PeopleSoft 合并。蒙特也是 Blue Martini Software 的创始人兼首席执行官，Blue Martini Software 是零售商电子商务和多渠道系统的领导者，是 2000 年最成功的 IPO 之一。继 Blue Martini 之后，他担任了一家基于位置的数字媒体公司 SeeSaw Networks 的董事长。他是 Rocket Fuel Inc .的董事长，并在卡内基梅隆大学计算机科学学院的院长顾问委员会任职。](https://www.splicemachine.com/) 

数据湖的引入是为了解决将重要数据锁在生产应用程序和部门数据库中的问题。当时的设想是，将所有这些数据加载到一个存储库中，将能够揭示有关公司运营的重要信息。Hadoop 使得在经济实惠的硬件上存储大量数据成为可能，这一事实放大了这一趋势。

回顾第一代数据湖，我们现在知道企业数据湖的生产者和消费者之间存在真正的脱节。制片人发现了一种非常经济高效的方式来捕获和集中所有结构化和非结构化企业数据。“读取模式”方法意味着所有数据都可以转储到廉价的存储设备上，以后再处理。不需要争论就可以获得干净的数据或正确的数据类型或格式。这项艰苦的工作被延迟到数据被消费掉——因此有了“读取时模式”这个术语随着企业竞相捕捉不断增长的数据量，这似乎是革命性的。

但当时数据消费者的心态完全不同。他们认为这个新的大数据堆栈将为他们提供比以前更多的东西；这将使传统的数据仓库和分析应用程序性能更好，可伸缩性更强。但这从未实现。如果不对数据湖进行更多的编程，像 Tableau、MicroStrategy 和 Business Objects 这样的 BI 工具就无法运行。他们数以千计的报告和仪表板不仅没有更好的可扩展性和性能，而且根本无法运行。此外，提取、转换和加载(ETL)工具，如 Informatica 和 Talend，如果不购买新模块、更改管道和实际编写代码，供消费的结构化数据就无法运行。此外，所有从未捕获的新数据(设备数据、移动数据和来自企业外部的外部数据)如果没有大量的“读取时架构”工作，包括争论、清理、过滤和转换，就无法投入使用。

## 期望差距

期望失败的主要原因深深植根于读取模式的原则。大数据堆栈的第一批用户是开发人员，他们非常灵活地获取任何形式、质量和数量的数据，并编写代码，在准备好进行分析时将数据处理成所需的形式。他们是人工智能和机器学习开发人员，在分布式计算和机器学习方面受过深入培训。从根本上说，他们是程序员。他们建立了优化媒体布局的广告技术系统，保护消费者和企业的欺诈检测系统，保护国家的国防和情报系统，他们是建造自动驾驶汽车的机器人专家。他们从零开始做这件事。这些开发人员是高需求的训练有素的计算机科学家，因此是昂贵和稀缺的资源。

但是数据的企业消费者需要他们在分析应用程序中一直依赖的功能。可以说他们不是编码员。他们需要一直依赖的相同的 SQL 关系数据库和数据仓库。这些久经考验的平台功能强大，几乎支持企业的所有运营系统、分析报告和仪表盘。此外，已经有大批高技能的 IT 专业人员可以设计、开发和操作这些平台。期望差距是基于 Hadoop 的数据湖应该提供更快、更具可伸缩性的数据库和数据仓库，而它确实提供了一组带有 API 的编程库，使您能够在更低的抽象级别编码数据的原始操作。

## 运营数据湖的要求

一个主要的误解是，你可以像对待数据库一样对待 Hadoop 上的数据湖。在数据湖中，数据是存在的，但是数据没有被清理、索引或操作化。当一家公司的数据从几个进入 Hadoop 的源扩展到数百个时，这变得非常明显。运营数据湖需要将传统 SQL RDBMS 和传统数据仓库的功能结合起来。

*   *接收*:他们需要能够接收数 Pb 的历史数据，并实时接收来自物联网和外部来源的数百万个数据点。
*   *SQL* :他们需要支持传统的 ETL 管道、BI 报告和仪表盘，而无需进行大量的重新编程。如果你必须有一个长达一年的项目来使一个旧的报告再次有用，那么说你集成了 BI 是不够的。
*   *表* *对文件*:分析师和 DBA 熟悉表和 SQL。他们对编程语言、开发环境、编译器和文件操作不太熟悉。
*   *分析:*运营数据库需要在许多充满聚合和分组的表之间执行复杂的数据连接，以支持企业分析工作负载。
*   *并发:*现实世界中没有一个数据科学家在沙盒中处理数据集，独立于其他任何人进行操作。实时操作数据湖有许多数据生产者和许多并发消费者。要使数据湖投入运行，需要为许多用户提供支持的数据库功能。
*   *备份和恢复:*系统错误和人为错误都是不可避免的。服务器停机，整个数据中心丢失，操作员偶尔也会出错。因此，运行中的数据湖需要增量备份和恢复，以便能够在发生意外事件时将数据湖恢复到以前的一致状态。传统数据湖中临时更改文件的平面文件系统使这变得困难。数据库备份和恢复功能以及最佳实践支持操作手册。
*   *更新*:争论数据很难，驱动应用程序也很难。分析师需要更改数据以使其到位，而不是每次需要修改一两条记录时都生成新的文件集来管理。此外，应用程序开发人员需要就地更改记录以支持应用程序。出现了错误，需要更新数据。最被低估的更新需求之一是分析的物化集合。维护运营数据存储通常需要按地理、部门或其他维度具体化数据摘要。数据湖需要能够实时地频繁更新这些摘要。数据库和数据仓库支持数据库中数据的一致更改，具有锁定权限、加密和压缩数据的安全特性，最重要的是，如果进程、管道或应用程序中出现异常，将数据回滚到以前的一致状态。

## 运营化数据湖的业务优势

运营数据湖最终兑现了大数据的承诺。它们使全新的来源能够应用于操作和分析应用。由于 Hadoop 堆栈的分布式存储，运营数据湖是可扩展的，并且通过利用大数据堆栈的分布式计算能力，有望加快计算速度。但是他们用 RDBMS 和数据仓库的稳定功能做到了这一点。

运营数据湖正在彻底改变行业。零售商、制造商和第三方物流/4PL 物流提供商正在从 ERP 系统、销售系统、仓储系统和运输系统中提取数据，以提供实时的全球供应链数据。他们正在用实时外部承运人数据和天气数据丰富这些数据湖，以支持新的实时供应链规划应用程序和可承诺量(ATP)系统。这些系统既能从经验中学习，又能实时规划。

医疗保健提供商正在提取临床 EMR(即电子病历)、患者数据和运营数据，以支持新的预测应用程序，帮助临床医生护理患者并帮助优化医院运营。

金融服务机构正在将客户和顾问数据提取到运营数据湖中，以帮助回答实时问题，例如，谁是我最赚钱的客户，哪些客户可能变得非常有价值，以及谁是我最有效的顾问。

想象一下，如果销售和营销渠道中的每一次点击和移动访问都被实时捕获并可由运营应用程序访问，营销人员最终会做些什么。

最后，拥有大量工程设备网络的公司，如电信公司、网络公司、公用事业公司以及石油和天然气公司，需要避免服务中断。他们的运营数据湖存储来自网络中每个组件的实时数据，并为预测下一次故障事件的预测应用提供动力，以便通过预测性维护主动避免故障。

## 我们如何操作数据湖

Splice Machine 是一个独特的数据平台，专门用于运行数据湖。它是唯一一个无缝集成的 SQL RDBMS 和构建在大数据堆栈上的数据仓库。我们将上述所有需求交付到一个平台中，该平台使用多个引擎来提供这种多样化的功能。我们称之为在线预测处理(OLPP ),因为它将 OLTP(用于接收、更新、并发和备份)与 OLAP(用于分析和机器学习)结合在一起。

Splice Machine 在 Hadoop 和廉价的块存储上存储数据。它通过大海捞针般的查找和 Apache HBase 的摄取速度以及 Apache Spark 的内存分析计算来访问数据。拼接机的用户不必处理部署这些引擎通常必需的低级分布式系统编程。相反，只需向引擎发出 SQL，它就会决定如何最好地处理查询以及使用什么计算引擎。

## 不同成分如何与运营数据湖交互

分析师可以通过标准 BI 工具和标准 JDBC/ODBC 适配器访问拼接机器驱动的操作数据湖。数据工程师可以使用他们的标准争论和 ETL 工具，如 Informatica 和 Talend。应用程序开发人员可以用他们选择的语言编写实时程序，包括 Java、Python、Scala、Ruby、Node.js 和 C++。数据科学家可以使用我们的 Apache Zeppelin 笔记本进行实验，并与 Scala 和 Python 中的 Spark 数据帧的直接进程内访问进行协作。他们还可以针对 SQL 数据存储用 R 和 SAS 编写直接函数。

无论用户访问数据平台的途径通常是什么，支持它都是至关重要的。

## 公司如何部署运营数据湖

如今，一些公司有严格的隐私和安全要求，并将其数据湖部署在本地 Hadoop 集群上。或者他们可以通过公共云上的数据库即服务来部署它。无论是何种平台，运营数据湖都能为金融服务、石油和天然气、医疗保健提供商和制造商等不同行业的公司提供 Apache HBase 大海捞针般的速度，以及 Apache Spark 的内存分布式分析能力。运营数据湖实现了数据湖的承诺，并提供了用户需要的实时性能。

通过 Pixabay 的特征图像。

<svg xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 0 68 31" version="1.1"><title>Group</title> <desc>Created with Sketch.</desc></svg>