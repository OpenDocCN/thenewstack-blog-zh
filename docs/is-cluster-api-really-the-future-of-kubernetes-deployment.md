# 集群 API 真的是 Kubernetes 部署的未来吗？

> 原文：<https://thenewstack.io/is-cluster-api-really-the-future-of-kubernetes-deployment/>

在 Sidero 实验室，我们喜欢[集群 API](https://github.com/kubernetes-sigs/cluster-api) (CAPI)。我们围绕它建立了一大堆东西。我说的是[多个](https://github.com/siderolabs/sidero)CAPI供应商。更不用说每天用 CAPI 测试几次 Talos Linux 了。我们是粉丝。但在这篇文章中，我们将谈论我们认为一些问题存在的地方，以及为什么我们选择了**而不是**来使用 CAPI 用于 [Omni](https://www.siderolabs.com/platform/saas-for-kubernetes/) ，我们的新 [SaaS 用于 Kubernetes](https://www.siderolabs.com/platform/saas-for-kubernetes/) 在裸机和 edge 上的部署。

一、集群 API 是什么**？根据文档，“集群 API 是 Kubernetes 的一个子项目，主要提供声明性 API 和工具来简化多个 Kubernetes 集群的供应、升级和操作。”这实质上意味着 Cluster API 为人们提供了一种创建和管理 Kubernetes 集群的方法，这种方法类似于他们在 Kubernetes 中管理应用程序工作负载时使用的方法。这给那些已经是 Kubernetes 专业人士的人提供了一个非常好的体验，让他们可以用自己喜欢的方式管理事情。**

所有的[云提供商](https://github.com/orgs/kubernetes-sigs/repositories?q=cluster-api-provider&type=all&language=&sort=)、 [VMware](https://tanzu.vmware.com?utm_content=inline-mention) 都有集群 API 提供商，对于裸机来说——[Sidero Metal](https://sidero.dev/)是我们自己的 CAPI 裸机提供商，负责服务器的全面管理(在需要时打开/关闭服务器，将服务器添加到集群，移除和擦除机器等)。根据 CAPI 的文件，这“使得跨各种基础设施环境的一致和可重复的集群部署成为可能”

听起来很蠢，那有什么问题？

### CAPI 的问题

我们很幸运在 Sidero 实验室拥有一群热情的用户。我们有相当多的企业在大规模运行 Talos Linux，他们的集群中有成千上万的内核。我们也有许多中小型企业运行几个只有几个节点的小集群，也有许多用户运行家庭实验室。这些不同的用例导致了人们对类似 CAPI 的东西的偏好的双峰分布。运行数百个裸机集群作为内部服务的团队，就像 CAPI 提供的电源一样。较小的团队没有得到大肆宣传。以下是几个原因。

*   CAPI 需要一个专用的“管理平台”。这意味着您需要一个 Kubernetes 集群来管理您的 Kubernetes 集群。对于硬件有限，并且只想运行一两个集群的人来说，为此目的专门使用另一个集群和节点是浪费和昂贵的。
*   真是**难**。在很多方面，人们必须深刻理解特定提供者提供的集群 API **和**的原语。这些原语根据所选的提供商而有所不同，这可能会导致普通用户在试图理解他们的管理平面和供应系统时感到困惑。这对完全不熟悉 Kubernetes 的团队来说是双重困惑。试图了解豆荚，部署等。不带来额外的精神负担就已经够难了。
*   CAPI 做了一些不太适合裸机或边缘部署的假设。在 CAPI 世界中，升级过程是“用较新的配置建立一个新节点，然后拆除旧节点”。这对于单节点集群的边缘用例根本不起作用，对于在一个节点被拆除的情况下需要复制大量数据的集群节点也不起作用(想象一下在本地连接的磁盘中有大量 Ceph 存储的裸机节点)。如果您没有备用服务器来进行滚动升级，它也不起作用——让每类昂贵的服务器闲置，以及管理平面服务器，会带来沉重的负担(如果您在云提供商中运行您的集群，这不是问题)。
*   故障排除很困难。由于集群 API 的模块化，很难找出哪里出了问题。集群创建的许多流程编排都归结于各种资源的状态，以及这些资源是否已完成配置，以便下一个*提供商有足够的信息来提供其资源。与上述观点相关，您必须深入了解 CAPI 本身与基础架构/引导/控制平面提供商之间的集成，甚至知道在哪里查找故障日志。*

所有这些导致我们建议普通用户不要使用 CAPI，尽管事实上我们开发了一个 CAPI 提供商，除非他们部署了许多包含数百台服务器的集群。

### 输入 Omni

我们大约在九个月前开始建造 Omni。Omni 的目标是为创建 Kubernetes 集群和管理它们提供绝对流畅的体验。这包括一系列令人惊叹的功能，如轻松加入节点、处理升级、与企业身份提供商集成的集群用户管理等。可能有人会怀疑，我们就如何构建这个系统以及是否基于集群 API 进行了很多讨论。最终的决定是不，我们不会。上面提到的问题是为什么不这样做的一些原因，以及 CAPI 无法实现的 Omni 的其他一些目标:

*   对于我们的一些用户来说，专用的“管理平面”是不可行的。我们的本地用户需要一种完全无间隙的简单方式来部署、管理和升级集群，我们希望通过 Omni 满足他们的需求。我说的是“运送一个机架到沙漠，并期望它工作”水平的气隙。对于这些用户来说，需要额外的硬件来运行 HA 管理平面集群是对资源的巨大浪费，或者在某些情况下是不可能的，因为他们已经有了一个服务器机架。
*   此外，操作这些设备的人甚至不知道 Kubernetes 是什么。我们需要尽可能简单的架构来启动 Omni，以及它将管理的集群。需要一个 Kubernetes 集群和 CAPI、一堆提供商、Omni 本身，然后试图在这个领域实现引导和故障排除几乎是不可能的。从需求中移除集群 API 允许我们将 Omni 作为一个单一的 Go 二进制文件，这使得管理变得简单明了。(是的，Omni 是一个 SaaS，但你可以轻松地自己运行它。)
*   Omni 通过 [Kubespan](https://www.talos.dev/latest/kubernetes-guides/network/kubespan/) 支持真正的混合 Kubernetes 集群。我们内部用这个，很漂亮。通过在 Azure 中廉价托管我们的控制平面节点，我们每月节省了大约 1500 美元，而我们的工作人员是 Equinix Metal 中功能强大的裸机节点。这一功能非常强大，允许您从任何地方(任何云、VMware、裸机)向群集中添加节点(注意如何标记这些节点并根据它们进行安排)。但是，在 Cluster API 中，没有一个提供程序是以可以在单个集群中混合使用的方式编写的。
*   Omni 的目标之一是让 Kubernetes at the edge 变得简单——使用 Omni 的大部分人正是在用它来做到这一点。使用集群 API 进行边缘部署没有一个好的方法。没有真正的方法允许预启动执行环境(PXE)在边缘启动:这些节点需要遵循“签入”流程。它在 Omni 中的工作方式是从一个公司的 Omni 帐户下载的映像启动节点。这个映像被预先配置为形成一个点对点的 Wireguard 连接，连接到 Omni 帐户。因此，只要一台机器启动，它就会在 Omni 中显示为一台未分配的机器，并允许用户将该机器附加到现有集群或用它创建一个新集群。这并不真正符合集群 API 供应流程，我们觉得我们提出的与集群 API 配合使用的任何东西都有点粗糙，不会提供我们想要的简单性。
*   最后，一些 Talos Linux 功能会受到集群 API 的限制。一个很好的例子就是 Kubernetes 和 Talos Linux 本身的升级。我们为这两者提供了非常好的 API，允许就地升级，并在升级过程中提供良好的就绪检查。在 CAPI 之外进行构建允许我们利用我们已经拥有的这些升级 API，并避免 CAPI 强加的滚动更新限制。

所以所有这些都是说，考虑到我们的设计目标，集群 API 并不适合 Omni。

### 未来

"这对 Sidero Metal 来说意味着什么？"有人可能会问。答案将是一个响亮的**什么都没有！** Sidero 实验室仍将是 CAPI 社区的一部分，我们所有的提供商将继续得到维护和改进。虽然我们认为 CAPI 存在局限性，但正如您从以上几点可以看到的那样，对于特定的使用情形，CAPI 仍然是不错的选择——大规模调配许多群集，而不需要混合群集。对于那些用户，我们将继续推荐他们使用并享受它。

但是对于 Omni 来说，我们将继续构建没有 CAPI 的 Omni，因为它为更多的用户提供了更好的体验。事实上，我们预计 Omni 将很快成为比 CAPI 更好的体验，即使对于那些运行数百个集群和服务器的用户来说也是如此。Omni 使得混合来自任何平台的工人变得简单(不像 CAPI)；是(像 CAPI)声明驱动的；带来了 SaaS 的简单性，并将很快支持裸机 IPMI，所有这些都包装在一个优雅的 UI(和 API)中。这是一个非常棒的平台，将简化几乎所有用户的生活。同时鼓励他们不要太担心操作集群，只管运行他们的工作负载！

如果你想更多地了解 Omni 或 CAPI，欢迎你参加我们 3 月 21 日的免费虚拟用户大会 [TalosCon](https://www.siderolabs.com/taloscon/) 。诺基亚将讨论“使用 CAPI、Talos Linux 和 Sidero Metal 将私有云管理的 Kubernetes 服务扩展到 100k+核心”。我们还将在 edge 上讨论 Omni 和 Kubernetes。

希望在那里见到你！

<svg xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 0 68 31" version="1.1"><title>Group</title> <desc>Created with Sketch.</desc></svg>