# 容器时代的 IT 监控:利用 eBPF 的可观察性

> 原文：<https://thenewstack.io/it-monitoring-in-the-era-of-containers-tapping-into-ebpf-observability/>

[InfluxData](https://www.influxdata.com/) 赞助了这篇文章。

容器对每个人来说都是游戏规则的改变者。作为基础设施和应用层之间的抽象，容器是一个团队活动，涉及 IT 系统工程师、运营、网络运营和开发运营。然而，不同角色的专业人员从不同的角度处理容器监控，所有这些都是有效和重要的，并且是构建完整的监控策略所必需的。

通过将应用程序分离成在集群中运行的容器化微服务，每个容器都打包了必要的资源来执行其部分交易。但是，除非其工作负载、对应部分以及将这些部分组合在一起的网络具有同等的性能，否则这些部分的总和将无法交付满足性能和服务级别目标的应用程序环境。

## 针对容器和网络的新监控指标

 [丹妮尔·庞特斯

丹妮拉·庞特斯是旧金山 InfluxData 公司产品营销团队的一员。她的职业生涯始于电信、无线技术和全球互联网服务供应。在加入 InfluxData 之前，她在日本、德国和巴西生活了几年，为一家开发和管理巴西市场的在线机构工作。](https://www.influxdata.com/) 

从基础设施的角度来看，像 Kubernetes 这样的系统在容器监控方面已经取得了很大的进步。重点已经从单个容器的健康转移到集群健康。这是因为 Kubernetes 通过提供一个逻辑层来简化流程编排，从而将运行微服务的基础架构层商品化，同时实现自动化部署和优化资源分配。降低基础架构成本，提高灵活性—这是一个伟大的价值主张！然而，这种新方法有其优点和缺点。

一方面，在符合要求的集群上运行到所需的最佳声明状态的行为不当或性能不佳的微服务，仍然会对网络和整体应用性能产生破坏性影响。另一方面，观察进程如何处理工作负载，以及哪些服务从容器中生成工作负载，可以在应用程序性能改进方面提供非常积极的结果。说起来容易做起来难，因为容器的一次性性质和进行这些观察的时间很短。

陷入困境或苦苦挣扎的微服务可以从一个容器移动到另一个容器，从一个主机移动到另一个主机，从一个接口移动到另一个接口。在容器化的微服务环境中，仅从外部寻找性能不佳的应用程序的中心需要跟踪一个移动的、间歇的目标:这是诊断团队最糟糕的噩梦。

 [卢卡·德里

Luca 是 ntop 的创始人，也是 ntop 项目的负责人，该项目旨在开发一个用于高速网络流量分析的开源监控平台。他在 ntop 和意大利比萨大学分享他的时间，在那里他是计算机科学系的讲师。](http://www.ntop.org/) 

IT 经理必须保持对来自编排系统、容器和节点的度量的监控。网络运营必须控制网络延迟、服务可用性、响应能力和带宽消耗。除非运行在这种容器化基础设施上的微服务及其庞大的网状容器间网络的健康状况也得到密切关注，否则容器化应用程序监控将会受到短视的影响。

很明显，仅从外部进行监控是不合适的，尤其是对于那些全栈团队。对这些团队来说，每一层和运动的部分都需要和谐地工作。考虑到这一点，微服务的性能监控以及它如何影响容器间的流动，比资源的可用性(通过杀死和旋转新的容器和容器来完成)更能显示问题正在哪里酝酿。为此，有必要从内部了解正在发生的事情。

## 衡量资源和服务指标

基线资源监控指标——比如 CPU、内存和磁盘空间——在 Kubernetes 的三个主要方面都有很好的介绍:容器、节点和主节点。部署 sidecars 可以实现额外的特定于应用的指标和事件监控。然而，当与从微服务性能角度收集的信息相关联时，可以更好地理解关于资源使用、饱和和故障的症状，这些信息包括:

*   等待时间:服务请求的时间
*   流量生成:与其他服务的通信
*   错误:错误发生的频率

容器活动影响基础设施、网络利用率和应用程序性能；因此，不容忽视。没有什么是理所当然的，因为速度和复杂性没有留下太多猜测的余地。针对容器化应用程序环境的周密监控计划必须包括验证容器内部和容器之间发生了什么的方法——识别出现故障、滥用或可疑行为的用户、流程、容器和容器。

诸如进出数据包检查以及根据 IP、端口和协议将数据包分组为流等方法提供了一种可行的方法来监控带宽利用率以及检测非法、恶意和畸形流量。然而，那是在容器扩散之前。对于容器化的应用程序，数据包范例不再足以提供必要的可见性，因为它们不携带上下文(即应用程序、用户、流程、pod 或容器)，因此对它们的监控将无法提供对责任的理解。有时服务在系统内部而不是在网络上交互，在网络上有可能捕获数据包。更糟糕的是，当今网络和应用程序的运行速度要求网络数据包分析器提高数据包处理速度，这给 CPU 带来了巨大的负载。也可以说，使用包只是因为网络基于它们，但应用程序看不到包。它们根据发送/接收的数据、动作延迟和代码响应进行操作。因此，与其使用包级数据来推断应用程序信息，不如直接读取系统指标来提取所需信息，而无需“翻译”，这样更有意义另外，采用系统自省方法会减轻系统的计算负荷。

获取关于容器上运行的工作负载的系统信息的一种方法是使用 eBPF 来收集内核事件。这项技术被 Lawrence Berkeley 国家实验室的 Steven McCanne 和 Van Jacobson 介绍为 Berkeley Packet Filtering (BPF ),这是一种用于内核包过滤的 Linux 内核技术。eBPF 被扩展来处理多种类型的事件，执行除包过滤之外的动作。使用 eBPF 时，您可以将内核事件与网络流数据相关联，以客观地识别哪些容器正在参与通信会话。这将指出哪些用户、流程和容器出现了异常行为。

InfluxData 及其合作伙伴 [ntop](https://www.ntop.org/) 正在采取下一步措施，使用[扩展的 Berkeley 数据包过滤器(eBPF)](https://thenewstack.io/linux-technology-for-the-new-year-ebpf/) 来监控容器化的应用程序环境。这项工作将揭示容器内的活动，指导它找出哪里出了问题，以及是谁导致了性能问题。

## 使用 eBPF 事件数据将网络指标与其他指标相关联

通过 eBPF 的系统自省起到了为基础设施和网络监控添加上下文的作用。这允许快速确定根本原因，并且可以作为容器部署场景中唯一可行的交互信息来源，原因有两个:

*   在当前的网络速度下，任何有意义的采样速率都会产生不可逾越的数据包量来进行检查，从而消耗宝贵的 CPU 周期。如果部署在托管云环境中，这些周期将缓慢且肯定会耗尽预算。
*   微服务之间的流量永远不会真正到达受监控的接口。因此，将没有机会捕获它们。

将 eBPF 监控功能添加到数据包检测中，可以将系统事件与网络流量绑定在一起，从而提供必要的多维度上下文信息，以降低监控数据的熵，并针对可操作的信息发出警报。将活动缩小到谁和什么来说明被监控的过程，这两种方法都无法单独完成，更不用说高效和有效地完成了。

在这个由短暂的容器基础设施和分散的应用程序组成的快速而复杂的新世界中，组织必须成为数据驱动的，以应对不断增长的性能期望。监控必须超越孤立资源的可用性、消耗和性能。它必须提供双筒望远镜和全景视图，以便很好地了解正在发生的事情和可能正在酝酿而未被发现的事情。监控必须揭示趋势，同时提供实时见解，并最终寻求预测和自动化。

为了实现这些目标，它应该研究集装箱间的流量和集装箱内的事件，并将这些数据与收集的其他指标和信息相关联，从而确定问题从哪里开始:集装箱、流程和用户。

## 度量、事件和网络流量的统一位置

eBPF 打开了另一个通道，以获得[可观察性，而不仅仅是监控内部系统中的](https://thenewstack.io/monitoring-vs-observability-whats-the-difference/)，这是将分布式容器化环境中的异常行为和性能变化联系起来所必需的。但是，为了将这些点联系起来，来自指标、事件和容器内/容器间事件的所有信息都需要放在一个平台上，该平台能够充分利用这些数据并对其进行交叉分析。

所有数据都应该放在同一个地方，并减少设置、增加、管理和收集来自多个孤立来源的信息所带来的负担。ntop eBPF 解决方案使用 InfluxDB 作为其时间序列存储引擎，因此可以包含所有类型的监控数据，如指标、内核事件、日志、跟踪和业务 KPI。当用于警报和预测建模时，这一组聚合的指标和事件非常有用。容器时代的复杂性要求一个集成的数据源、一个用于多种数据类型分析的引擎和一个用于所有可视化的 UI。将所有这些整合在一起，将使洞察和观点更加丰富，从而形成一个监控解决方案，实现更智能的警报和可操作的信息。

<svg xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 0 68 31" version="1.1"><title>Group</title> <desc>Created with Sketch.</desc></svg>