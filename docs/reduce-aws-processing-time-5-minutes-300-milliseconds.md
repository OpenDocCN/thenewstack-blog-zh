# 将 AWS Lambda 上的处理时间从 5 分钟减少到 300 毫秒的技巧

> 原文：<https://thenewstack.io/reduce-aws-processing-time-5-minutes-300-milliseconds/>

![Jean Lescure, Data Mining Expert ](img/00e33c234b866fcb38e464be02f1fe66.png)

Jean Lescure，数据挖掘专家。

2016 年初， [Gorilla Logic](https://gorillalogic.com) 的高级软件工程师和架构师 [Jean Lescure](https://cr.linkedin.com/in/jeanlescure) ，通过亚马逊网络服务的 Lambda 无服务器计算服务，观看了一个包含 500 万行数据的 3GB 文件。他知道当时的操作无法扩展到更大的文件，他想知道是否能让它运行得更快。到 9 月在旧金山举行的 Stream 会议时，Lescure 已经将时间降到了 300 毫秒。对于 Gorilla Logic 的客户，一家每年拥有 2 Pb 数据吞吐量的大型航空航天公司来说，这简直令人震惊。别人能复制他的成功吗？

根据 Lescure 在会议上的发言，他们可以。他从手机应用程序启动演示开始了他的演讲。它由两个并排的应用程序组成，每个程序为 AWS S3 存储桶中的一个文件生成五百万个随机行。他注意到一个应用已经完成了任务，并继续解释这次黑客攻击的用例。

他说，Lescure 的方法非常适合数据迁移，因为你可以非常快速地完成迁移。启动一个 Lambda 客户端，它逐行传输数据，并且不会锁定你的应用程序。这意味着当您在后台迁移数据时，用户仍然可以访问您的应用程序。

或者你可以用它来进行繁琐的处理——比如在谷歌硬盘中接收发票或其他数据。或者可以做‘神经计算’分析和图像处理，高可用性，按需计算。

好吧，但是怎么做？

## 这么多数据

Lescure 在与另一个数据大用户电信客户合作时发现了这一黑客行为。Lescure 解释说，他是 AWS 的一名 AWS 全栈开发人员，拥有 Ruby on Rails 和 Node.js 所需的技能，可以为客户提供对数据的快速访问。

第二个应用程序终于完成了它的任务。莱斯科尔指出过去的五分钟，继续说。

为了满足公司的数据需求，他决定采用流媒体技术。在他的演示应用的第一次迭代中，数据从 S3 ( [简单存储服务](https://aws.amazon.com/s3/))桶流入 AWS Lambda。但是你的桶里的数据越多，成本就越高。第二次迭代通过将数据直接传输到 Lambda，然后逐行发送输出，将时间从 5 分钟减少到 30 秒。中间没有 S3。

他使用了 Node.js 和 Ruby 中嵌入的流功能。他解释说，这基本上是关于开放输入和输出端口，允许字节在没有任何中间件的情况下从一端到另一端运行。在这种情况下，中间件是 Lambda 应用程序，但是把它放到磁盘上是没有成本的，因为它只在内存中运行。

经过这一惊人的改进后，他决定优化每一个步骤，进一步缩短处理时间。

## 达到 300 毫秒

在测试中，Lescure 发现解压缩文件是这个过程中成本较高的部分之一。通过简单地去除压缩，他让它们达到了 300 毫秒的 80%。

当然，需要向认为文件需要存放在 S3 存储桶中以防止在传输过程中丢失的客户推销这个想法。他解释说，他们可以根据需要在数据库上拥有尽可能多的冗余，但是如果客户端需要 S3 存储桶中的冗余，稍后可以启动另一个 Lambda 实例来压缩文件，并将它们发送回 S3。

通过稍微移动一下工作负载，处理时间可能会减少。

Lescure 解释说，当你在一个常规数据库上执行插入操作时，它会使用极其优化的算法和代码来检查模式。但是 Amazon 构建的数据库实例并没有针对计算进行优化，所以做任何分析，特别是在模式方面，都会产生性能成本。这就是 Lambda 能够扭转局面的地方，它提供了更快地进行模式验证的能力，只需要一些额外的实例。

通过降低数据库端的计算能力并提高 Lambda 端的计算能力，Lescure 能够将处理时间减少到一秒钟以下，即使在管理千兆字节的数据时也是如此。

就这么简单。

<svg xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 0 68 31" version="1.1"><title>Group</title> <desc>Created with Sketch.</desc></svg>