# 第 1 部分:数据管道架构的发展

> 原文：<https://thenewstack.io/part-1-the-evolution-of-data-pipeline-architecture/>

[](https://www.linkedin.com/in/kostaspardalis)

 [科斯塔斯·帕达里

舵栈的产品主管。布兰多公司首席执行官(已收购)。科斯塔斯永远是一个企业家和工程师。](https://www.linkedin.com/in/kostaspardalis) [](https://www.linkedin.com/in/kostaspardalis)

数据管道是任何现代数据基础设施的动脉。它们的目的非常简单:实现和部署它们是为了将数据从“系统 A”复制或移动到“系统 b”

更正式一点(也足够抽象以证明我们的工程师头衔)，数据管道是负责将状态从“系统 A”复制到“系统 b”的过程。

有些人可能认为上面的定义不完整或不准确，因为传统上在 ETL 中，状态是不被复制的。它还可以在存储到目标之前通过管道进行更改。但是数据管道的上述定义遵循 ELT 范式，管道实际上负责提取和加载，两个系统之间的状态保持不变。

在传统数据基础设施的环境中，“系统 A”通常是捕获或生成新数据的系统，比如云应用程序或数据库，而“系统 B”是数据仓库或数据湖。

建立数据管道是因为创建一个能够处理我们需要的所有可能的工作负载的数据库系统是非常困难的。因此，最初，创建数据或 ETL 管道是为了将数据从 OLTP(在线事务处理)数据库系统(如 PostgreSQL)复制到 OLAP(在线分析处理)系统(如 Snowflake)。

随着计算越来越多地转移到云中，SaaS 成为软件交付的新标准，事情变得更加复杂和有趣。

目前存在的能够生成有价值数据的系统在数量和复杂性上都有所增加，具体表现在以下几个方面:

*   我们仍然有 OLTP 数据库来驱动我们的应用程序，但现在它们位于云上，我们访问它们的方式已经发生了变化。
*   OLAP 仍然以数据仓库的形式推动分析，但我们正在转向更加开放、支持更多用例的云数据平台。
*   像 Kafka 和 Kinesis 这样的流系统已经成为任何现代数据基础架构不可或缺的一部分；这是有原因的。事件流和数据的实时检查变得越来越重要。
*   最后，随着云 SaaS 应用的商品化和平台化，它们已经成为每个组织都需要访问和整合的重要数据源。

除了上述复杂性之外，我们还应该补充一个事实，即仅仅将数据从创建点移动到数据仓库是不够的。如今，数据管道的构建也是为了将数据从我们的分析和处理存储(如数据仓库和数据湖)同步回可以采取行动的系统。

在过去的二十年中，当涉及到处理数据的复杂性时，现实已经发生了很大的变化——这影响了数据管道的架构。但是在我们看到今天应该如何构建它们之前，让我们看看到目前为止是如何完成的。

## 🏗️公共管道建筑

我在很早的时候就开始了构建数据管道的经历，但是当我构建 [Blendo](https://www.blendo.co/) 的时候，我才真正融入其中。在 Blendo，我们的任务是构建从云资源(主要是应用程序)到像雪花和 BigQuery 这样的云数据仓库的数据管道。

我们构建它们的方式如下:

1.  对于我们想要从中提取数据的每个源，我们将每个实体映射到数据仓库中的一个表。

实体是通过 API 从源云应用程序公开的每个资源。例如，Zendesk 定义了一个名为 tickets 的资源。可以想象，它代表了我们在票务系统中创建的门票。

我们可以通过这个资源访问的所有票据都将在我们的数据仓库中名为“tickets”的表中结束，其中票据资源的每个属性都将作为“tickets”表的一列存在。

2.当我们第一次尝试从数据源中提取数据时，我们会尝试提取所有可用的数据。例如，如果我们正在构建一个以 Zendesk 为源的管道，在同步过程结束时，所有的标签都应该在我们的数据仓库中可见。

更重要的是，管道将保持一些内部状态，其中将存储代表管道执行开始时间的时间戳。

这种状态将是持久的，因此管道可以在它再次运行时访问它。此外，这种状态将是一致的，因为如果我们搞砸了，我们最终可能会丢失数据或损坏数据。

3.将来，我们将始终能够访问我们前面描述的管道的一致状态。这种状态称为检查点，我们将使用它来恢复我们的管道，并避免一次又一次地同步每一条数据。

通过使用检查点，我们可以在源位置检查自检查点创建以来创建或更新了什么，并仅将这些数据同步到目标位置。

4.新数据被追加到数据仓库的表中，更新的数据覆盖旧数据。这是我们做出的一个非常重要的设计决定，我们将在本系列的第二部分看到，也是我们想要重新思考的一个决定。

5.最后，我们将使用某种调度程序，以预定义的时间间隔重复执行管道。

## 😇这种方法的好处是

上面的架构相当成功，并且作为数据管道的高级架构，被大多数供应商使用——有一些变化。它的成功有几个不同的原因。

*   目的地，我们的数据仓库，被保证同步到源的最新状态。当然，有一些延迟，但是分析师知道，如果管道执行一切正常(并且考虑到最新检查点的滞后)，她将使用源数据的准确和最新状态。
*   这一事实简化了大量的分析工作负载，使分析师可以轻松地专注于数据。此外，如果她熟悉源数据，那么对她来说解释数据仓库中的模式是非常容易的，因为它几乎与源中的原始模式相同。
*   通过始终将数据更新到目标上的最新状态，我们优化了数据仓库的存储和处理。从而减少成本和查询执行时间。

在过去，这种方法对于像 Amazon Redshift 这样的数据仓库非常重要，因为调整数据仓库集群的大小是一件痛苦的事情，并且需要大量的数据基础设施停机时间。

## 这种方法的缺点是(🦄或者建立新技术的机会)

但是生活中的一切都是一种交换，对于数据基础设施系统来说尤其如此。所以也有一些问题。

最大的问题，也是最麻烦的问题是，数据本身的变化也是数据，在某些情况下，即使不是更重要，也是同等重要的。

例如，考虑 CRM 系统中的销售线索记录。随着销售人员与销售线索的互动，它从销售渠道的一个阶段进入另一个阶段。如果我们只保留线索的最新阶段，就不可能计算出线索在管道阶段的平均时间。

数据和管道的调试和审计几乎不可能执行。由于我们丢失了记录如何以及何时改变的任何历史信息，所以很难弄清楚什么时候出了问题以及什么原因。

随着组织的成熟，其数据基础设施也随之成熟，因此这两个功能变得越来越重要。

最后，在现代数据基础设施中，您必须同时处理事件和关系数据。事件自然地以流的形式出现，它们的行为就像时间序列数据，没有状态的概念。如何同时处理这两种类型的数据？它们需要不同类型的查询，具有不同的复杂性，在某些情况下甚至需要不同的存储技术。

例如，众所周知，处理亚马逊红移的时间序列数据非常困难。建议的方法是旋转模拟某种基于时间的分区的表。您可以按时间访问数据，当您必须进行垃圾收集时，您只需丢弃旧表。

## 下一步是什么

随着我在 Blendo 和今天在 [RudderStack](https://rudderstack.com/?utm_content=inline-mention) 与更多客户的互动，我越来越清楚，坏事实际上是创新和创建新型数据管道架构的机会。

随着市场的变化和要求的提高，以及技术的成熟，重新思考我们的架构的新机会出现了。

在[第二部分](https://thenewstack.io/part-2-the-evolution-of-data-pipeline-architecture/)中，我们经历了市场和技术的变化，这些变化使我们能够重新设计数据管道的架构，以及这种新架构的外观。

通过 [Pixabay](https://pixabay.com/) 获得特征图像。

<svg xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 0 68 31" version="1.1"><title>Group</title> <desc>Created with Sketch.</desc></svg>