# 可观测性和 AIOps 的误导性承诺

> 原文：<https://thenewstack.io/observability-and-the-misleading-promise-of-aiops/>

AIOps 这个术语最初是由 Gartner 在 2017 年创造的，它承诺通过减轻管理复杂系统中涉及的许多“人的问题”来推动更好的决策和更快的事件解决。但是任何关于人工智能的讨论都应该记住，这项技术并不神奇——人工智能可以完成与人类相似的任务，只是速度更快、更有耐心。AIOps 背后的大肆宣传掩盖了它准备实现其目标的现实。AIOps 能否解决困扰运营的底层问题？简单来说，不是。

## AIOps 的承诺

AIOps 是一个热门的新领域: [Gartner](https://www.bmc.com/blogs/gartner-aiops-market-guide/) 已经将其划入魔力象限，该领域的知名厂商包括 [Splunk](https://www.splunk.com/en_us/artificial-intelligence-aiops.html) 和 [NewRelic](https://newrelic.com/products/applied-intelligence) 都在宣传他们的 AIOps 平台。人工智能操作分为三类:观察系统、服务管理、自动化脚本和操作手册。我想看一下有关观测系统和服务管理的承诺和机会，以及有关的问题和挑战。

人们采用 AIOps 是为了提高可操作性，减少人工工作量。AIOps 系统的目标是让我们更好地确保快速交付高质量的软件，并在系统出现故障时支持补救和修复。

## 坏习惯的遗产

 [丹尼尔·费希尔

Danyel Fisher 是 Honeycomb.io 的首席设计研究员。他将自己对数据可视化的热情集中在帮助 sre 快速清晰地了解他们的复杂系统上。在加入 Honeycomb 之前，他在微软研究院工作了 13 年，研究如何帮助人们更快地从大数据分析中获得洞察力。](https://www.honeycomb.io/) 

让我们从基础开始。DORA 度量标准是描述一个团队在管理软件交付和运营方面有多成功的好方法。它们衡量软件部署的速度、成功的频率以及从任何故障中恢复的难度。根据 DORA 的标准，高绩效团队有能力快速部署，检测部署是否失败，并快速修复。

为了跟踪部署的成功和发布的质量，我们可以保留一套面向用户的信号。例如，我们可以跟踪页面加载所花费的时间，看看它是在增长还是在缩减。由于这些数字可能很大—数百万用户、数百个页面—我们将它们聚合成组，并仅跟踪统计数据，如页面加载时间的第 95 个百分位数，或这些页面上的错误状态数。

尽管描述简单，但错误可能很微妙。不良部署的标志可能是某个特定页面的加载速度比以前慢，或者某个代码路径更有可能生成错误。在这些非常用户可见的错误发生之前，计算机系统有其他方式来指示苦恼:一个进程可能耗尽内存或磁盘，或者使用它所有的 CPU 随着进程变慢，各种缓冲区可能会填满。

随着时间的推移，研究小组发现其中一些信号与其他信息来源相关。也许他们已经注意到，当一个进程失去控制时，它会烧光所有的 CPU，锁住系统。或者他们发现，当后端数据库积压时，用户响应时间往往会下降。他们可能会注意到，在日志显示某个关键进程无法写入磁盘后，该进程崩溃了。作为对这些发现的反应，这些瞬态信号中的每一个都会受到一两个警报的监控——警告磁盘已满，CPU 超载，灾难可能会发生。该团队设计了其流程，以产生充满信号的日志文件，希望参考这些日志可以帮助诊断出哪里出了问题。

当软件在单片上运行时，监控和收集这些类型的信号可能是一个好主意——正如谚语所说，当我们把所有的鸡蛋放在一个篮子里，然后雇用一个团队来监视这个篮子。

然而，在现代，这根本没有意义。我们的系统太复杂，太不可预测:一台机器短暂地耗尽 CPU，因为垃圾收集器短暂地运行；日志文件喋喋不休是因为一个无人关心的系统的警告；临时缓存会吃掉所有内存，然后释放。这是新常态。

警报一直在响；没有简单的方法来确定哪个警报对应于哪个故障。(磁盘空间不足是与这个用户错误有关，还是由其他原因造成的？有一段时间无法 pinged 通 DNS 是否与网络故障有关？在建立网络连接之前重试六次真的有关系吗？)

## AIOps 的误导性承诺

那么，AIOps 似乎是合乎逻辑的下一步。聚类算法可以将虚假的警报聚集在一起，意识到它们没有任何共同点，并删除它们。也许一个目光敏锐的人工智能系统可以找到这些庞大而多样的数据集之间的关联:它可以注意到，当特定进程使用所有可用内存时，用户故障经常发生，而在其他时候则不会发生；或者注意到某些用户路径与故障相关联。

AIOps 的承诺有三个方面:结束警报疲劳，快速缩小故障原因的过程，以及在故障影响用户之前检测和预测故障的方法。这种视觉的问题很简单，对于人工智能系统来说，它很难处理。事实上，人工智能恰恰是解决这类问题的最糟糕的技术。

这似乎是一个大胆的主张；我们来分解一下。

## 人工智能需要接受数据训练

任何人工智能系统的根本挑战在于，它需要接受数据训练。机器学习系统训练寻找“好”和“坏”例子之间的界限，因此当它可以从每个类中获得混合时，它做得最好。换句话说，为了训练一个学习系统，我们需要一群成功的人和一群失败的人；然后我们可以了解这两个群体之间的界限是什么。

不幸的是，失败的系统不是这样的。他们往往在很大程度上成功，直到失败。这意味着失败事件将比成功事件少得多。更糟糕的是，之前的训练例子应该是没用的。虽然任何相当好的运营团队可能不擅长预测和修复未来不可预见的问题，但他们至少可以跟上上一个问题。AIOps 依赖于持续出现的已知故障模式。

## DevOps 生活在一个异常的世界里

训练问题的一个可能的替代方案是“异常检测”异常检测背后的[概念是，系统可以识别“正常”的数据组，然后找到那些超出正常范围的数据组。我们可以把它想象成在正常事件周围画一个圆圈，然后确定落在圆圈之外的事件。](http://cucis.ece.northwestern.edu/projects/DMS/publications/AnomalyDetection.pdf)

在许多情况下，这可能具有挑战性:很难围绕“正常”行为画出识别圈。我们可能希望系统行为一致，因此异常将是令人担忧的异常情况。创新意味着系统——以及系统行为——一直在变化。更有可能的是，我们会画一个太小的圆圈，将大量完全正常的行为识别为“异常”；或者我们会画一个太大的圈，把异常误认为正常行为。(更有可能的是，我们会犯两种错误)。

> 人工智能系统寻找它们可以识别和重复的模式。问题是，一旦发现了这些模式，DevOps 团队就会试图粉碎它们。

更糟糕的是，琐碎的故障时有发生——在任何生产系统中都有不间断的琐碎问题，包括那些用户可见的问题。一个寻找异常的警报系统，即使它不太可能成功地画出了适当的圆圈，仍然会对实际上并不构成问题的异常重复而喧闹地开火。如果异常检测器不能只发现重要的异常，那么我们永远不会真正解决噪音警报问题。

## 部署是异常的

情况变得更糟。请记住，异常检测的目标是发现行为异常的系统，但是是以用户不可见的方式。如果故障是用户可见的，我们会用正常的警报来发现它们。在一个持续部署的世界中，很难想象正常情况下的水平设置——快速部署系统的整个要点是不断产生新的异常行为。

## 修复破损的构建是一种异常现象

DevOps 的基本过程恰恰与人工智能系统的工作相反。人工智能系统寻找它们可以识别和重复的模式。问题是，一旦发现了这些模式，DevOps 团队就会试图粉碎它们。这就是所谓的“已知未知”问题。最终的结果是，DevOps 团队最终与他们的人工智能背道而驰:每当它发现什么样的警告足够重要以至于触发寻呼机时，DevOps 团队就大胆地去修复底层问题。更糟糕的是，他们随后会写一份无可指责的事后分析，讲述他们在破坏模式方面做得多么出色！谈论一套不正当的激励机制。

## 你信任你的人工智能吗？

当我们试图找出如何调整我们的学习模型来区分好的和坏的发布时，我们一头扎进了“可解释的人工智能”的开放研究问题。目前，关于如何帮助人工智能系统解释他们做出了什么决定以及为什么做出决定的研究正在取得进展，这项工作非常困难，因为人们很难理解神经网络系数或决策森林加权参数。

很难想象一个运营团队相信一个系统，当他们认为他们看到事情出错时，会放心地说“一切都很好，不要担心”——或者更糟糕的是，跑来跑去参加一个人工智能系统的消防演习，该系统发现了一个实际上无关紧要的异常。

不可避免地，为了解决这个问题，他们可能会想用另一层警报来支持人工智能系统。人工智能真的能判断出用户体验何时降级，或者运营团队需要监控它得出的结果吗？一个警惕的行动团队能对人工智能没有移除真正重要的警报并提升不重要的警报感到安全吗？

## 用灰质建模人工智能

同样，我们需要记住人工智能技术不是魔法。只有当数据中真的存在可识别的模式、某种形式的信号，并且如果我们认为人工智能系统可以被成功训练来找出什么是“有趣的”，什么不是，人工智能才能有所帮助。显然，这些都不是真的:有很多很多信号进来，但很少是相关的。

一个人能看到几千个嘈杂的警报和警告，并有足够的耐心剔除那些有趣的吗？如果真的找不到信号，那么人工智能就不太可能发现它。这是一个问题，因为人类一直在经历这些信号。看着不稳定、不一致的信号，需要更多的预测。请神谕来解释你的茶叶仍然是一个神谕，即使它是 OracleBot 9000。

## AIOps 的替代方案

AIOps 的基本概念是，一种算法可以检查大量嘈杂和不相关的警报，以判断哪些是与人类相关的，哪些是不相关的。但我希望我们能开始看到这一假设的缺陷。

有什么更好的选择？在[透过镜子](https://www.gutenberg.org/files/12/12-h/12-h.htm)中，白衣骑士唱到了这个问题:“……我在想一个把我的胡须染成绿色的计划，然后总是用一个大风扇，这样他们就看不见了。”

当然，我们应该做的是对重要的事情保持警惕。当有太多的警告时——这些警告是不可操作的、不稳定的或嘈杂的，或者与用户的痛苦没有直接联系——信号就会淹没在噪音中。但是 AIOps 鼓励用户放弃这些好习惯。相反，发送大量嘈杂的无关信号，AIOps 会处理剩下的。通过这样做，AIOps 无意中导致了它声称可以帮助解决的问题的激增。

更有效的方法是将您的警报与用户体验下降的情况联系起来。更好的是，建立一个错误预算，[通过 SLOs](https://landing.google.com/sre/workbook/chapters/implementing-slos/) 跟踪用户体验有多糟糕。当用户体验开始下降时，使用提供跟踪、丰富事件和其他有用信息的可观察性工具来找出哪里出了问题以及原因。

结束警惕疲劳的一个万全之策是只对重要的事情保持警惕。顾名思义，关注用户的警报体验意味着每个警报都值得调查，因为它是对用户可能看到的问题的陈述。

## 但这是我掌握的数据

然而，也许不可能对用户性能发出警报。例如，如果您的数据系统只收集性能计数器的时间序列，那么就很难将其与用户体验联系起来。但这不是 AIOps 要解决的问题，而是需要使用正确工具的问题。

想象一下，去看医生，担心你可能骨折了，医生在看你在办公室走动之前给你做了脑电图、心电图和 EKG。通过将这些传感器读数融合在一起，它们可能会识别出当你迈左腿时，你的心率会出现峰值；符合骨折的行为。但是使用 x 光不是更准确更有效吗？

AIOps 也是如此。在错误的信号上使用人工智能系统可能有机会发现你系统中的问题——但适当的可观察性会更有意义。

## AI 准备好行动了吗？

简单地说，不是。广义的 AIOps 混淆了结果和机制。在 AIOps 被封装在 3PO 系列协议机器人的黄金机身中之前，目标不应该是获得人工智能——而应该是解决底层问题。AIOps 承诺确保警报具有可操作性并基于用户需求，监控部署质量以确保其稳健和安全，并能够在不同的数据视角之间灵活移动。

然而，这些事情都不需要“人工智能”。实现 AIOps 的预期目标可以通过以下方法来实现:在对用户重要的系统方面构建警报，根据那些与用户相关的指标来跟踪您的部署情况，以及使用允许您灵活地从这些用户可见的效果转向其背后丰富的解释性数据的工具。通过降低噪音和使用增强信号的工具，在噪音中找到信号。

*充分披露:作者为 [Honeycomb.io](https://honeycomb.io) 工作，该公司生产一种可观察性工具。它不做任何事。*

通过 Unsplash 的特征图像。

<svg xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 0 68 31" version="1.1"><title>Group</title> <desc>Created with Sketch.</desc></svg>