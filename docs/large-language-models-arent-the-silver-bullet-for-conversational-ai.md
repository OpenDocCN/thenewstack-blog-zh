# 大型语言模型不是对话式人工智能的银弹

> 原文：<https://thenewstack.io/large-language-models-arent-the-silver-bullet-for-conversational-ai/>

机器学习的大型语言模型(LLM)——如 [ChatGPT](https://thenewstack.io/beware-chatgpt-a-language-model-in-the-shape-of-shakespeare/) 、 [GPT3](https://thenewstack.io/openais-gpt-3-makes-big-leap-forward-for-natural-language-processing/) 和 BERT——最近吸引了世界的注意力。而且理由很充分。

简单地说，LLM 是人工智能(AI)工具，可以读取、总结、翻译和生成文本。他们能够高度自信地预测句子中接下来会出现哪些单词，这使他们能够生成类似于人类说话和写作的语言。事实上，这些模型是如此的先进，以至于有些人甚至质疑它们是否有能力让[达到](https://www.washingtonpost.com/technology/2022/06/11/google-ai-lamda-blake-lemoine/) [感知](https://www.washingtonpost.com/technology/2022/06/11/google-ai-lamda-blake-lemoine/)。

但是，尽管 LLM 已经成为对话式人工智能系统的重要基础已经不是什么秘密，但许多人错误地认为 LLM 最终将成为解决所有对话式人工智能问题的银弹——事实并非如此。

原因有几个:

## 显著的幻觉率

众所周知，在 LLM 上训练的对话系统会生成没有任何源内容为基础的陈述，或者更糟的是，与源内容相矛盾——这种现象被称为[幻觉](https://aclanthology.org/2022.naacl-main.387.pdf)。

虽然每个模型的比率不同，幻觉是目前所有 LLM 都有的。目前最大的 LLM GPT 3 的幻觉率为[41%](https://arxiv.org/pdf/2203.02155.pdf)——这意味着大约每 2.5 个提示中就有一个会产生包含幻觉的响应。

例如，您可以询问模型 1-800-APLCARE 是否是真正的支持热线，它可能会回答:“1-800-APLCARE 不是真正的 Apple 支持热线。苹果通过他们的网站、电话号码和在线论坛提供支持，但 1-800-APLCARE 不在其中。”实际上，根据苹果网站，1-800-APLCARE 是一条真正的支持热线。在这个例子中，生成的文本实际上是不正确的。

从不同来源引用也不能解决问题，因为该模型经常断章取义，将句子重新组合成一个段落，以创建一个不正确的答案。例如，你可以问模型，“一个 g4dn.16xlarge GPU 实例 AWS 收费多少？”它可能会回答，“AWS 的 g4dn.16xlarge GPU 实例每小时的成本是 0.526 美元。”在这种情况下，g4dn.xlarge 的定价被嫁接到 gfdn.16xlarge。

这些不准确的微妙之处在这些例子中是无害的，但在处理更敏感的主题时有更广泛的含义。OpenAI 在其研究中表示，当 LLM 用于现实世界的应用时，幻觉会构成非常真实的威胁，例如在商业环境中回答员工的问题，或者在医疗保健环境中提供自动化的患者支持。此外，虽然幻觉率有望在未来得到改善，但目前还没有事实核查机制。所以对于未经训练的人来说，这些幻觉很可能是真的。

问题是 LLM 是一个黑箱——几乎没有解释力。但是，要生产一个对话式人工智能系统，生成具有高度信心的真实响应，你需要额外的算法层来帮助确保可预测性。

## 缺乏可控性

LLM 不像传统系统(如谷歌)那样构建，传统系统由数百层算法构成，最终需要连接在一起。LLM 之所以如此强大，是因为它们提供了一个开箱即用的端到端系统，本质上将这些层融合在一起。

一方面，这大大减少了构建和训练复杂系统所需的时间。然而，它也有很大的局限性，因为它提供了很少的可控性，这意味着没有办法操纵模型来产生超出其训练数据的响应。

例如，假设你想利用对话式人工智能为员工提供支持。你的员工可能会问某个叫做“猫王”的会议室在哪里。如果没有像这样的定制用例所需要的额外的可控性，该模型将会根据它所得到的关于实体“猫王”的数据，给出一个无意义的响应。在这种情况下，特定领域的上下文对于产生有意义且可操作的响应至关重要。

## 陈旧的知识

LLM 和 ChatGPT、GPT3 一样，都是训练记忆知识，一枪搞定推理。然而，LLM 所学的知识很快就会过时——尤其是在企业领域。这是因为知识是流动的，数据量每年都在增加。结果是基于模型当前数据集的不准确响应。

例如，根据 2020 年的数据训练的模型不会意识到最近的发展——比如詹姆斯·韦伯太空望远镜以人类肉眼从未见过的方式揭示了宇宙。相反，它会说詹姆斯·韦伯仍在开发中，不知道过去一年的成功。

前面提到的缺乏可控性使得将这些陈旧的知识与模型的其他数据分开变得很困难。也没有明显的机制来覆盖它的知识库，并教导模型对特定提示的最合适的答案是什么。

此外，重新训练 LLM 需要大量的计算资源才能有效，这使得每次模型需要重新训练时都是一项昂贵的工作。对于企业应用程序，如面向客户或员工的聊天机器人，这是不现实的或有效的。

对于像这样的企业 LLM 应用程序，模型是活的和有呼吸的是至关重要的——这意味着它在任何时候都吸收和提供最新的信息。

## 那么，LLM 对今天有什么好处呢？

围绕大型语言模型的兴奋类似于我们早期在计算机视觉中看到的。当 AlexNet 第一次问世时，许多人很快就说计算机视觉已经“解决了”，但事实并非如此。将如此强大的技术转化为实际解决日常生活问题的重要的现实产品仍然需要大量的创新。

类似地，LLM 提供了一个构建对话式人工智能用例的新领域——但它们从来不意味着是对话式人工智能问题的一刀切。

相反，如果企业希望利用创新创造有意义的成果，就需要大量的额外创新。

例如，您可以使用 LLM 作为为客户支持而构建的对话式 AI 系统的起点。它在理解和解释语言方面将做得令人难以置信，但你需要建立定制的算法，这些算法能够理解上下文，能够识别特定领域的语言，并能够根据与用户的交互采取必要的行动。

## 像 ChatGPT 这样的 LLM 应用程序是如何改变这一点的？

ChatGPT 的发展是一项了不起的成就。我们从经典的自然语言理解(NLU)技术到 transformer 模型和 LLM 再到 ChatGPT 的速度远远超出了几年前的预期。而且，由于它对任何给定提示做出响应的速度和创造力，它的发展几乎在一夜之间将对话式人工智能带入了主流。

例如，你可以让它给你的客户写一封有思想的电子邮件，感谢他们的业务，或者你可以用它给你的孩子读一个有创意的睡前故事。它将轻松处理这些任务，并且它肯定会给任何与之交互的人留下深刻印象和娱乐。

然而，ChatGPT 也不能幸免于上述挑战。它仍然患有[21%](https://arxiv.org/pdf/2203.02155.pdf)幻觉率。那是五分之一！而且，在其当前的界面中，ChatGPT 非常局限于提示的输入和输出——这意味着利用 ChatGPT 的唯一方式是通过 OpenAI 现有的聊天功能。

现实情况是，ChatGPT 的真正潜力仍然非常未知。一旦 ChatGPT 模型向世界各地的开发者开放，供他们利用和创新，chat GPT 的全部力量就会显现出来。与传统的 LLM 类似，额外的可控层将允许企业使用 ChatGPT 创建前所未有的定制对话式 AI 用例。

但是毫无疑问，如果 LLM 和 ChatGPT 这样的应用程序想要产生有意义的输出，它们需要在现有 LLM 系统的基础上进行大量的创新。这也意味着那些还没有利用 LLM 架构的企业将需要重新调整他们的机器学习策略，以包括 LLM 和 LLM 应用程序的采用——否则他们将很快落后。

<svg xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 0 68 31" version="1.1"><title>Group</title> <desc>Created with Sketch.</desc></svg>