# Nvidia AI 套件在容器、虚拟机中运行工作负载

> 原文：<https://thenewstack.io/nvidia-ai-suite-runs-workloads-in-containers-vms/>

企业现在可以利用英伟达的 AI 企业软件套件在 VMware 的 vSphere 平台上的 Kubernetes 容器或虚拟机(VM)中开发和运行人工智能工作负载。

Nvidia 几年来一直将人工智能和机器学习作为其增长计划的核心，去年在试用的基础上向[提供了在 vSphere 和 Tanzu](https://thenewstack.io/vmware-extends-tanzu-support-for-nvidia-ai-enterprise/)(VMware 的 Kubernetes 平台)上运行的人工智能企业。上周，该公司表示，它可以提供生产支持。

“Nvidia AI Enterprise 1.1 中最受客户欢迎的功能之一是对在 VMware vSphere 和 [Tanzu](https://thenewstack.io/vmwares-tanzu-extends-across-all-security-layers-on-kubernetes/) 上运行的生产支持，这使开发人员能够在其 vSphere 环境中的容器和虚拟机上运行人工智能工作负载，”[Nvidia 产品副总裁 John Fanelli](https://www.linkedin.com/in/johnfanelli/) 在一篇[博客文章](https://blogs.nvidia.com/blog/2022/01/19/ai-enterprise-release/)中写道。“这是由 Nvidia 和 VMware 策划的人工智能就绪平台中的一个新的里程碑，提供了一个集成的、完整的针对人工智能优化的容器化软件和硬件堆栈，所有这些都完全由 IT 管理。”

Nvidia 去年推出了 AI Enterprise，这是一套人工智能软件和框架，可以在一系列服务器制造商的 Nvidia 认证硬件上运行，无论是在企业的内部数据中心，还是在 Equinix 数据中心的裸机系统上作为服务运行。目标是给开发者一个交钥匙解决方案，组织可以利用它来处理他们的人工智能工作负载。

## **Nvidia 和 VMware 发展合作伙伴关系**

这也是在 2020 年 VMware 的虚拟 VMworld 活动上宣布的 [Nvidia-VMware 多级合作关系](https://thenewstack.io/vmware-extends-vsphere-to-capabilities-for-nvidias-ai-and-gpus/)的最新扩展。英伟达通过其 GPU、软件和 DGX-2 等系统来扩展其人工智能能力。VMware 长期以来一直是数据中心的主要参与者，通过采用 Kubernetes 等技术，它正在积极地向云领域延伸。

现在有了 AI Enterprise 1.1，开发人员可以通过 vSphere 利用容器和虚拟机。

根据 Gartner 分析师的说法，IBM、谷歌和微软等众多老牌 IT 公司和无数初创公司正在全球人工智能软件市场上竞争，预计今年该市场将增长到 625 亿美元，比 2021 年同比增长 21.3%。

恩德勒集团首席分析师[罗布·恩德勒](https://www.linkedin.com/in/rob-enderle-03729/)称，英伟达多年来在扩大其在该领域的存在方面做得很好，包括与 VMware 等公司和越来越多的硬件制造商发展联盟。

“Nvidia 开始只是将他们的 GPU 技术作为解决方案的一部分，但后来意识到需要一个生态系统来促进成功的部署…所以他们开发了这个生态系统，”Enderle 告诉 New Stack。“我认为英伟达是成功人工智能部署的主要驱动力。由于许多因素，如培训成本，大多数早期的人工智能努力都没有达到预期。英伟达一直在积极应对这些因素，目前拥有最全面的工具集，将人工智能从概念带到部署。”

## **英伟达现身 AI**

该分析师表示，自动驾驶汽车、机器人和后端系统等市场中最重要的人工智能实施都涉及英伟达技术，并补充说，英伟达官员很早就明白模拟将是训练的关键工具，并在其他人之前开发了这项技术。

通过 AI Enterprise 1.1，Nvidia 认识到企业对利用人工智能的容器化开发的需求不断增长，这既带来了许多好处，也增加了复杂性。它需要跨多层基础架构进行编排，从人工智能和分析软件框架和硬件到容器和虚拟机。Fanelli 说，作为一个全栈解决方案，AI Enterprise 旨在降低复杂性，使企业更容易接受人工智能。

## **对开发者的促进**

Enderle 说，这也使开发人工智能应用程序的开发人员更加容易。他说，企业产品必须符合围绕安全性和可审计性等领域的企业政策，以便所创造的东西不会偏离公司的目标。它还消除了进入壁垒，并确保企业的预期结果得以实现。

“人工智能企业解决方案内置了一些关键功能，使它们能够在企业中执行，因此开发人员不必自己创建这些功能，从而大大加快了企业和政府的开发和潜在销量，同时也提高了所有市场中最终产品的可行性，”Enderle 说。

Nvidia 和 VMware 将继续简化对人工智能企业的访问，计划很快将 vSphere with Tanzu 添加到 GPU 制造商的 LaunchPad 计划中，组织可以免费测试和原型化人工智能工作负载，并学习如何开发和管理人工智能工作负载。该计划在全球九个 Equinix 数据中心提供。

## **思科、日立 Vantara 加入服务器阵容**

英伟达有越来越多的硬件制造商提供英伟达认证的系统来运行人工智能企业，包括戴尔 EMC、惠普企业、联想、超微、Atos 和技嘉。随着 AI Enterprise 1.1 的发布，Nvidia 将思科系统和日立 Vantara 加入到阵容中。

思科正在推出 UCS C240 M6 机架式服务器，这是一款由英伟达 A100 Tensor Core GPUs 支持的双插槽 2U 系统，可以运行一系列存储和互连密集型工作负载，包括大数据分析、数据库、协作和高性能计算(HPC)。Hitachi Vantara 的第一个此类系统是 Hitachi Advanced Server DS220，它也包括两个插槽和 A100 Tensor Core GPUs。

[思科全球战略合作伙伴计划云技术和软件高级总监 Jeremy Sawyer](https://www.linkedin.com/in/jeremy-sawyer-2767526/) 在[的博客文章](https://blogs.cisco.com/partner/cisco-ucs-becomes-nvidia-certified-accelerating-customer-hybrid-cloud-journeys)中写道，企业正在迁移到混合云环境，其中涉及多个位置的本地故障转移基础设施。与此同时，随着开发人员转向容器并使用 Kubernetes 管理环境，他们越来越多地采用云原生技术。

“此外，许多这些公司都在他们的混合云环境中运行计算密集型、基于容器的工作负载，如人工智能训练和推理、数据分析和 HPC，”Sayer 写道。“为了帮助加速这些工作负载，我们的许多客户转向 Nvidia GPUs 和 Nvidia AI 企业软件套件。”

有鉴于此，思科开发一款 Nvidia 认证的服务器是有意义的，他写道。

<svg xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 0 68 31" version="1.1"><title>Group</title> <desc>Created with Sketch.</desc></svg>