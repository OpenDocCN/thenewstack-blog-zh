<html>
<head>
<title>How Artificial Intelligence Could Reconstruct Your Memories</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">人工智能如何重建你的记忆</h1>
<blockquote>原文：<a href="https://thenewstack.io/researchers-use-ai-read-reconstruct-memories/#0001-01-01">https://thenewstack.io/researchers-use-ai-read-reconstruct-memories/#0001-01-01</a></blockquote><div><div id="tns-post-body-content">


<p class="translated">我们没有一天不听到人工智能可以做一些令人惊讶的新事情。从击败人类象棋冠军、<a href="https://thenewstack.io/alphagos-win-human-go-champion-means-ai/" target="_blank" class="local-link">围棋冠军、</a>扑克冠军、到帮助<a href="https://thenewstack.io/new-machine-learning-algorithms-accelerate-drug-discovery-desktop-computers/" target="_blank" class="local-link">发现药物、</a>和<a href="https://thenewstack.io/power-blox-uses-swarm-intelligence-create-distributed-micro-energy-grids/" target="_blank" class="local-link">管理分布式微型电网</a>，人工智能正在执行曾经想不到的任务。</p>
<p class="translated">但是几乎不可能的事情正在发生，而且发生得很快。我们已经听说了研究人员现在如何训练人工智能解码人脑中的复杂想法。现在，来自俄勒冈大学的一组科学家正在使用人工智能来实际获取某人的记忆，并且几乎是从他们的大脑中“提取出来”——或者至少是一幅图像。</p>
<p class="translated">该团队的发现最近发表在神经科学杂志上，详细描述了如何从人类大脑的角回中检索编码记忆的内容，角回是后外侧顶叶皮层的一部分，它控制着许多功能，包括语言，数字处理，空间认知，注意力和记忆检索。</p>
<h2 class="translated">计算机视觉</h2>
<p class="translated">以下是多部分实验的设计。在实验的第一部分，研究中的23名参与者在观看一系列照片时，每个人的大脑活动都在fMRI(功能性磁共振成像)机器中进行扫描，每张照片都描绘了一个不同的人的头像。</p>
<p class="translated">然后，fMRI会检测这些参与者在看到这些照片时大脑循环流量的任何变化，这些轻微的变化会被人工智能软件实时记录和处理。肤色、眼睛形状和其他明显的面部特征被分解成所谓的<a href="https://en.wikipedia.org/wiki/Eigenface" target="_blank" class="ext-link" rel="external ">特征脸</a>——或计算机视觉和面部识别软件计算中使用的向量值。</p>
<p class="translated">研究人员写道:“使用受计算机视觉方法启发的人脸识别方法，我们将主成分分析应用于大量人脸图像，以生成特征脸。”</p>
<p class="translated">这些特征脸然后在一个编号系统中进行评级，以便它可以被翻译成人工智能可以解析为训练数据的东西。</p>
<p class="translated">“然后我们模拟了特征脸值和fMRI活动模式之间的关系，”研究小组解释道。“然后，由每个人的脸引发的活动模式被用来生成预测的特征脸值，这些值可以被转换成每个人的脸的重建图像。”</p>
<h2 class="translated">重建的记忆</h2>
<p class="translated">对于实验的第二部分(或者可以称为“读心术”)，人工智能随后被测试其重建新一轮面部照片的能力，只使用通过fMRI机器收集的参与者记录的大脑活动数据。基于上一轮的训练数据，人工智能能够将测试对象的神经模式“翻译”成构成重建图像基础的特征脸。下面是出现的内容:<br/> <img decoding="async" loading="lazy" class="aligncenter size-full wp-image-2795221" src="../Images/c510cdeb77afb9de2004137104d787e2.png" alt="" data-original-src="https://cdn.thenewstack.io/media/2017/07/a7eb5500-ai-mind-reading-university-oregon-3.jpg"/></p>
<p class="translated">这并不令人难以置信的准确，但与此同时，一些可怕的不可思议可能正在这里出现。</p>
<p class="translated">在另一项测试中，参与者被要求在他们的记忆中回忆某人的面孔，这些记忆是从大脑的角回中存储和检索的。这些人工智能驱动的重建出人意料地成功，在很大程度上，人工智能能够得出不同的品质，如性别、肤色和情感表达。</p>
<p class="translated"><img decoding="async" loading="lazy" class="aligncenter size-full wp-image-2795219" src="../Images/a487c2f65504c9100abd3ddabc39d772.png" alt="" data-original-src="https://cdn.thenewstack.io/media/2017/07/9603250b-ai-mind-reading-university-oregon-1.jpg"/></p>
<p class="translated">为了验证他们的结果，并获得对大脑内部工作的一些见解，研究小组比较了由记忆检索角回(ANG)和使用枕颞皮质(OTC)进行的重建，枕颞皮质对面部特征很敏感。</p>
<p class="translated"><img decoding="async" loading="lazy" class="aligncenter size-full wp-image-2795220" src="../Images/1cb8679227ee0a21527c9d4a96f9dec9.png" alt="" data-original-src="https://cdn.thenewstack.io/media/2017/07/8abc036b-ai-mind-reading-university-oregon-2.png"/></p>
<p class="mol-para-with-font translated">研究人员写道:“令人惊讶的是，我们还发现，在面部感知期间接受ANG活动模式训练的模型能够成功重建一组独立的面部图像，这些图像保存在记忆中。”“…角回的[活动]模式[支持]感知和记忆面孔的成功重建，证实了该区域在积极呈现记忆内容中的作用。”</p>
<p class="translated">正如你在这里看到的，所谓的机器读心术还没有完全实现。正如研究人员指出的那样，结果也证明了这一点，人们仍然能够控制他们的记忆是如何形成的，例如，在这个实验中看到的重建记忆还不足以让人们在精神上准确地识别出一个毫无疑问的嫌疑罪犯。但是，这项技术似乎正在取得进展，我们可能最终会在某一天达到这一点。</p>
<p class="translated">在<em> <a class="ext-link" href="http://www.jneurosci.org/content/36/22/6069.full" target="_blank" rel=" external ">《神经科学杂志》</a>阅读全文。</em></p>
<p class="attribution translated">图片:俄勒冈大学</p>


<div class="tns-logo-slug">
<svg xmlns:xlink="http://www.w3.org/1999/xlink" viewbox="0 0 68 31" version="1.1">
<title>Group</title>
<desc>Created with Sketch.</desc>
<g id="Page-1" stroke="none" stroke-width="1" fill="none" fill-rule="evenodd">
<g id="Group">
<path d="M24.002,29.619 L29.77,29.619 L29.77,15.808 C29.77,15.038 29.622,11.265 29.59,10.414 L29.77,10.414 C31.424,14.019 31.473,14.147 32.168,15.322 L39.65,29.618 L44.845,29.618 L44.845,0 L39.075,0 L39.075,11.064 C39.075,12.197 39.075,12.44 39.182,14.472 L39.325,17.468 L39.151,17.468 C39.034,17.267 38.596,16.173 38.467,15.929 C38.164,15.323 37.725,14.512 37.373,13.905 L30.031,0 L24,0 L24,29.619 L24.002,29.619 Z" id="Path-Copy" fill="#FF3287"/>
<path d="M56.948,0 C50.745,0 47.606,3.43 47.606,8.296 C47.606,14.114 51.036,15.404 55.518,17.132 C60.438,18.853 61.782,19.332 61.782,21.539 C61.782,24.225 58.969,24.867 57.401,24.867 C54.579,24.867 52.493,23.342 51.536,20.858 L47,24.185 C49.43,28.937 52.145,30.185 57.713,30.185 C59.364,30.185 62.059,29.74 63.727,28.694 C67.779,26.156 67.779,22.22 67.779,20.898 C67.779,18.129 66.531,16.207 66.178,15.726 C65.049,14.121 63.032,12.918 61.25,12.278 L57.084,10.914 C55.073,10.267 52.928,10.105 52.928,8.019 C52.928,7.707 53.008,5.528 56.288,5.319 L61.465,5.319 L61.465,0 C61.465,0 57.342,0 56.948,0 Z" id="Path-Copy-2" fill="#00AFF4"/>
<polygon id="Path" fill="#00AFF4" points="5.32907052e-15 1.77635684e-15 5.32907052e-15 5.319 7.572 5.319 7.572 29.564 14.132 29.564 14.132 5.319 21.544 5.319 21.544 1.77635684e-15"/>
</g>
</g>
</svg> </div>
</div>
</div>    
</body>
</html>