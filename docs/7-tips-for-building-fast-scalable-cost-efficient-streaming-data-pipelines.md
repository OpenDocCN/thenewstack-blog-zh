# 构建快速、可扩展、经济高效的流数据管道的 7 个技巧

> 原文：<https://thenewstack.io/7-tips-for-building-fast-scalable-cost-efficient-streaming-data-pipelines/>

[](https://www.qubole.com/)

[Ashish thu soo](https://www.qubole.com/)

[Ashish thu soo 是 Qubole 的首席执行官兼联合创始人。在 2011 年联合创立 Qubole 之前，Ashish 领导脸书的数据基础设施团队，建立了世界上最大的数据处理和分析平台之一。Ashish 在脸书的工作不仅帮助实现了分析师、工程师和数据科学家访问数据的大胆目标，还推动了大数据革命。](https://www.qubole.com/)

[](https://www.qubole.com/)[](https://www.qubole.com/)

实时数据使用的急剧增长不可避免地导致了流媒体分析投资的增加。企业正在从传感器、智能手机、IT 设备、网站和其他非传统来源获取越来越多的数据，并实时处理这些数据以改善运营和更好地服务客户。

通常情况下，数据来自多个来源，并被收集在一个[开放的数据湖](https://www.infoworld.com/article/3534516/is-your-data-lake-open-enough-what-to-watch-out-for.html)中，在那里与现有的历史数据相结合，以提供商业价值和结果，通常是通过机器学习和人工智能。数据工程师面临的挑战是建立流数据管道，以实现快速实验和大规模可靠运行。

当使用开源和商业软件的组合来组装流处理栈时，有几个障碍会阻碍项目的成功。这篇文章探讨了克服这些障碍的一些最佳实践，并构建了快速、可扩展和健壮的流管道。

## 允许快速实验

尝试新模型和数据集的能力至关重要。这里重要的一步是减少获取和准备新数据源的时间，以便它们可以与其他数据资产相结合。例如，使用通用流数据源的预打包连接器，这允许您在不编写代码的情况下快速试验不同的数据集。其中包括 Kafka、Kinesis、S3、S3-SQS、GCS、HIVE、HIVE-ACID、Snowflake、BigQuery、ElasticSearch、MongoDB 和 Druid 的连接器。

但是使用连接器对于快速实验是不够的。使用能够开发管道的工具也很重要，这些管道具有自动生成的代码，然后可以进行编辑，例如，用于连接数据的代码，以及通过 UI 驱动的界面构建业务逻辑的代码。

## 通过自动化控制总拥有成本

Spark 结构化流管道是长期运行的，这意味着成本可能会很快失控。对集群管理应用自动化可以显著降低成本，同时确保维持业务 SLA。

关键是充分利用大型云提供商的[现场](https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/using-spot-instances.html)和[可抢占](https://cloud.google.com/kubernetes-engine/docs/how-to/preemptible-vms)节点类型及其传统的按需类型，因为这些现场和可抢占类型允许您更经济高效地运行工作负载。对于数据工程师来说，选择正确的实例类型并知道何时扩大和缩小它们是一个猜谜游戏，他们往往会在过度供应和供应不足之间摇摆不定。关键是使用异构集群配置和自动化，可以根据使用模式即时调整集群大小，甚至根据历史数据预测要部署的集群大小。

## 允许云的可移植性

Gartner 去年的一项调查发现[超过 80%](https://www.gartner.com/smarterwithgartner/why-organizations-choose-a-multicloud-strategy/) 的受访者使用不止一家公共云提供商。在一个数据在多个云中生成和存储的世界中，拥有一个不会将您局限于特定存储库、存储格式、数据处理框架或用户界面的流管道策略是必不可少的。适应性是关键。

这需要技术在您预期使用的每个公共云上提供相同的流管道功能。工程师应该能够带来他们自己的代码(jar ),通过做一些重新配置，在每个云中重新创建一个现有的管道，而不需要完全重写他们的代码。

## 使测试和调试变得容易

因为构建管道是一个迭代的、无循环的过程，所以确保您有有效的方法来测试和调试管道是关键。工程师应该能够使用输入数据的子集，通过持续几分钟的“试运行”来测试管道。这有助于验证连接性，确保数据模式是正确的，并确保业务逻辑是完整的并按预期执行。

## 确保数据的准确性和一致性

长时间运行的管道可能会遇到一致性、准确性和质量方面的问题，这是由于数据的到达没有特定的顺序以及模式的演变。为了解决这个问题，请仔细研究数据传输过程以及如何管理管道更新。作为最佳实践，在数据存储到数据湖中之后，为数据建立预定义的、定期的“控制点”。这确保您拥有可靠的、有序的、经过错误检查的数据(在概念上类似于互联网分组交换中的传输控制协议)。

通常，在对数据管道或应用程序的代码进行更改时，要消除复杂性和潜在的错误点。随着业务需求的发展，应用程序会及时改变，这需要持续的数据工程。

## 允许重放和重新处理数据

当模型更新或业务逻辑改变时，用户可能需要编辑管道，进行更改并从特定的检查点重新开始。

当发生变化时，能够有效地重放或重新处理流管道是非常重要的，并且能够在过程的不同点这样做。这类似于编辑视频——每次进行一次编辑就重播整个视频是不切实际且耗时的。同样的原理也适用于流式数据管道。

解决这个问题的一个方法是提供一个“错误接收器”输入数据中的模式可能会发生变化并导致不一致。因此，能够检测模式不匹配和无效记录、过滤这些记录并将坏记录的元数据(以及异常消息)写入单独的存储位置非常重要。用户可以设置发生这种情况时的警报，并通过清理和重新处理这些错误记录来防止数据丢失。

## 最大限度地减少使用原生流的时间

一些应用需要真正的实时数据，因此缩短数据接收到并投入使用之间的延迟非常重要。一些数据仓库支持“微批处理”，它经常以小增量收集数据，但这对于真正的实时用例来说引入了太多的延迟。

数据湖更适合这些用例，因为它们支持原生流，即在数据到达时对其进行处理并供分析使用。数据管道在收到数据时转换数据，并触发分析所需的计算。在原生流和微批处理之间进行选择取决于您的应用程序的需求。

## 结束语

实时数据为更深入的分析和令人兴奋的新用例提供了机会，但这是一个相对较新的领域，工程师需要在控制成本的同时快速进行实验。构建一个利用自动化和预写代码的流处理堆栈将允许您的团队开发新的数据分析方法，同时最大限度地提高效率和创新。上面的指导方针应该有助于您的流数据项目取得成功。

通过 Pixabay 的特征图像。

<svg xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 0 68 31" version="1.1"><title>Group</title> <desc>Created with Sketch.</desc></svg>