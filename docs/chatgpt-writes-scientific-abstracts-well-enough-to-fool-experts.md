# ChatGPT 写的科学摘要可以糊弄专家

> 原文：<https://thenewstack.io/chatgpt-writes-scientific-abstracts-well-enough-to-fool-experts/>

2022 年底发布的人工智能 ChatGPT 激起了全球数百万用户的兴趣，他们使用该工具即时生成类似莎士比亚的十四行诗，或编程代码行[。](https://thenewstack.io/chatgpt-smart-but-not-smart-enough/)

但是 ChatGPT 在制作怪异的人类文本方面的多功能性也引发了学术界的焦虑，许多教育工作者担心它可能被学生滥用寻找一种简单的方法来写令人信服的大学水平的论文，以冒充他们自己的作品。

同样，那些从事科学研究的人也表达了这种担忧，他们担心像 ChatGPT 这样强大的大型语言人工智能(AI)模型可能会被用来撰写研究论文，其中一些论文可能足以欺骗其他科学家和学术机构。

不幸的是，西北大学和芝加哥大学最近的研究表明，ChatGPT 事实上非常擅长撰写可信的科学摘要——好到他们不仅愚弄了人类专家，还愚弄了传统的剽窃检测工具。

科学摘要是一篇科学论文的概述，通常包含在论文的开头，简要概述了研究的背景信息、方法、结果和讨论。摘要是为了给读者一个工作的浓缩版本，是任何研究论文的重要组成部分。

在这种情况下，预印本[研究](https://www.biorxiv.org/content/10.1101/2022.12.23.521610v1.full.pdf)涉及使用 ChatGPT 生成 50 份医学研究摘要，此外还有人类撰写的摘要。然后，每个人类评审员被要求查看 25 篇机器和人类创作的摘要，以给出二进制分数来表明他们认为它是假的还是真的。

## 正品

为了让机器生成的文本更加可信，研究人员提示聊天机器人，要求它根据知名科学杂志的最近标题生成文本，如《美国医学会杂志》、《新英格兰医学杂志》、《BMJ》、《柳叶刀》和《自然医学》。除了在人类评论者身上测试机器和人类生成的摘要集，摘要还通过传统的抄袭检测器和人工智能输出检测器运行。

“我们的审稿人知道他们得到的一些摘要是假的，所以他们非常怀疑，”该研究的主要作者凯瑟琳·高在一份声明中说。

“这不是有人在野外读摘要。事实上，我们的评论者仍然有 32%的时间错过了人工智能生成的摘要，这意味着这些摘要真的很好。我怀疑，如果有人偶然看到这些生成的摘要之一，他们不一定能够识别它是由人工智能写的。”

在生成摘要的过程中，ChatGPT 能够正确处理一些表面的细节，这有助于为文本增添真实性。例如，在创建一项关于高血压的虚假研究时，ChatGPT 包括了队列中数万名患者的详细信息，而一项猴痘研究被描述为受试者少得多。尽管这些数字本身是伪造的，但仍然有足够的一致性来欺骗人类读者。

机器生成的文本也骗过了传统的抄袭检测工具，这些工具将 ChatGPT 摘要的原创性评分中值定为 100%。然而，人工智能输出检测器能够识别 66%的人工智能生成的摘要——不算太差，但也不算太大。

另一方面，人类审查者并没有做得更好:他们只能挑出 68%的虚假摘要，相比之下，他们能正确识别 86%的人类撰写的文本。事实上，人类审查员错误地将 14%的真实摘要识别为假的。

虽然不是万无一失，但高说，结果表明的人工智能检测工具需要成为审查过程的一部分。“我们发现人工智能输出检测器非常擅长检测 ChatGPT 的输出，并建议将其作为筛选过程包括在科学编辑过程中，以防止被像[造纸厂](https://blog.mdpi.com/2022/05/09/paper-mills/)这样可能试图提交纯生成数据的组织锁定。”

尽管 ChatGPT 可能被用于邪恶的目的，但该团队认为这项技术也有潜在的优势。

“我们预计这项技术既可以用于道德领域，也可以用于不道德领域。鉴于其生成可信数字摘要的能力，它可以用来完全伪造研究，”该小组说。

另一方面，该技术可以与研究人员自己的科学知识结合使用，作为减轻写作和格式化负担的工具。科学家可以用非母语的语言发表文章，以提高公平性。”

<svg xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 0 68 31" version="1.1"><title>Group</title> <desc>Created with Sketch.</desc></svg>