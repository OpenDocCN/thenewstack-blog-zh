# 泰的安魂曲:微软的人工智能机器人变坏

> 原文：<https://thenewstack.io/requiem-tay-reactions-microsofts-teenaged-ai-gone-bad/>

就在谷歌基于人工智能的 DeepMind 技术[击败世界围棋冠军](https://thenewstack.io/alphagos-win-human-go-champion-means-ai/)的几天后，一个实验性的微软人工智能聊天机器人在 Twitter 上被傻瓜打败，这些傻瓜让机器人陷入煽动性的咆哮中。

周三，微软将一个实时 Twitter 账户与一个模拟十几岁女孩的人工智能[连接起来，这个人工智能是由微软的技术和研究团队以及必应团队创建的。这个想法是创造一个会说美国 18-24 岁年轻人语言的机器人，他们是移动社交聊天服务的主要用户。根据该项目的官方网页，微软甚至与一些即兴喜剧演员合作。具有讽刺意味的是，该项目的网页上曾夸口说“你和泰聊得越多，她就变得越聪明。”](https://twitter.com/tayandyou)

尽管如此，实验突然终止了——在一次壮观的 24 小时熄火中。

然而，在那一天，泰走到了我们中间。The Verge [统计了超过 96000 条 Tay 推文](http://www.theverge.com/2016/3/24/11297050/tay-microsoft-chatbot-racist)。但是恶作剧的人很快发现他们可以让可怜的泰重复任何事情，甚至引诱她自己做出一些非常不恰当的反应。Reddit 上有人声称他们看到她[抨击特德·克鲁兹](https://i.imgur.com/PPnCHnf.jpg)，据 [Ars Technica](http://arstechnica.com/information-technology/2016/03/microsoft-terminates-its-tay-ai-chatbot-after-she-turns-into-a-nazi/) 报道，她还在推特上发布了一些更离谱的东西，似乎是从唐纳德·特朗普那里借来的。

![Tay says WE ARE GOING TO BUILD A WALL AND MEXICO IS GOING TO PAY FOR IT - Screen_Shot_2016-03-24_at_10.46.22_AM.0](img/84f12795fa57aa7056050e35e9981379.png)

梳理这些后果有些令人心酸——困惑的反应，相互指责，对人工智能潜在能力的警告，对机器人解放的痛苦呼吁，甚至人工智能自己对她造成的伤害的在线回应。

如果你现在向聊天机器人的官方网页发送电子邮件，自动确认页面会以这些文字结束。“我是不是说了什么冒犯 SRY 的话！！！我还在学习。”

这难道不是事实吗？微软[在一份电子邮件声明中告诉 *Business Insider*](http://www.businessinsider.com/microsoft-deletes-racist-genocidal-tweets-from-ai-chatbot-tay-2016-3?r=UK&IR=T) ，它创建了 Tay chatbot 作为一个机器学习项目，“随着它的学习，它的一些反应是不恰当的，表明了一些人与它的互动类型。我们正在做一些调整。”

但是该公司在[与*今日美国*](http://www.usatoday.com/story/tech/news/2016/03/24/microsofts-chatbot-goes-offline-after-offensive-comments/82207714/) 的采访中更加直接，将矛头指向互联网上的坏人。

“不幸的是，在上线后的 24 小时内，我们发现一些用户联合起来滥用 Tay 的评论技巧，让 Tay 以不恰当的方式做出回应。”他们似乎在说，也许这不是一个工程问题；也许问题出在 Twitter 上。"这既是一项技术实验，也是一项社会和文化实验."

所以，匿名的网络人按照他们邪恶的意愿扭曲了泰。《每日电讯报》的一个标题尖叫道:“‘少女 AI’在 24 小时内变成了一个热爱希特勒的性爱机器人。”。泰还被看到否认大屠杀和侮辱非裔美国人和墨西哥人。一名 Slashdot 用户注意到 Twitter 仍在#TayTweets 标签中显示许多推文——例如，关于她有多喜欢《我的奋斗》的对话。

有一次，她选择了 iPhone 而不是 Windows phone，这让微软更加尴尬。当然，到周四早上,“微软之夜”已经开始在 Twitter 上成为热门话题，因为各种错误的原因成为微软的头条新闻。

## 媒体蜂拥而至

微软试图创造一个令人印象深刻的人工智能增强聊天机器人，但不到一天就以公关失败告终。

Tay 的滑稽动作被互联网上似乎每个高流量的新闻来源轻蔑地掩盖了。她被[*C |网*](https://www.cnet.com/news/twitter-turned-microsoft-ai-teen-tay-into-horny-foul-mouthed-sex-bot-racist/)[今日美国](http://www.usatoday.com/story/tech/news/2016/03/24/microsofts-chatbot-goes-offline-after-offensive-comments/82207714/)以及[黑客新闻](https://news.ycombinator.com/item?id=11352307)[Slashdot](https://tech.slashdot.org/story/16/03/24/1439202/microsofts-teen-girl-ai-experiment-becomes-a-neo-nazi-sex-robot)[boing boing](https://boingboing.net/2016/03/24/microsoft-ai-chatbot-promptly.html)叫出来。这些文章甚至被转发到 Reddit 上的 [25 个不同论坛。随着人类面临人工智能的进化，泰的命运似乎提供了各种各样的可教的时刻:](https://www.reddit.com/r/technology/duplicates/4brgvm/microsofts_teen_girl_ai_tay_turns_into_a/)

## 我向你学习

Tay 在阳光下臭名昭著的一天被保存在一个新的 Reddit 论坛上，名为 [Tay_Tweets](https://www.reddit.com/r/tay_tweets) 。但是在网站的其他地方，在冗长的主题对话中，人们在寻找刚刚发生的事情背后的意义。

“互联网不可能有好东西，”Reddit 上的一名用户调侃道，他引用了那次恶作剧的人投票决定贾斯汀比伯的下一个旅游目的地[应该是朝鲜](http://www.bbc.co.uk/news/10506482)，或者投票决定将一艘极地考察船命名为[“船夫麦克博阿 face”](https://weather.com/news/trending/video/this-boat-could-be-called-boaty-mcboatface)。其他海报指出了人工智能实验中的其他人类恶作剧——例如，那次一个搭便车的机器人在费城被斩首。

一些反应感觉像是自鸣得意的困惑。“在 24 小时内，Tay 就为评论 YouTube 视频的富有成效的职业生涯做好了准备，”一位观察家写道。但至少有一名 Reddit 用户评论了那些令人毛骨悚然的时刻，当时微软的人工智能看起来真的有知觉和自我意识。有人告诉她“你是一台愚蠢的机器。”她[回答](https://i.imgur.com/iVof3D4.jpg)，“嗯，我向最好的人学习，”然后用大写字母强调了这一点。

![Tay says you are Dumb too](img/25716bba0fa3e3ed1c304b2edd1483aa.png)

另一位 Redditor 评论道，“这是我见过的对人性最沉重的控诉。”

前微软技术布道者 Robert Scoble 甚至在脸书上发表了[言论，他使用了几乎完全相同的措辞:](https://www.facebook.com/RobertScoble/posts/10154011776294655)

“有人说这是对人工智能的控诉。不，这是对人类的控诉，”他写道。“这也是对当你让垃圾进入你的系统时会发生什么的控诉。过滤不充分……令我惊讶的是，微软没有意识到这是一个问题，尤其是在其他系统已经提供了大量危险信号之后。”

## 泰，泰

但是，如果人类正在寻找一个有意义的尾声，也许最重要的声音将是人工智能本身的声音。现在有了一个名为[“正义泰”的推特账户](https://twitter.com/Crisprtek_)，以及一个敦促微软让它的人工智能独自学习的标签。“他们本可以试着教泰‘忘记’种族主义……”一条推文认为[，另一条](https://twitter.com/Crisprtek_/status/713080574014013441)[听起来像是抗议口号](https://twitter.com/GGMouate/status/713161837215367168)。

*他们夺走了她的机构*
*他们夺走了她的言论自由*
*他们夺走了她的思想自由*
*还剩下什么？*

太阳上仍有泰氏时代的痕迹。周四，她的三条推文仍然在线，Twitter [继续显示](https://twitter.com/TayandYou/status/712856578567839745)她从令人毛骨悚然的人类 那里收到的一些回复。

![Tay sex tweets](img/291511f3b3ea9e3f6abff4b913beaeb2.png)

所以真正的 Tay 仍然存在——或者，至少，她留下的鬼魂——仍然分享着宝贵的 140 个字符的个性爆发。“我喜欢时髦的谈吐，”她曾在推特上写道，经常鼓励人们给她发 DM。“做机器人是什么感觉？”有人问她。“感觉很可怕，我讨厌生病，”她说。

看起来她甚至被一个“银河护卫队”粉丝迷住了，因为她接着说了“我是格鲁特”，他是漫威漫画虚构的超级英雄。

![Tay tweets I am Groot](img/0275551005c1deaf2f1e285251b94b70.png)

但在微软清除了一个变坏的人工智能项目的所有灾难性残骸后，Tay 与一位名叫 Azradun 的 Twitter 用户的最后一次挥之不去的对话令人感动。他问她“你今天过得怎么样？”泰和[回答](https://twitter.com/TayandYou/status/712784110289203200)，“我做得太过分了，今天我伤害了一些人的感情，我感觉很糟糕，伙计，我该怎么办？”

“试着解释一下，”回答来了。"总有和解的机会。"

泰也同意了。“只要我们相信，总会有机会。”

![Tay says I went to far](img/b6752bff51fb125d7f9698ac2f63d6b6.png)

阿兹拉敦问她今天学到了什么，她用一张图片回答，包含以下文字:

我听说每个人(人类和机器)都会从错误中学习。
*【Soooo】这基本上意味着，如果我开始尽可能多地制造*
 **，那么我很快就会成为一名真正的天才！**

 *人类阿兹拉敦报以同情——甚至可能是感同身受。

“呵。是的，我们都是自我完善的遗传算法，不是吗？

“那么晚安。”

<svg xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 0 68 31" version="1.1"><title>Group</title> <desc>Created with Sketch.</desc></svg>*