# 通过数据预处理从机器学习中获得更多

> 原文：<https://thenewstack.io/get-more-out-of-machine-learning-with-data-preprocessing/>

从过滤电子邮件收件箱中的垃圾邮件，到分析网站，到个性化广告和产品搜索，机器学习被用于方方面面。所以当 [ML 开发者创造新的算法](https://thenewstack.io/the-ultimate-guide-to-machine-learning-frameworks/)时，他们想知道他们正在产生最优的结果。然而，由于几个可能的错误，机器学习开发经常会遇到延迟或降低有效性能的问题，使结果不可靠。

本文将着眼于可能阻碍有效的机器学习模型的因素。然后，我们将探索预处理如何帮助增强机器学习，以及 ML 团队如何实现预处理来改善机器学习模型提供的结果。

## 什么是预处理

预处理是为机器学习模型准备原始数据的重要第一步。原始数据通常包含各种错误、异常和冗余。或者它可以以特定机器学习模型不能使用的格式呈现。对数据进行预处理可以确保数据集准备好与特定的机器学习模型及其算法一起工作。

## 可能干扰 ML 模型的问题

无数的问题会干扰机器学习模型的性能。这些问题包括从数据本身的问题到开发人员的错误选择。

如果机器学习模型[试图从一个质量很差或有错误的数据集中得出](https://thenewstack.io/creating-machine-learning-models-takes-too-much-time/)，那么结果将会是偏斜和不可靠的。类似地，如果没有足够的数据来推动这个过程，结果也不会令人满意。如果数据集中存在未被识别的固有偏差，那么机器学习结果将反映并放大这些偏差，从而产生错误的结果。

此外，由机器学习开发者选择正确的算法来逼近每个数据集；错误的选择会导致混乱、低效的处理。开发人员应该警惕过度拟合和欠拟合，这两种情况[会稀释和无效](https://www.javatpoint.com/overfitting-and-underfitting-in-machine-learning)机器学习性能，产生不准确的结果，要么方差太大，要么偏差太大。

开发人员还必须选择最佳超参数，以适应给定的数据集；糟糕的超参数调整是另一个可能对机器学习模型产生不利影响的潜在问题。

## 预处理如何提高 ML 性能

无论数据集如何，建立一个高效、可信和可靠的机器学习模型是一个多步骤的过程。花时间彻底预处理数据是整个过程中的重要一步。

从长远来看，专注的预处理可以节省开发人员的时间，因为它为成功建立了机器学习模型，避免了在事实发生后改变结果或回到建立模型的开始阶段的需要。

开发人员必须仔细选择特定的预处理方法[来匹配](https://www.v7labs.com/blog/data-preprocessing-guide)特定的数据集。预处理的深度也将取决于每个数据集和算法；预处理不是一刀切的方法。

## 数据预处理步骤

### 汇集数据集

数据预处理的第一步[是组装](https://www.upgrad.com/blog/data-preprocessing-in-machine-learning/)数据集。这包括从所有不同的位置收集数据，并将其整合到一个位置，如数据仓库。当你制定算法时，这将减少低效和重复的结果。组装数据集可以包括从不同的库中导入数据，并将文件转换为正确的格式，以使算法需要处理的所有数据都可用且易于访问。

例如，使用机器学习来创建视频剪辑之间的平滑过渡的视频编辑器，如果他们以一组干净的预处理视频文件开始该过程，将会有更好的结果。与其一次发送一个大的视频文件并反复激活机器学习算法，视频编辑应该将他们所有的剪辑汇集在一个地方，并在部署将自动完成部分编辑过程的算法之前[对媒体进行分类](https://massive.io/how-to/how-to-send-large-videos/)。

### 导入库和数据集

一旦组装好数据集，就需要导入核心库。大多数机器学习开发人员使用 Python，[所以一定要为你的模型导入必要的 Python 库。](https://codeberryschool.com/blog/en/how-to-import-a-library-in-python/)

在导入相关的 Python 库之后，您将导入数据集本身。这一关键步骤包括提取自变量和因变量，这将防止进一步出错。

### 评估数据集的质量

原始数据集至少有一些缺失值或异常值是正常的；重要的是[在使用算法之前识别并解决](https://www.sciencedirect.com/topics/engineering/anomaly-detection)这些差距。在数据中寻找可能扭曲整体结果的异常值。检查不匹配的数据类型和混淆的数据值；这些数据“错别字”会导致不可靠的结果。在数据清理过程中解决任何丢失的数据。

### 数据清理

在预处理的数据清理步骤中，您需要从数据集中调整、修复或删除不相关的和错误的数据。在这一步中，您可以替换丢失的数据或调整数据集以补偿丢失的值。

这是数据预处理中最重要的部分，因为这是确保数据可信和可靠的地方。

### 减少数据

如果您正在处理大量数据，那么将数据减少到可管理的大小将有助于高效的算法处理。并非数据集中的所有数据都与每个特定的处理任务相关；合并和组织成最简洁的相关包将产生更清晰和更有效的结果。

### 转换数据

在这个预处理步骤中，您需要[将数据转换成适合您的特定算法和模型的格式](https://www.stitchdata.com/resources/data-transformation/)。

规范化数据允许您在内聚的术语上比较完全不同的形式，而特征选择有助于算法，其中某些类型的数据被认为更重要并相应地突出显示。这使得您的数据结果更容易解释，具有一致的测量标准。

## 预处理的好处

也许预处理数据最明显的好处是它可以提高机器学习模型的准确性。通过清理和组织数据以确保其可信，机器学习模型算法将能够产生更稳健、更准确的结果，而无需从错误、不相关或有偏见的数据中开始。

从预处理数据开始可以减少过度拟合和欠拟合的可能性。由于该过程的这一重要初始步骤根除并消除了[冗余和不相关的数据](https://thenewstack.io/do-we-need-data-normalization-anymore/)，机器学习模型将能够准确地整合新信息。

预处理也提高了模型的效率。预处理需要时间，但它可以缩短模型本身的总体训练时间。这意味着开发人员可以通过减少算法被训练处理的无关紧要的数据量来节省时间和资源。

## 清晰高效的机器学习模型的预处理

预处理是机器学习模型开发的关键步骤。在将数据引入机器学习算法之前，开发人员应该投入足够的时间和资源来认真组织和准备他们的数据集。

从一个干净的、预处理的数据集开始将允许算法提供更清晰的、更容易解释的结果。这在分析阶段节省了分析师的时间和资源；并允许开发人员更容易地理解机器学习过程以及如何为未来的数据分析改进算法。

<svg xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 0 68 31" version="1.1"><title>Group</title> <desc>Created with Sketch.</desc></svg>