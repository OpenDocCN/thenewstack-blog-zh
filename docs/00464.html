<html>
<head>
<title>Autonomous Robot Does Surgical Cuts Better than Human Surgeon</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">自主机器人比人类外科医生做得更好</h1>
<blockquote>原文：<a href="https://thenewstack.io/autonomous-robot-surgical-cuts-better-human-surgeon/#0001-01-01">https://thenewstack.io/autonomous-robot-surgical-cuts-better-human-surgeon/#0001-01-01</a></blockquote><div><div id="tns-post-body-content">


<p class="translated">无论你从哪里看，自动化似乎正处于向各种行业蔓延的风口浪尖。我们已经熟悉了<a href="https://thenewstack.io/robot-tamer-reprograms-industrial-robot-curious-living-creatures/" target="_blank" class="local-link">工业机器人</a>在工厂车间取代人类，或者<a href="https://thenewstack.io/olli-electric-self-driving-3d-printed-shuttle-can-hail-smartphone/" target="_blank" class="local-link">无人驾驶汽车</a>在一些道路上谨慎地首次亮相。但我们对医学等领域的机器人不太熟悉，在这些领域，我们仍然倾向于相信人类医生的技能，而不是机器。</p>
<p class="translated">然而，这种偏见可能很快就会消失，因为越来越多的研究开始表明，机器往往能够匹配甚至超过人类医疗保健专业人员的技能水平，无论是在<a href="https://thenewstack.io/deep-learning-algorithm-diagnoses-skin-cancer-better-human-dermatologists/" target="_blank" class="local-link">疾病诊断</a>方面，还是在执行外科手术过程中可能比人更准确。</p>
<p class="translated">正如智能组织自主机器人(STAR)的创造者在2017年IEEE/RSJ智能机器人和系统国际会议(<a href="https://www.iros2017.org/#" target="_blank" class="ext-link" rel="external "> IROS 2017 </a>)上提交的最新<a href="https://ras.papercept.net/conferences/conferences/IROS17/program/IROS17_ContentListWeb_3.html#tubt12_04" target="_blank" class="ext-link" rel="external ">研究结果中指出的那样，他们的实验表明，他们的机器人系统实际上比执行相同任务的人类外科专家更精确。看一看:</a></p>
<p class="translated">https://youtu.be/9ptlm-O39XA</p>
<p class="translated"><img decoding="async" loading="lazy" class="aligncenter size-full wp-image-3435213" src="../Images/188e3973b229d4bf4f93621395008fe6.png" alt="" data-original-src="https://storage.googleapis.com/cdn.thenewstack.io/media/2017/11/5d18131b-star-robot-surgery-7.jpeg"/></p>
<p class="translated"><img decoding="async" loading="lazy" class="aligncenter size-full wp-image-3435214" src="../Images/c78f785d615cb33ed4bdfe5f9a723de0.png" alt="" data-original-src="https://storage.googleapis.com/cdn.thenewstack.io/media/2017/11/a514d8e7-star-robot-surgery-6.jpg"/></p>
<p class="translated">这项研究使用了三种猪组织，即脂肪、肌肉和皮肤。使用其先进的3D成像系统和近红外(NIR)相机，STAR能够证明它可以在所有三种类型的组织中进行精确的切口，使用研究人员在组织上放置的微型红外标记进行指导。这比看起来要难，因为这些组织的质地不一致，因此会导致电外科切割工具打滑和偏离轨道。</p>
<p class="translated">STAR能够在所有三种组织上很好地完成任务，这要归功于它的仪器，这些仪器配备了传感器，可以精确地测量持续切割不同类型表面所需的力，并不断调整运动和纹理等变量。</p>
<p class="translated"><img decoding="async" loading="lazy" class="aligncenter size-full wp-image-3435215" src="../Images/54a9c42066342bc024a538487868d816.png" alt="" data-original-src="https://storage.googleapis.com/cdn.thenewstack.io/media/2017/11/32d0ce08-star-robot-surgery-5.jpg"/></p>
<p class="translated"><img decoding="async" loading="lazy" class="aligncenter size-full wp-image-3435216" src="../Images/be184a2762e3ecc402c01513f4dd92c6.png" alt="" data-original-src="https://storage.googleapis.com/cdn.thenewstack.io/media/2017/11/d407e379-star-robot-surgery-4.jpg"/></p>
<p class="translated">然后，STAR与人类外科医生展开了同样的切割任务，这次是在猪皮上。第一个练习是剪一条5厘米长的直线。一些外科医生使用不同的手术方法来达到相同的效果(即开腹手术或<a href="https://en.wikipedia.org/wiki/Laparoscopic_surgery" target="_blank" class="ext-link" rel="external ">腹腔镜手术</a>，但总的来说，机器人的切口更接近理想的长度，更少偏离理想的切割线，切口周围受损的肌肉也更少。</p>
<p> </p>
<p class="translated"><img decoding="async" loading="lazy" class="aligncenter size-full wp-image-3435218" src="../Images/b3114636d941bddaa1f8caa6ed9bf2b0.png" alt="" data-original-src="https://storage.googleapis.com/cdn.thenewstack.io/media/2017/11/5a24da5a-star-robot-surgery-2.jpg"/></p>
<p class="translated">实验的下一部分涉及STAR从一片猪脂肪中取出一个用粘土制成的模拟肿瘤。该区域再次用机器人近红外摄像机可见的标记进行了描绘，但为了使这项任务更加困难，在顶部覆盖了一层薄薄的皮肤，试图混淆机器人的视觉跟踪系统。然而，机器人能够以令人印象深刻的精确度进行切割，正如研究人员所设定的那样，在肿瘤周围4毫米的范围内。</p>
<p class="translated"><img decoding="async" loading="lazy" class="aligncenter size-full wp-image-3435219" src="../Images/d46741e05d28721378ec18855dea6c7a.png" alt="" data-original-src="https://storage.googleapis.com/cdn.thenewstack.io/media/2017/11/5b8c001a-star-robot-surgery-1.jpg"/></p>
<h2 class="translated">机器人外科医生</h2>
<p class="translated">“我真的相信这是外科手术的未来，”该研究的合著者、马里兰大学机械工程助理教授Axel Krieger 告诉IEEE Spectrum<a href="https://spectrum.ieee.org/the-human-os/biomedical/devices/in-fleshcutting-task-autonomous-robot-surgeon-beats-human-surgeons" target="_blank" class="ext-link" rel="external "><em/></a>。“我相信这将首先发生在外科手术的小功能上，并变得越来越复杂，类似于自动驾驶汽车，制动辅助等小功能慢慢演变成越来越多的自主功能。我绝对会信任这样的机器人来做我的手术，一旦它得到充分开发和验证。”</p>
<p class="translated">该团队目前正致力于训练STAR系统切除更复杂的肿瘤，例如那些具有更多三维复杂性的肿瘤。</p>
<p class="translated">STAR的精确度将有利于改善手术后的结果，因为以更少的错误进行的更不容易出错的切割转化为患者更短的恢复时间，并且将防止癌性肿瘤重新形成。</p>
<p class="translated">即使机器人外科医生不能完全取代人类医生，机器人辅助手术对人类医生来说也是有好处的，因为它们有助于减轻长时间进行这些精细手术可能给人类外科医生带来的一些身体压力。这些问题包括眼睛疲劳、手、脖子、背部和腿部问题，以及腕管综合症——所有这些都可能导致外科医生犯错或提前退休。</p>
<p class="translated">当进行微创手术时，例如在腹腔镜手术中发现的微创手术时，这些身体劳损的问题甚至更加明显，在腹腔镜手术中，必须进行微小的切口，并且在插入患者体内的小型摄像机和器械的帮助下进行手术。由于他们经常看着视频屏幕进行这些操作，人类外科医生没有在手术过程中有用的直接“动手”经验。对于机器人来说，这不是一个问题，这意味着我们很可能会在未来的手术室里看到更多的自主机器。</p>
<p class="attribution translated">图片:贾斯汀·奥普弗曼和瑞安·德克尔</p>


<div class="tns-logo-slug">
<svg xmlns:xlink="http://www.w3.org/1999/xlink" viewbox="0 0 68 31" version="1.1">
<title>Group</title>
<desc>Created with Sketch.</desc>
<g id="Page-1" stroke="none" stroke-width="1" fill="none" fill-rule="evenodd">
<g id="Group">
<path d="M24.002,29.619 L29.77,29.619 L29.77,15.808 C29.77,15.038 29.622,11.265 29.59,10.414 L29.77,10.414 C31.424,14.019 31.473,14.147 32.168,15.322 L39.65,29.618 L44.845,29.618 L44.845,0 L39.075,0 L39.075,11.064 C39.075,12.197 39.075,12.44 39.182,14.472 L39.325,17.468 L39.151,17.468 C39.034,17.267 38.596,16.173 38.467,15.929 C38.164,15.323 37.725,14.512 37.373,13.905 L30.031,0 L24,0 L24,29.619 L24.002,29.619 Z" id="Path-Copy" fill="#FF3287"/>
<path d="M56.948,0 C50.745,0 47.606,3.43 47.606,8.296 C47.606,14.114 51.036,15.404 55.518,17.132 C60.438,18.853 61.782,19.332 61.782,21.539 C61.782,24.225 58.969,24.867 57.401,24.867 C54.579,24.867 52.493,23.342 51.536,20.858 L47,24.185 C49.43,28.937 52.145,30.185 57.713,30.185 C59.364,30.185 62.059,29.74 63.727,28.694 C67.779,26.156 67.779,22.22 67.779,20.898 C67.779,18.129 66.531,16.207 66.178,15.726 C65.049,14.121 63.032,12.918 61.25,12.278 L57.084,10.914 C55.073,10.267 52.928,10.105 52.928,8.019 C52.928,7.707 53.008,5.528 56.288,5.319 L61.465,5.319 L61.465,0 C61.465,0 57.342,0 56.948,0 Z" id="Path-Copy-2" fill="#00AFF4"/>
<polygon id="Path" fill="#00AFF4" points="5.32907052e-15 1.77635684e-15 5.32907052e-15 5.319 7.572 5.319 7.572 29.564 14.132 29.564 14.132 5.319 21.544 5.319 21.544 1.77635684e-15"/>
</g>
</g>
</svg> </div>
</div>
</div>    
</body>
</html>