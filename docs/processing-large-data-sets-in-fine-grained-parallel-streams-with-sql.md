# 用 SQL 处理细粒度并行流中的大型数据集

> 原文：<https://thenewstack.io/processing-large-data-sets-in-fine-grained-parallel-streams-with-sql/>

SQL 被广泛用作数据访问语言，Trino 为 SQL 访问多个数据源提供了强大的引擎。然而，随着越来越多的实时数据变得可用，开发人员将需要以可预测的性能处理无限规模的大型数据集。

Aerospike Trino 连接器利用特定的 Aerospike 机制通过并行流访问大型数据集。它与 Trino 的分布式计算框架及其基于成本的优化器(CBO)一起工作，以定义数据分割、下推查询操作并利用适当的索引。结果是更快地获得洞察力，从而加快决策和业务成果。

本文解释了通过并行流访问大型数据集的机制，并描述了一些为并行处理定义[数据分割](https://thenewstack.io/aerospike-database-6-secondary-index-queries-json-and-more/)的方案，以及测试它们的框架。

请跟随[附属互动教程](https://developer.aerospike.com/tutorials/java/query_splits)。

## 大型数据集的并行处理

为了处理大型数据集，一种常见的方案是将数据划分为多个分区，并分配一个工作任务来处理每个分区。分区方案必须具有以下属性:

*   分区总体上是详尽的，这意味着它们覆盖整个数据集，并且是互斥的，这意味着它们不重叠。
*   它们是确定而有效地计算出来的。
*   根据工作任务的需要，可以以高效灵活的方式访问它们，例如，一次访问较小的块。

## Aerospike 中的数据分区

三种类型的[气塞式索引](https://docs.aerospike.com/server/operations/manage/indexes)——初级、集合和次级——是面向分区的。这意味着它们在每个节点上被分区分割，查询在每个节点上通过单独的分区进行处理。客户端可以请求在特定分区上处理查询，以便多个客户端工作人员可以并行工作。很容易看出如何为并行处理数据流建立多达分区总数(4，096)的[并行流](https://thenewstack.io/accelerating-sql-queries-on-a-modern-real-time-database/)。

【Aerospike 查询支持分页，客户端可以通过重复请求一定数量的记录，一次处理一大块记录，直到检索到所有记录。

## 拆分超过 4，096 的数据集

许多数据处理平台允许超过 4，096 的工作任务。例如， [Spark](https://developer.aerospike.com/tutorials/spark-conn) 允许最多 32K 个工人任务并行运行。 [Trino](https://developer.aerospike.com/blog/aerospike-trino-connector-chapter-two) 允许理论并发数大于 4096。

Aerospike 允许将一个分区有效地划分为多个子分区，从而支持大于 4，096 的数据拆分。该方案基于“摘要取模”函数，该函数可以将一个分区划分为任意数量的不重叠且共同完整的子分区。它包括添加过滤器表达式“digest % N == i for 0 <= i < N”，其中“digest”是记录的散列键。

“摘要-模”函数的优势在于，它可以在不从存储设备(如 SSD)读取单个记录的情况下进行评估。所有记录的摘要保存在内存中的主索引中。因此，确定子分区中摘要的成员资格，以及相应记录的成员资格是很快的。每个子分区流只需要从可能较慢的存储设备中读取它的记录，尽管它需要对所有记录执行更快的内存中摘要模评估。

该方案适用于主索引和集索引查询，因为它们保存记录的摘要。辅助索引保存记录的主索引位置，查找提供摘要信息。

## 定义和分配拆分

如何定义数据集上的分割并将其分配给 N 个工作任务，其中 N 可以从 1 变化到任意大的数？实际上，在给定的平台上，N 会有一个上限，因为平台定义的绝对限制，或者处理大量并行流并在它们之间进行协调的开销会抵消这些好处。

理解在单个 Aerospike API 调用中可以请求哪些分区或子分区是很重要的:

1.  完整分区和子分区不能在一个调用中混合。
2.  完整分区必须按顺序连续，或者为“(pstart-id，pcount)”。
3.  子分区必须是连续的，属于连续的分区，并使用相同的模因子，或“(pstart-id，pcount，sstart-id，scount，m)”。

目标是利用 API 中可用的操作实现最佳效率。

## 拆分分配方案

我们将考察三种不同的分割作业。

如果 N 是请求的拆分数量:

1.  最多 N 个拆分(可以更少)，大小相同，每个拆分一个 API 调用。
2.  至少 N 个拆分(可以更多)，大小相同，每个拆分一个 API 调用。
3.  正好 N 次拆分，大小相同，每次拆分最多三次 API 调用。

前两个选项允许特定的离散拆分值来分配相同数量的数据(作为分区或子分区),并选择最接近的允许拆分数，即 4，096 的倍数。每个分割都用一个 API 调用来处理。

第三种方法允许任意数量的分割，分区和/或子分区的数据分配大小相同。然而，每次拆分可能需要多达三次 API 调用。

## 并行查询框架

可以使用下面的简单框架来测试来自上述分割任务的并行流处理。可以对其进行调整，以适应预期工作负载和环境的需求。

测试数据由大约 1KB 大小的 100，000 条记录(可以更改)组成，在整数 bin 上定义了一个二级索引。

## 处理流程

处理过程如下(可调参数为*斜体*):

*   根据请求的*分割数量*和期望的*分割类型*进行分割分配。
*   创建所需数量的*工作线程*(线程)。所有员工同时开始处理拆分。每个工作线程循环执行以下操作，直到没有未处理的拆分可用:
    *   获得*下一个预定的*分割。
    *   在拆分的分区和子分区上创建一个或多个查询请求，并按顺序处理它们。
    *   根据请求的查询类型分配*二级索引查询谓词*。
    *   创建请求的*过滤器表达式*。如果正在使用子分区筛选器表达式，则将它(用 AND)附加到该表达式中；否则，单独使用。
    *   以请求的*模式*(同步或异步)用过滤器处理查询。
    *   一次获取*个块大小*的记录，直到所有记录都被检索到。
    *   使用*流处理实现来处理记录。*CountAndSum 实现:

*   按工作线程合计计数中的记录数。
*   由工作线程在总和中聚合整数 bin 值。
*   最后，对所有员工进行总计和求和。
*   等待所有工作线程完成，并输出流处理的聚合结果。

在 CountAndSum 示例中，对于给定的查询谓词和筛选器，已处理记录的总数和所有记录的整数 bin 的总和必须相同，而不管拆分数量、拆分类型、工作线程数量和处理模式。

## 参数和变化

这需要大量的操作，包括拆分数量、工作线程数量、查询索引类型等等。请跟随[附属互动教程](https://developer.aerospike.com/tutorials/java/query_splits)深入了解。

## 细粒度并行的用例

对于通过转换、聚合和更新处理的非常大的数据集，处理速度可以受益于非常高的并行度。

需要连接的多个数据集以及需要在大量工作节点上混洗子集的数据集可能无法从非常高的检索并行性中受益。在后续步骤中跨大量工作节点传输数据的成本会限制细粒度检索的优势。处理平台上基于成本的优化器应该能够为给定查询确定 Aerospike 数据访问的最佳并行级别。

<svg xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 0 68 31" version="1.1"><title>Group</title> <desc>Created with Sketch.</desc></svg>