<html>
<head>
<title>Meet the Neural Network AI You Can Train Easily — Like a Dog</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">认识一下你可以像训练狗一样轻松训练的神经网络人工智能</h1>
<blockquote>原文：<a href="https://thenewstack.io/meet-neural-network-ai-can-train-easily-like-dog/#0001-01-01">https://thenewstack.io/meet-neural-network-ai-can-train-easily-like-dog/#0001-01-01</a></blockquote><div><div id="tns-post-body-content">


<p class="translated">对于大多数普通人来说,“人工智能”这个词可能会让他们联想到聪明人用代码做复杂、神秘的事情的画面，这些代码将帮助机器做神奇的事情——比如准确地诊断疾病，加速T2发现新的救命药物，或者T4在人类自己的游戏中打败人类。因此，对于许多没有技术诀窍的人来说，训练一个人工智能的想法似乎相当复杂，遥不可及。</p>
<p class="translated">为了对抗这种假设，阿姆斯特丹的设计师<a href="http://bjoernkarmann.dk/objectifier" class="ext-link" rel="external ">比约恩·卡门</a>创造了<a href="https://bjoernkarmann.dk/objectifier" target="_blank" rel="noopener noreferrer external " class="ext-link">对象化器</a>，这是一种人工智能界面，任何人都可以轻松训练它执行简单的任务，比如用手势开关灯。为此，它配备了一个用计算机视觉技术增强的摄像头和一个简单的神经网络。</p>
<p class="translated">用户可以用他们想要的任何手势训练系统，使用移动应用程序界面将某个动作与某个结果关联起来。比如说。当一本书合上，或者一只手掌向前推时，系统可以通过编程做出反应，从而关闭灯或音乐播放器。观看这段有趣的视频，它展示了普通市民训练物化者的过程:</p>
<p/>
<p class="translated">这里的总体概念是改变人们与人工智能的暧昧关系。为了证明训练一个人不一定需要很多知识。</p>
<p class="translated">卡门在他的网站上说:“客体化者使人们能够在日常环境中训练物体对他们独特的行为做出反应。”。“它给人一种训练人工智能的体验；从一个被动的消费者转变为一个积极的、顽皮的国内技术指导者。有了计算机视觉和神经网络，复杂的行为与你的命令联系在一起。例如，你可能想打开收音机，播放你最喜欢的舞步。将您的无线电连接到Objectifier，并使用训练应用程序显示无线电应在何时打开。”</p>
<div id="attachment_2438992" class="wp-caption aligncenter"><img aria-describedby="caption-attachment-2438992" decoding="async" loading="lazy" class="wp-image-2438992 size-full" src="../Images/d163217a97ec3cb80b244b3fbef9d910.png" alt="" data-original-src="https://cdn.thenewstack.io/media/2017/06/3381a372-objectifier-bjoern-karmann-2.jpg"/><p id="caption-attachment-2438992" class="wp-caption-text translated">从左到右:开发Objectifier的原型化过程的不同阶段——左边是最新版本。</p></div>
<p class="translated"><img decoding="async" loading="lazy" class="aligncenter size-full wp-image-2438993" src="../Images/a99dd99c04b10efa718d6b66a9b345fd.png" alt="" data-original-src="https://cdn.thenewstack.io/media/2017/06/de1a761b-objectifier-bjoern-karmann-3.jpg"/></p>
<h2 class="translated">训狗人工智能</h2>
<p class="translated">为了强调这一点，卡门进一步简化了这一点，故意在客体化者和训练狗遵循简单命令之间画了一个平行线。它可能不会每次都做对，但它有能力学习。“与Objectifier互动很像训练一只狗——你只教它你想让它关心的东西，”卡门解释说。"就像狗一样，它能看到并理解周围的环境."</p>
<p class="translated">卡门的类比部分是受《连线》杂志最近的一篇文章的启发，这篇文章指出了计算领域最近的范式转变，这是由深度神经网络在各种应用中的日益增长的使用带来的。这些分布式计算系统功能强大，能够学习，但并不总是清楚<em/>这究竟是如何发生的——就像我们人类尚未完全理解大脑中的底层机制，以及认知、学习和意识本身背后的过程一样。因此，为了自己对这一类比的研究，卡门与专业训狗师进行了交谈，以了解训练一只狗实际需要什么。</p>
<div class="span4 masonry-item remove-gutter-">
<div class="mc-sub-content-container">
<div class="wysiwyg-ce ">
<p class="translated">“观察训练技术、工具和互动揭示了一个充满灵感和与机器学习相似之处的世界，”卡门写道。“狗类比的强大之处在于，每个人都可以在没有任何编程知识的情况下理解这项复杂技术的工作原理。”</p>
</div>
</div>
</div>
<p class="translated">就像训练一只狗(或一个婴儿人类)一样，我们不需要知道大脑是如何工作的来训练它。在这种情况下，对象化器使用<a href="https://thenewstack.io/reinforcement-learning-ready-real-world/" target="_blank" class="local-link">强化学习</a>(一种人工智能训练技术)来根据它从其环境中接收到的信息采取行动，但用户决定哪些信息实际上是相关的。例如，正如我们在上面的视频中看到的，一个关心晚上在某盏灯下看书的用户会把客体化器连接到那盏灯上。为了训练它打开它，他们会打开灯，选择一个手势或动作——也许是打开一本书的封面——并在物化者的相机前执行它，同时按下移动应用程序界面上的“1”按钮。要关灯，他们合上书，按“0”键，客体化者就会知道把合上书皮和关灯联系起来。所有这些都可以在一分钟内完成。</p>
<div id="attachment_2438990" class="wp-caption aligncenter"><img aria-describedby="caption-attachment-2438990" decoding="async" loading="lazy" class="wp-image-2438990 size-full" src="../Images/b899e4e67489a7ab0015e6b5dffa0782.png" alt="" data-original-src="https://cdn.thenewstack.io/media/2017/06/ad07aeca-objectifier-bjoern-karmann-4.jpg"/><p id="caption-attachment-2438990" class="wp-caption-text translated">客体化者的移动应用程序界面如何工作，以及如何训练系统将一个手势或事件与“打开”或“关闭”某个东西相关联。</p></div>
<p class="translated"><img decoding="async" loading="lazy" class="aligncenter size-full wp-image-2438989" src="../Images/da90a65195b7bb72e38366e166fa7dc2.png" alt="" data-original-src="https://cdn.thenewstack.io/media/2017/06/f1e84f4c-objectifier-bjoern-karmann-5.jpg"/></p>
<div id="attachment_2438985" class="wp-caption aligncenter"><img aria-describedby="caption-attachment-2438985" decoding="async" loading="lazy" class="wp-image-2438985 size-full" src="../Images/75c1f5d61da69277b04c67eddfcd2523.png" alt="" data-original-src="https://cdn.thenewstack.io/media/2017/06/e669c584-objectifier-bjoern-karmann-8.jpg"/><p id="caption-attachment-2438985" class="wp-caption-text translated">训练客体化者在书打开时开灯，在书合上时关灯。</p></div>
<p class="translated">目前，这个对象化器的当前版本只是一个原型，但它已经获得了来自<a href="https://www.google.com/" target="_blank" rel="noopener noreferrer external " class="ext-link">谷歌I/O实验挑战赛</a>的奖项。卡门现在正致力于改进它，以便它可以做更复杂的事情，而不仅仅是这些二进制的“开”和“关”状态，并给它添加一个音频接口，这样用户就可以通过发出语音命令来训练它。Karmann的目标是继续将Objectifier作为一个开源项目(基于<a href="http://ml4a.github.io/guides/ConvnetClassifier/" target="_blank" rel="noopener noreferrer external " class="ext-link">ConvnetClassifier</a><a href="http://www.openframeworks.cc/" class="ext-link" rel="external ">open frameworks</a>应用程序)来生产，以便任何想要并获得激光切割机和3D打印机的人都可以构建自己的产品。</p>
<p class="translated">这是一种非常简单但有效的方式，让人们可以亲身体验人工智能的训练。所有繁重的代码提升都是由应用程序本身完成的，但即使是非专家也会直观地理解这个过程是多么的简单。毕竟，人工智能的初级形式已经围绕着我们——在我们的智能手机和数字助理如Siri、Cortana和Alexa中，或者在推荐引擎如网飞和亚马逊等支撑服务的引擎中。人工智能在我们生活中日益增长和无处不在的作用似乎是我们理所当然的事情，但在深层次上，我们许多人对此感到不安，解决其中的原因很重要。因此，随着人工智能继续渗透到我们的生活中，这项技术去神秘化是至关重要的，对于我们人类来说，理解人工智能不会咬人——如果它训练有素的话。</p>
<p class="attribution translated">图片:比约恩·卡门</p>


<div class="tns-logo-slug">
<svg xmlns:xlink="http://www.w3.org/1999/xlink" viewbox="0 0 68 31" version="1.1">
<title>Group</title>
<desc>Created with Sketch.</desc>
<g id="Page-1" stroke="none" stroke-width="1" fill="none" fill-rule="evenodd">
<g id="Group">
<path d="M24.002,29.619 L29.77,29.619 L29.77,15.808 C29.77,15.038 29.622,11.265 29.59,10.414 L29.77,10.414 C31.424,14.019 31.473,14.147 32.168,15.322 L39.65,29.618 L44.845,29.618 L44.845,0 L39.075,0 L39.075,11.064 C39.075,12.197 39.075,12.44 39.182,14.472 L39.325,17.468 L39.151,17.468 C39.034,17.267 38.596,16.173 38.467,15.929 C38.164,15.323 37.725,14.512 37.373,13.905 L30.031,0 L24,0 L24,29.619 L24.002,29.619 Z" id="Path-Copy" fill="#FF3287"/>
<path d="M56.948,0 C50.745,0 47.606,3.43 47.606,8.296 C47.606,14.114 51.036,15.404 55.518,17.132 C60.438,18.853 61.782,19.332 61.782,21.539 C61.782,24.225 58.969,24.867 57.401,24.867 C54.579,24.867 52.493,23.342 51.536,20.858 L47,24.185 C49.43,28.937 52.145,30.185 57.713,30.185 C59.364,30.185 62.059,29.74 63.727,28.694 C67.779,26.156 67.779,22.22 67.779,20.898 C67.779,18.129 66.531,16.207 66.178,15.726 C65.049,14.121 63.032,12.918 61.25,12.278 L57.084,10.914 C55.073,10.267 52.928,10.105 52.928,8.019 C52.928,7.707 53.008,5.528 56.288,5.319 L61.465,5.319 L61.465,0 C61.465,0 57.342,0 56.948,0 Z" id="Path-Copy-2" fill="#00AFF4"/>
<polygon id="Path" fill="#00AFF4" points="5.32907052e-15 1.77635684e-15 5.32907052e-15 5.319 7.572 5.319 7.572 29.564 14.132 29.564 14.132 5.319 21.544 5.319 21.544 1.77635684e-15"/>
</g>
</g>
</svg> </div>
</div>
</div>    
</body>
</html>