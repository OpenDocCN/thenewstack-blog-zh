# 国会和 AI

> 原文：<https://thenewstack.io/congress-and-ai/>

在制定技术相关法律方面，国会从来都不是最快的。现在，即使 AI 接管了创造性的写作和艺术，[国会](https://thenewstack.io/chip-maker-ceos-frustrated-as-52-billion-chip-bill-stalls/)继续无所事事。

随着立法者努力理解生成性人工智能程序，如[微软 Bing](https://blogs.microsoft.com/blog/2023/02/07/reinventing-search-with-a-new-ai-powered-microsoft-bing-and-edge-your-copilot-for-the-web/) 、 [ChatGPT](https://openai.com/blog/chatgpt) 和[谷歌 Bard](https://blog.google/technology/ai/bard-google-ai-search-updates/) ，一些更注重技术的立法者担心国会在应对上一次主要技术浪潮——社交媒体——方面的毫无准备会重演。然而，担忧似乎不会导致行动。

的确，现在有人强烈反对让科技公司与华盛顿保持一定距离，承诺在隐私保护、儿童安全、虚假信息、[加密货币](https://thenewstack.io/why-art-could-become-currency-in-a-cryptocurrency-world/)和[数据可移植性](https://thenewstack.io/the-4-definitions-of-multicloud-part-1-data-portability/)等关键问题上进行“自我监管”。但是严厉的话意义不大。

例如，乔·拜登总统认为，在新的技术浪潮开始时，应该建立一个有效的监管框架，以鼓励科技公司生产内置消费者保护功能的产品，而不是事后诸葛亮。但是，两党呼吁监管技术似乎毫无进展。

## 算法问责制

以 2022 年的[s . 3572——算法问责法案为例。根据该法案的主要作者，参议员罗恩·怀登的说法。)，是为软件、](https://www.congress.gov/bill/117th-congress/senate-bill/3572)[算法](https://thenewstack.io/the-power-of-graph-algorithms/)和其他自动化系统带来新的透明度和监督，这些系统被用来对美国人生活的几乎每个方面做出关键决策。

怀登说，“如果有人因为你的肤色而决定不租给你房子，那就是彻头彻尾的非法歧视。使用导致歧视和偏见的有缺陷的算法或软件同样不好。我们的法案将揭开秘密算法的帷幕，这些算法可以决定美国人是否可以去看医生、租房子或进入学校。”

听起来不错，不是吗？它将要求科技公司向美国联邦贸易委员会提交“自动化决策系统和增强关键决策流程的影响评估”。然而，它从未在 2022 年离开委员会，甚至没有被重新引入 2023 年的国会。

## 由 ChatGPT 撰写

最近，在一月份，国会议员特德·刘(D-Cal。)提交了一份简短的决议，由 [ChatGPT](https://thenewstack.io/just-out-of-the-box-chatgpt-causing-waves-of-talk-concern/) 撰写，指示众议院对生成性人工智能技术进行广泛的研究，“以保证人工智能的开发和部署是安全的，符合道德的，并尊重所有美国人的权利和隐私。”但是，这份不具约束力的决议没有规定任何事情。这只是一个写进[国会记录](https://www.congress.gov/congressional-record)的担忧。

真正的问题，解释代表[杰伊 Obernolte](https://obernolte.house.gov/) (R-Cal。)在《纽约时报》的中，大多数立法者对人工智能完全一无所知。拥有人工智能硕士学位的 Obernolte 继续说道，“在监管之前，需要就危险是什么达成一致，这需要对人工智能是什么有深刻的理解。你会惊讶我花了多少时间向我的同事解释人工智能的主要危险不是来自眼睛里射出红色激光的邪恶机器人。

哈。我是一名科技记者，一点也不会感到惊讶。我仍然在向人们解释“密码”不是一个好的密码。人工智能在目前的发展状态下有多危险，远远超出了大多数人的概念。

例如，技术专家兼隐私专家亚历山大·汉夫(Alexander Hanff)尝试用 ChatGPT 回答了一个非常流行的问题:“我是谁？”或者，在这种情况下，“谁是亚历山大·汉弗？”像许多这样的问题一样，它有些地方对，有些地方错。ChatGPT，我想我们大多数人都知道，有一个编造事情的坏习惯。

然而，这一次，查塔普遭遇了非常黑暗的转折。它坚持说汉弗已经死了。不仅如此，它甚至编造了一个虚假的链接到[卫报](https://www.theguardian.com/us)作为他已经死亡的“证据”。

现在想象一下，如果你愿意，一家银行依靠 ChatGPT 或 Bing 来检查某人的抵押申请。由于每个人都坚持认为你可以依赖 ChatGPT，我可以很容易地看到这种情况发生。但是，如果 ChatGPT“认为”你已经死了，那你的抵押贷款就结束了，你可能会发现在你报告信用欺诈时会遇到更多的麻烦。

就人工智能今天的状态而言，我们距离能够信任它还有很长的路要走。的确，从技术上来说， [ChatGPT 只是一个大型语言模型](https://www.pbs.org/newshour/science/analysis-chatgpt-is-great-at-what-its-designed-to-do-youre-just-using-it-wrong)。当我们问事实问题时，我们真的不能指望准确。但是，这正是我们正在做的。有人需要监控和管理人工智能，这样它的危险就不会压倒它的优势。不会是政府。

此时，我不知道会是谁。鉴于大型科技公司自我监管的历史记录，我也没有看到世界上的谷歌和微软会这样做。我只知道，随着我们向前发展，我们都应该非常谨慎地信任人工智能，无论是做学校论文，还是决定乔或金妮是否应该在药物试验中使用真正的药物或安慰剂。

<svg xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 0 68 31" version="1.1"><title>Group</title> <desc>Created with Sketch.</desc></svg>