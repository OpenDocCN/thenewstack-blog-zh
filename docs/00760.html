<html>
<head>
<title>Deep Learning AI Detects Rare Genetic Disorders by Scanning Faces</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">深度学习人工智能通过扫描面部检测罕见的遗传疾病</h1>
<blockquote>原文：<a href="https://thenewstack.io/deep-learning-ai-detects-rare-genetic-disorders-by-scanning-faces/#0001-01-01">https://thenewstack.io/deep-learning-ai-detects-rare-genetic-disorders-by-scanning-faces/#0001-01-01</a></blockquote><div><div id="tns-post-body-content">


<p class="translated">毫无疑问，人工智能工具将彻底改变医疗保健——它已经在这样做了，帮助人类医疗保健从业者<a href="https://thenewstack.io/deep-learning-algorithm-diagnoses-skin-cancer-better-human-dermatologists/" target="_blank" class="local-link">更容易地诊断皮肤癌</a>，<a href="https://thenewstack.io/decagon-ai-predicts-new-and-dangerous-drug-interactions/" target="_blank" class="local-link">发现新的和意想不到的药物相互作用</a>，以及帮助科学家解开复杂的<a href="https://thenewstack.io/deepmind-ai-makes-breakthrough-with-protein-folding-problem/" target="_blank" class="local-link">蛋白质折叠问题</a>。</p>
<p class="translated">现在，美国公司<a href="https://www.fdna.com/" target="_blank" class="ext-link" rel="external "> FDNA </a>最近完成的一项研究表明，在不远的将来，在面部识别算法的帮助下，人工智能也可能有助于诊断罕见的遗传疾病。</p>
<p class="translated">根据该团队最近发表在《自然医学》杂志上的<a href="https://arxiv.org/pdf/1801.07637.pdf" target="_blank" class="ext-link" rel="external ">研究论文</a>，该团队的人工智能辅助诊断工具可以帮助早期检测罕见的遗传疾病，并为更个性化的医疗保健形式铺平道路，即所谓的<a href="https://en.wikipedia.org/wiki/Precision_medicine" target="_blank" class="ext-link" rel="external ">精确医疗</a>。</p>
<h2 class="translated">泄露秘密的面部特征</h2>
<p class="translated">这项技术被称为DeepGestalt，它结合了计算机视觉和深度学习算法，这些算法已经用来自26，000多幅患者图像的数据进行了训练，呈现了200多种遗传条件。这些数据大多是通过他们的应用程序<a href="https://www.face2gene.com/" target="_blank" class="ext-link" rel="external "> Face2Gene </a>收集的，该应用程序使用类似的面部识别和深度学习技术来识别往往与罕见遗传综合征相关的泄露秘密的面部特征。</p>
<p class="translated">例如，患有科妮莉亚·德朗综合征的人通常会有长而粗的眉毛，小鼻子，薄上唇和下翻的嘴巴。这些特征可以由人类专家挑选出来，但问题是，人们可能在最初症状出现多年后才最终看到遗传专家，即使这样，找到正确的诊断也不会便宜或迅速。最重要的是，个别人类遗传专家可能不一定对所有罕见和模糊的遗传状况有丰富的经验，因此给出错误的诊断。因此，像DeepGestalt这样的面部分析框架将是临床医生在早期准确检测这些疾病的宝贵工具，因为早期诊断有助于防止患者后来出现发育迟缓或潜在的健康问题。</p>
<p class="translated">为了提高诊断率，DeepGestalt使用深度卷积神经网络(DCNNs)进行操作，这有助于解决患者输入照片中面部大小、背景、表情和光照的差异。该软件首先利用以130个面部标志为目标的标志检测算法来预处理图像。在预处理之后，图像被裁剪成“面部区域”，每个面部区域被送入DCNNs以执行遗传综合征分类任务，然后被汇总并与数据库进行比较，以得出遗传综合征预测的排序列表。</p>
<p class="translated">研究人员解释说:“每个区域的特定DCNN分别做出预测，然后通过对结果进行平均来组合这些预测，并为多类问题产生一个强大的格式塔模型。”在实际临床使用时，通过所描述的流水线来处理在训练期间未被使用的患者图像。输出向量是相似性得分的排序向量，指示患者的照片与模型中支持的每个综合征的相关性。”</p>
<p class="translated"><img decoding="async" loading="lazy" class="aligncenter size-full wp-image-6547170" src="../Images/76f9e99faafb19ff83d6bc8b8065b417.png" alt="" data-original-src="https://cdn.thenewstack.io/media/2019/01/bb97474b-deepgestalt-fdna-1.jpg"/></p>
<p class="translated">毫不奇怪，在这些分类任务中，DeepGestalt比它的人类同行做得好得多。在该团队对502张显示92种不同遗传疾病患者的图像进行测试期间，该软件在确定症状方面的准确率超过90%，而人类临床医生的准确率为70%。为了了解该算法在可用训练数据较少的情况下如何表现，该团队进行了单独的测试，以解决更难检测的<a href="https://en.wikipedia.org/wiki/Noonan_syndrome" target="_blank" class="ext-link" rel="external ">努南综合征</a>，并发现它的准确率较低，为64%，仍优于人类专家。</p>
<p class="translated">该团队目前正致力于将DeepGestalt框架与基因组测序数据相结合，以提高<a href="https://en.wikipedia.org/wiki/Molecular_diagnostics" target="_blank" class="ext-link" rel="external ">分子诊断</a>的准确性，从而拓展个性化、精准医疗领域。当然，就目前而言，这里的想法不是在过程中取代人类，而是将这样的工具集成到诊断程序中，以提高检测率并改善总体结果。此外，该软件并不能取代实际的基因测试，后者可以提供更多关于这些综合征背后特定基因突变的信息。然而，增加这样的工具无疑会给寻找答案的家庭带来一线希望。</p>
<p id="Ihz7OG" class="translated">要了解更多，请阅读<a href="https://arxiv.org/pdf/1801.07637.pdf" target="_blank" class="ext-link" rel="external ">的论文</a>。</p>


<div class="tns-logo-slug">
<svg xmlns:xlink="http://www.w3.org/1999/xlink" viewbox="0 0 68 31" version="1.1">
<title>Group</title>
<desc>Created with Sketch.</desc>
<g id="Page-1" stroke="none" stroke-width="1" fill="none" fill-rule="evenodd">
<g id="Group">
<path d="M24.002,29.619 L29.77,29.619 L29.77,15.808 C29.77,15.038 29.622,11.265 29.59,10.414 L29.77,10.414 C31.424,14.019 31.473,14.147 32.168,15.322 L39.65,29.618 L44.845,29.618 L44.845,0 L39.075,0 L39.075,11.064 C39.075,12.197 39.075,12.44 39.182,14.472 L39.325,17.468 L39.151,17.468 C39.034,17.267 38.596,16.173 38.467,15.929 C38.164,15.323 37.725,14.512 37.373,13.905 L30.031,0 L24,0 L24,29.619 L24.002,29.619 Z" id="Path-Copy" fill="#FF3287"/>
<path d="M56.948,0 C50.745,0 47.606,3.43 47.606,8.296 C47.606,14.114 51.036,15.404 55.518,17.132 C60.438,18.853 61.782,19.332 61.782,21.539 C61.782,24.225 58.969,24.867 57.401,24.867 C54.579,24.867 52.493,23.342 51.536,20.858 L47,24.185 C49.43,28.937 52.145,30.185 57.713,30.185 C59.364,30.185 62.059,29.74 63.727,28.694 C67.779,26.156 67.779,22.22 67.779,20.898 C67.779,18.129 66.531,16.207 66.178,15.726 C65.049,14.121 63.032,12.918 61.25,12.278 L57.084,10.914 C55.073,10.267 52.928,10.105 52.928,8.019 C52.928,7.707 53.008,5.528 56.288,5.319 L61.465,5.319 L61.465,0 C61.465,0 57.342,0 56.948,0 Z" id="Path-Copy-2" fill="#00AFF4"/>
<polygon id="Path" fill="#00AFF4" points="5.32907052e-15 1.77635684e-15 5.32907052e-15 5.319 7.572 5.319 7.572 29.564 14.132 29.564 14.132 5.319 21.544 5.319 21.544 1.77635684e-15"/>
</g>
</g>
</svg> </div>
</div>
</div>    
</body>
</html>