# 在混合工作负载环境中实现云原生 HPC 功能

> 原文：<https://thenewstack.io/achieving-cloud-native-hpc-capabilities-mixed-workload-environment/>

## 不断发展的企业高性能工作负载

随着传统工作负载和深度学习等新应用之间的界限变得模糊，容器也成为企业 HPC 中的一个热门话题。毫不奇怪，就像他们的互联网同事部署云规模的服务一样，HPC 架构师看到了云原生方法的价值。在集群流行之前，HPC 开发人员就一直在构建分布式应用，开源是他们的天性，他们也欣赏并行性、弹性和水平扩展的优雅。虽然术语 CI/CD 并不源自 HPC，但一些 HCP 管理员面临着与他们的 DevOps 同事相同的挑战，需要快速可靠地部署新功能。

## 采用的障碍

那么，为什么我们没有看到大规模向云的迁移，以及用库本内特 YAML 模板表示的容器化 HPC 应用的广泛使用呢？通常情况下，答案是复杂的。

 [罗布·拉隆德

Navops 副总裁兼总经理:Rob Lalonde 拥有超过 25 年的行政管理经验，领导 Univa 加速增长并进入新市场。Rob 曾在多家成功的高科技公司和初创企业中担任高管职位。他拥有独特的多学科技能，曾在销售、营销、业务开发、首席执行官和董事会任职。Rob 在约克大学 Schulich 商学院完成了 MBA 学习，并拥有劳伦森大学的计算机科学学位。](http://www.univa.com/) 

有几个问题，但我们在下面更详细地探讨两个。

*   在认证和可信应用程序工作流方面的重大投资。
*   与工作量管理相关的技术考虑。

在企业对 HPC 进行了数十年的投资之后，现在已经有了数以千计经过充分锻炼的数学库和特定领域的应用程序。从线性代数到微分方程例程，再到车辆碰撞模拟中使用的显式并行解算器，它们构成了行业垂直领域的创新核心，因此是企业 HPC 架构的必备部分。

与应用程序本身一样，几十年来一直在改进工作负载管理器，以解决重复出现的工作负载模式。这些模式包括交互式作业、MPI 并行作业、多步工作流和参数扫描。特别是在时间就是金钱的企业 HPC 环境中，用户依靠分层资源共享、拓扑感知调度、回填调度和基于策略的抢占等功能来最大限度地平衡昂贵资源的利用率和可能会降低吞吐量的业务优先级。有趣的是，人工智能(AI)中的新工作负载越来越依赖于 GPU 的计算能力，更快地执行训练神经网络所需的矩阵运算。无论这些工作负载是存在于容器、虚拟机中还是在裸机上运行，它们都依赖于 HPC 中首创的技术来将 GPU 作为可调度、可消耗的资源进行管理。

## 进化与革命

尽管障碍重重，变革正在酝酿之中。越来越多的用户正在利用公共云资源并采用容器化来实现新的服务交付模式。虽然现在还为时尚早，但对于新的工作负载，一些用户正怀着“革命性”的心情寻求通过采用云原生方法来解决问题。随着 Kubernetes 在云中变得无处不在——GKE、AKS、EKS 等。—这一观点正在慢慢形成势头。

其他人更务实，从“进化”的角度思考——保持应用程序原样，但使用容器来使应用程序更容易共享，更易于跨云移植，并在规划其向云原生计算发展的过程中提高资源效率。

## 管理共存是关键

随着企业 HPC 用户尝试新的云原生软件，需要集成现有的应用程序。最后一件事是首席信息官，甚至首席财务官！—希望为 HPC 应用程序、Kubernetes 应用程序和 Hadoop MapReduce 或 Spark 工作负载提供独立的复制集群。复制环境阻碍了资源共享，并导致基础架构和管理成本飙升。

为了解决这个问题，我们看到客户采用两种不同的方法来实现共存。

*   第一种方法是在现有 HPC 集群上运行容器化和非容器化工作负载。HPC 工作负载管理器越来越支持容器化应用，同时保留面向 HPC 的调度语义。这种方法支持容器，但不支持本地 Kubernetes 应用程序所需的软件服务。
*   第二种方法是设计在本地或驻留云的 Kubernetes 集群上运行 HPC 工作负载的方法。虽然不太常见，但这种解决方案现在是可行的，并且随着本地 Kubernetes 应用程序数量的增长，这种解决方案可能会变得更加常见。

使用第二种多租户策略的站点的一个很好的例子是[健康度量和评估研究所](https://navops.io/ihme-case-study.html) (IHME)，这是华盛顿大学的一个领先的独立健康研究中心，拥有世界上最大的人口健康数据库。IHME 为各种统计建模应用运行了一个重要的高性能计算环境，并且还为微服务应用采用了 Kubernetes。使用包括 [Navops Command](https://www.navops.io/command.html) (用于资源管理和多租户)和 [Univa Grid Engine](https://www.univa.com/products/) (用于工作负载管理和调度)在内的软件解决方案，可以调度现有 HPC 应用在 Univa Grid Engine 内部作为服务透明运行，同时使用 Kubernetes 作为底层基础。这种方法允许传统的 HPC 工作负载在共享的 Kubernetes 集群上运行，从而避开了采用云原生技术的重大障碍。在 2017 年 12 月 KubeCon + CloudNativeCon 上展示的案例研究中，IHME 描述了其如何能够降低基础设施需求，保护软件投资，并按照自己的节奏实现应用程序的现代化，同时提高服务水平。

## 帮助 HPC 用户跨越云原生鸿沟

随着 HPC 用户接受新的云原生开发和部署模式，他们正在寻找不仅能帮助他们发展到混合云环境，还能帮助他们发展到混合应用环境的解决方案。企业 HPC 用户需要能够在经济高效的共享基础设施上运行传统 HPC 工作负载、简单容器、基于微服务的应用，甚至是 Mesos 框架。

无论用户如何规划他们的云原生 HPC 之路，Univa 都有工具和专业知识提供帮助。有兴趣了解更多的读者可以访问[http://univa.com](http://univa.com)。

[Univa](http://www.univa.com/products/navops.php) 是软件定义的计算基础设施和工作负载协调解决方案的领先独立提供商。Univa 提供了多种解决方案，可以帮助 HPC 用户踏上云原生计算之旅。下面列出了提到的主要产品。

*   Univa Grid Engine 是一个广泛使用的分布式资源管理器，针对传统和容器化工作负载进行了优化。
*   Navops Command 为 Kubernetes 带来了高级调度功能，包括支持多步工作流和基于用户、组和项目的分层资源共享。当与 Univa Grid Engine 一起使用时，它允许客户在各种 Kubernetes 环境上运行现有的工作负载，而无需修改。
*   Univa 的 Universal Resource Broker (URB)是一个开源项目，可用于网格引擎和 Kubernetes 集群，支持各种流行的 Mesos 兼容框架(Hadoop、Spark、Storm、Marathon 等)与传统和容器化的工作负载并行运行。
*   Navops Launch 基于可重复使用的模板自动部署本地和基于云的集群。它提供了多个特定于云的适配器，允许 HPC 站点实施“云爆发”策略，根据可配置的策略以对用户透明的方式将工作负载无缝转移到云。

<svg xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 0 68 31" version="1.1"><title>Group</title> <desc>Created with Sketch.</desc></svg>