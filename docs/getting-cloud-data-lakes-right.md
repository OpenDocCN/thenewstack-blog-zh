# 正确对待云数据湖

> 原文：<https://thenewstack.io/getting-cloud-data-lakes-right/>

Prateek Shrivastava

Prateek 是 Qubole 的首席产品经理。在加入 Qubole 之前，他在 Informatica、诺基亚和思科等大型企业以及 SEVEN Networks 和 ScanBuy Inc .等初创企业担任过各种产品管理和工程职位。Prateek 在 USPTO 拥有两项与使用手机摄像头分析/解码移动设备上的条形码相关的专利。

大多数业务用户使用 BI 工具跟踪顶线、底线和客户体验指标，这些工具对数据仓库中的小型关系数据集(几 TB)进行操作，并需要执行小型数据扫描(几 GB)。数据分析师是商业智能(BI)工具的主要用户，他们与数据工程师合作编写加载所需数据的 SQL 脚本。

但如今，从数据中获得竞争优势已经不仅仅局限于 BI，还包括从交互式、流式和点击流分析到机器学习、深度学习等应用。对于这些较新的应用程序，数据湖提供了最佳的体系结构。数据以不同的速度、不同的形式从多个来源到达，并被分级和编目到一个中央存储库中。然后，它可以以经济高效的方式用于任何规模的任何类型的分析或机器学习应用程序。

至少理论上是这样，但是我们都知道建立一个成功的数据湖并不像听起来那么简单。经过几年前的大肆宣传之后，不可避免的反弹开始了，因为一些企业意识到他们已经建立了 TB 级的数据湖，但没有实现承诺的价值。然而，随着数据的持续冲击，这并不是放弃数据湖的理由；这是一个退一步，检查行业已经学到了什么，并在未来使用最佳实践的原因。

为了构建有效的数据湖，有三个广泛的领域需要数据团队给予更多的关注:数据接收、数据布局和数据治理。本文依次介绍了每个领域，并描述了确保项目成功的关键考虑因素和能力。我们在这里将重点放在云数据湖上，因为出于成本和规模的原因，大多数新的数据湖都是在那里创建的。

## 数据接收:解决批处理和流式传输

数据必须在对分析师和数据科学家有用之前被吸收到湖中。因此，数据摄取为下游分析的有效性奠定了基础。数据接收的架构最佳实践包括:

### 管理批处理和流数据接收

 [兰加·钱德拉塞卡兰

Ranga 是 Qubole 的首席产品经理。在加入 Qubole 之前，他在高通、Helpchat 和 InMobi 担任过各种产品管理和工程职位。Ranga 拥有安娜大学(印度泰米尔纳德邦)的工程学士学位和亚利桑那州立大学的电气工程硕士学位。](https://www.qubole.com) 

数据以可变的速度和不同的类型流入数据湖。无论是接收批处理数据还是流数据，数据湖都必须确保零数据丢失，并且只写一次或至少写一次；处理模式可变性；以最佳的数据格式写入正确的分区，并在需要时提供重新接收数据的能力:

*   **批处理数据摄取:**批处理系统主要是定期将应用程序数据、日志和关系数据集从事务系统移动到数据湖。对于事务性数据的批量接收，数据湖必须支持对湖中数据集的行级插入和更新。与重写数据分区或整个数据集相比，具有快照隔离(更一般地说是 ACID 语义)的 Upsert 功能极大地简化了任务。此外，ACID 语义意味着在一个数据湖上并发读写是可能的，不会出现数据完整性问题，也不会明显降低读取性能。

*   **流数据接收:**物联网数据和点击流需要实时分析，其中数据以不同的速度和不同的格式收集。即使对于流数据，数据湖也必须保证数据只被写入一次或至少一次。这可以通过使用 [Spark 结构化流式传输](https://spark.apache.org/docs/latest/structured-streaming-programming-guide.html) 以及从诸如 Kafka 的保持偏移的消息队列以可变速度到达的流式数据来实现。(这也可以用亚马逊 Kinesis 来实现。)用于流处理的数据湖解决方案应该与消息队列中的模式注册表相集成，在消息队列中，工程可以管理模式以防止每当事件的模式改变时数据管道的破坏。此外，数据平台必须支持重放功能，以跟上流处理方面的业务发展，并重新处理/恢复过时的事件。

数据湖必须支持持续优化，从摄取的数据中创建聚合和黄金数据集，用于下游分析。我们将在下一节数据布局中讨论这一方面。

### 源到目标模式转换

为了将数据从数据库或数据仓库迁移到数据湖，工程师通常必须在逻辑实体上重新创建模式。这很普通也很耗时，而且需要保持模式与源模式同步。S3 中的数据，如日志文件，可能没有模式，可能作为稀疏填充、深度嵌套的半结构化数据集存在于数据湖中。数据工程师将受益于智能检测源模式和动态创建逻辑表的能力，并将半结构化 JSON、XML 或 CSV 展平为列式文件格式。这些表的模式应该保持同步，以支持持续集成。

### 监控数据的移动

数据接收管道有时会因为难以控制的原因而失败，例如错误数据、模式漂移、间歇性平台故障等等。这就是为什么将管道和底层基础设施连接到 Datadog、Prometheus 和 SignalFx 等丰富的监控和警报工具以缩短故障后恢复时间非常重要。作为最佳实践，错误的记录应该发送到错误流中进行根本原因分析。

### 保持数据新鲜

企业需要数据可用性来缩短洞察时间。使用 UPSERT 功能(插入、更新、合并)进行数据重述和行级数据插入是数据湖体系结构中保持数据新鲜的一个重要考虑因素。为了更新几行而重写分区或整个数据集既麻烦又昂贵。

## 数据布局:针对机器学习和 SQL 分析进行优化

数据生成和数据收集具有突发性和连续性。机器数据通常是稀疏的，以 JSON 或 CSV 等半结构化格式收集。视频、图像和自由文本等记录媒体都是非结构化格式的。尝试以原始形式检查、探索和分析这些数据集既困难又缓慢，因为分析引擎会扫描多个文件中的整个数据集。更好的方法是提前计划并构建 ETL 管道，这些管道反映了为频繁访问的数据定义的布局策略。关键是使用不同的技术减少数据扫描和查询开销。

### 使用列数据格式进行读取分析

以 ORC 和 Parquet 等开源列格式发布数据，以减少数据扫描。这些机器可读的二进制文件格式针对读取分析进行了优化。在扫描整个数据集时，主动避免需要使用 [json_parse 和 json_extract](https://prestodb.github.io/docs/current/functions/json.html) 等函数解析 JSON 的查询。通过清理频繁访问的 JSON 值，将其转换为数据类型并以列格式存储，从而将其扁平化。

### 分区数据

按照时间、地理位置和业务线等常用谓词(SQL WHERE 子句)对数据进行分区，以减少不必要的数据扫描。由于分区会向 metastore 添加元数据，并导致查询执行中的查找开销，因此根据所考虑的数据集调整分区粒度非常重要。典型的要求是按年、月、周、日或小时进行分区，而不是按分钟或秒。摄取系统将负责解析事件时间戳，写入分区的正确物理位置，并更新 metastore。

### 使用压缩将小文件分成大块

数据的突发到达以及实时流接收导致数据被写入云对象存储中不同大小的多个文件。与本地模型相比，云对象存储中的网络调用既昂贵又缓慢，这会降低读取性能。通过压缩将小文件异步分块成更大的文件可以减少这些网络开销并提高性能。压缩是必要的，并且是比试图根据数据到达模式来调整接收系统更好的策略，因为数据到达模式是不可预测的，或者至少是难以预测的。

### 为基于成本的优化收集统计数据

收集和维护数据集的统计数据，如文件大小、行数和值的直方图。分析引擎运行时中基于成本的优化器可以使用可用的统计信息，通过连接重新排序等技术来优化查询，从而显著提高性能。

### 基于成本优化的 z 顺序索引物化视图

物化视图(MV)是基于特定排序关键字的数据的有序副本。分析引擎运行时可以使用实体化视图有选择地扫描数据，以查找具有过滤条件的查询计划。索引不仅应该在表级别维护，还应该在分区级别维护。虽然可以为给定的表配置多个物化视图，但这需要额外的存储和计算来保持其更新。单个物化视图上的 z 顺序索引有助于解决这个问题。z 顺序索引服务于具有任意组合的多列的查询，而不仅仅是按单个列排序的数据。

托管数据湖的概念是提供自治的数据管理功能，这些功能可用于实施上述数据布局策略。有了托管数据湖，数据工程变得更快更容易。

## 数据治理:管理结果

当数据接收和数据布局实现得很好时，数据可以以一种大众化的方式广泛地提供给用户。当多个团队开始访问数据时，数据架构师需要进行监督并管理结果。服务于重要客户并提供有意义体验的企业级数据平台需要将最佳创新与监督、法规遵从性和基于角色的访问控制相结合。在这种情况下，数据架构师会发现单一平台对于配置管理、审计、获取作业报告和实施成本控制至关重要。

### 发现您的数据

数据本身很难找到和理解，也不总是可信的。用户需要能够发现和分析数据集的完整性，然后才能在使用案例中信任它们。数据目录通过不同的机制丰富元数据，用它来记录数据集，并支持搜索界面来帮助发现。

*   使用爬虫和分类器对数据进行分类。越来越多的数据集从传感器和客户交互中流入，数据用户花费大量时间搜索这些半结构化数据集。自动添加关于数据如何进入的上下文的描述，并保持元数据和数据同步，将加快从发现到消费的端到端周期。

*   **数据字典和血统。**在数据所在的位置对数据进行注释是鉴定数据集的一种强有力的方法。除了模式和数据的物理位置之外，数据字典还包含表和列的描述、最常见的用户和使用统计、包含所述表的规范查询等等。此外，数据沿袭允许用户通过映射数据从其源头开始的生命周期来信任用于业务的数据，包括数据在此过程中是如何被修改的以及谁接触了它。

*   **元数据管理。**回答基于“需要知道”的问题，如客户流失分析，以了解用户如何购买和他们有什么偏见，通常需要争论新的和不同的数据集。因为第一步是发现所需的数据集，所以有必要向最终用户展示一个数据字典，用于探索目的，以查看数据驻留的位置和包含的内容，并确定它对于回答特定问题是否有用。Discovery 包括数据分析功能，支持数据集的交互式预览，以便了解格式化、标准化、标签、数据形状等。

### 监管和合规需求

新的或扩展的数据隐私法规，如 GDPR 和 CCPA，围绕擦除权和被遗忘权提出了新的要求。这些条款规定了消费者对其数据的权利，并涉及对违规行为的严厉经济处罚(高达全球营业额的 4%)，因此不可忽视。因此，在不中断数据管理流程的情况下删除特定数据子集的能力至关重要。除了删除本身的吞吐量之外，您还需要对 PCI/PII 数据的特殊处理和可审计性的支持。

### 许可和财务治理

云数据湖有助于即时访问数据，避免漫长的采购周期。作为一个有启发性的例子，与 Apache Ranger 开源框架的深度集成促进了表、行和列级别的粒度访问。架构师可以针对云服务提供商提供的身份和访问管理(IAM)访问解决方案中已经定义的用户角色授予权限。由于这种方法建立在定义的用户角色和策略之上，因此简化了对基础架构、引擎和工具以及数据的权限管理。

随着广泛使用，监控和审计功能对于检测访问违规、标记敌对查询等是必不可少的。虽然云提供了灵活性，但如果你不关注成本表或不预测计算需求，它也会付出代价。为了让 P&L 所有者和架构师鸟瞰使用情况，他们需要从单一控制台获得集群、作业和用户级别的成本归属和探索功能。

## 结论

获得正确的云数据湖对于使用您收集的数据建立可持续优势至关重要。如果做得好，云数据湖将打破数据孤岛，并以非常低的成本促进任何规模的多种分析工作负载。数据民主化和提供新的、更好的客户体验突然变得可以实现。

通过 Pixabay 的特征图像。

<svg xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 0 68 31" version="1.1"><title>Group</title> <desc>Created with Sketch.</desc></svg>