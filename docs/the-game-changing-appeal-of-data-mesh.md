# 数据网格改变游戏规则的吸引力

> 原文：<https://thenewstack.io/the-game-changing-appeal-of-data-mesh/>

本文是四部分系列的第一部分。

 [亚当·贝勒马尔

Adam Bellemare 是 Confluent 的技术人员，之前是 Shopify、Flipp 和 BlackBerry 的数据平台工程师。他已经在数据领域工作了十多年，在大数据架构、事件驱动的微服务和在组织中构建流数据方面有着成功的历史。他也是 O'Reilly 书名《构建事件驱动的微服务》的作者。](https://www.linkedin.com/in/adambellemare/) 

数据自上而下地塑造着现代组织，以至于对数据的贪婪需求往往成为几乎所有商业决策的出发点。
但是，随着我们对数据驱动的雄心日益高涨，在整个组织中存储、访问和使用重要业务数据的架构却没有跟上。

所谓的数据民主化在很大程度上没有兑现承诺。数据仍然很难访问，通常只是“伸手进去自己拿”之类的东西。这导致了某种形式的数据混乱。

这就是数据网格的用武之地。

如果您在过去一年左右的时间里曾经到过这个站点，那么您可能已经碰到了数据网格的概念。它是一年多前由 Thoughtworks 的技术顾问扎马克·德赫加尼(Zhamak Dehghani)开发的，旨在纠正她认为当今商业世界中数据生成和消费方式的主要缺陷。

数据网格是一个不断发展的过程的最新阶段，旨在更智能地访问和使用数据，以做出更好的战略决策，更好地服务于我们的客户。我相信它不仅被设计成商业智能过程的一个关键部分，而且也服务于操作过程。

从广义上讲，它是一种战略和战术构造，通过缩小每个业务领域的操作和分析平面之间的差距，重新调整数据的生产和消费方式，来设计更可靠的数据平台。它从领域驱动设计(用于开发微服务)、DevOps(自动化和自助服务基础设施)或可观察性(日志记录和治理)中汲取思想，并将其应用于数据世界。

数据网格是重要原则的表述，遵循这些原则将从根本上改变组织生产、使用和分发数据的方式。本文是四篇系列文章中的第一篇，旨在阐述数据网格的必要性，然后就如何调整您的思维和工作流程以实现它提出建议。它为开始您自己的数据网格项目提供了一个大纲，从基本概念到在您的组织中运行一个原型系统。

## 那么…是什么？

现在，企业中几乎每一点都会不断产生数据。这导致了广泛的事件流处理(ESP ),即对一系列数据点采取行动的实践，这些数据点来自一个从不停止生成数据的系统。(“事件”指的是系统中的每个数据点，“流”指的是那些事件的持续交付。)

事件由组织中发生的与业务相关的事情组成，如用户注册、销售、库存变化或员工更新。然后，这些事件被顺序地组织成一个流，用于促进正在进行的交付。

事件流会随着新数据的出现而更新，它们的数据可以由任何业务来源生成，例如销售、视频和音频流以及文本数据等。ESP 能够将所有形式的运营、分析和混合信息汇集在一起，并且它以多种不同的形式出现，包括结构化和非结构化。事件流在大多数数据网格实现中扮演着重要的角色。

在许多组织中，来自所有这些不同系统的稳定数据流涌入数据湖，即以自然/原始格式存储的信息库或数据仓库，它们组合并存储来自不同来源的数据。在那里，一个数据分析师团队对信息进行清理，以便不同的人可以在许多其他不同的环境中使用这些信息。

从理论上讲，将这些数十亿字节的信息合并到一个系统中意味着这些见解发展得更快。这些见解可能会导致基于数据模式预测未来事件的分析，或者作为另一个例子，导致合并数据源以创建更多上下文和意义的丰富。

一个典型的数据仓库有许多分布在整个公司的数据源，这些数据源具有不同的质量水平。将有许多 ETL(提取、转换、加载)作业在不同的系统中运行，并将数据集拉回中央仓库。分析团队清理并修复大量数据。提取和加载占用了剩余的时间。

数据仓库模型是一个被设计成可伸缩的、可靠的和持久的系统，但是它充满了麻烦。问题是，在过去的几年里，我们问了很多我们的数据。我们希望它满足战略商业智能的所有要求。但我们也需要它来设计应用程序、让客户满意并优化运营工作流。

与此同时，分析洞察贯穿于我们业务的方方面面，从必须了解客户行为以构建个性化建议的产品经理，到构建这些解决方案的工程师。

我们试图用 Apache Hadoop 等解决方案来应对这种快速增长的数据量。但不幸的是，我们这些数据领域的人非常熟悉一致、稳定和定义良好的数据的稀缺。这通常表现为分析报告中的差异:例如，分析报告说发生了 1，100 次产品交易，但客户为 1，123 次交易付费。操作系统和分析系统并不总是一致的，这在很大程度上是由于从多个不同的来源获取数据。

数据架构通常缺乏严密性，并以一种特别的方式发展，没有我们想要的那么多规则或结构。用户知道，当他们深入数据湖获取数据以进行进一步处理和分析时，信息可能会变得脆弱。旧软件可能看起来很可靠，但当出现异常数据或被修改时就会失败。随着一个给定项目中的软件变得越来越大，并且开发了一个处理它的更大的用户基础，它变得越来越没有可塑性。

简而言之，数据仓库或数据湖策略已经变得容易出错且不可持续。它导致数据生产者互不联系，数据消费者缺乏耐心，数据团队不堪重负，难以跟上步伐。最重要的是，它根本没有为我们今天所处的位置和未来的方向提供足够的支持结构。

如果你想让任何系统伸缩，你需要减少耦合点的数量，同步的地方。按照这种逻辑，数据架构可以通过分解成更小的、定义明确的、面向领域的组件来最容易地进行扩展。其他团队和产品可以订阅该数据，确信它是真实的权威来源，以对等的方式直接从他们的同行那里获取。因此，数据网格。

## 数据的神经系统

网格旨在为组织中的重要业务数据提供优质产品。它做得很简单。Data mesh 将提供干净、可用和可靠数据的责任放在了生成、使用和存储数据的团队身上，而不是集中的分析团队。它将清理数据的责任推给了最接近数据的人。换句话说，是那些最了解它的人。

在数据网格中，资产的所有权被给予最熟悉其结构、目的和价值的本地团队，以及拥有其产品的团队。在这种分散的方法中，多方合作以确保获得优秀的数据。拥有数据的各方必须是数据的好管家，并与他人沟通以确保他们的数据需求得到满足。

数据不再被视为应用程序的副产品，而是被视为定义良好的数据产品。将数据网格视为数据仓库的对立面。数据产品是分布在公司各处的格式良好的数据源，每个产品都被视为一流产品，拥有专用所有权、生命周期管理和服务级别协议。我们的想法是精心制作、管理这些数据，并将其作为产品提供给组织的其余部分，供其他团队使用，从而为整个组织的数据共享提供一个可靠且值得信赖的来源。

事件流是驱动绝大多数数据产品的最佳解决方案。它们是存储和交流重要业务数据的可扩展、可靠和持久的方式，并弥合了分析和操作处理之间日益模糊的鸿沟。他们让消费者控制该数据的不断更新的只读副本，以便在他们认为合适的时候进行处理、改造、存储和更新(想想微服务)。

云存储和计算产品的流行使得这很容易适应；分析消费者可以将数据存储在云对象存储中进行大规模并行处理，而运营用户可以直接消费数据，在事件发生时采取行动。这消除了同一数据集的多个来源，而这些来源经常会导致旧的数据采集策略出现问题。

但是实现数据网格还有很多工作要做，我将在接下来的三篇文章中探讨主要的考虑事项:
∏数据是如何产生的:数据作为产品和领域所有权
∏数据是如何消费的:自助式数据和联合治理
∏如何组织劳动力:实现最佳网格的团队方法

每个组织都会发现，其数据网格实现可能在其支持的数据产品类型、技术设计、治理模型和组织结构方面有所不同。

但有一点是肯定的:随着数据消费者的需求不断多样化，我们的需求规模不断扩大，我相信数据网格——其重点是通过事件流提供的分布式领域数据集——将变得越来越普遍，并成为我们数据驱动的未来的重要组成部分。

<svg xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 0 68 31" version="1.1"><title>Group</title> <desc>Created with Sketch.</desc></svg>