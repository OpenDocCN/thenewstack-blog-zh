<html>
<head>
<title>TNS Demo: Get Started with Machine Learning at the Edge</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">TNS演示:在边缘开始机器学习</h1>
<blockquote>原文：<a href="https://thenewstack.io/tns-demo-get-started-with-machine-learning-at-the-edge/#0001-01-01">https://thenewstack.io/tns-demo-get-started-with-machine-learning-at-the-edge/#0001-01-01</a></blockquote><div><div id="tns-post-body-content">


<p class="translated">你是如何把AI带到边缘计算的？这是新堆栈演示第一集的主题，由分析师兼TNS特约撰稿人<a href="https://thenewstack.io/author/janakiram/" target="_blank" class="local-link">贾纳基拉姆·MSV</a>整理。基于英特尔的人工智能套件，我们展示了如何“训练”设备来识别不同的车辆类型——在这种情况下，是一辆模型汽车和公共汽车。像这样的系统可以根据传感器“看到”的车辆类型来计算通行费。它可以被视为边缘设备，因为它不需要连接到互联网来获得数据中心服务器的任何额外帮助。</p>
<p class="translated"><iframe loading="lazy" title="DEMO - Get Started with Machine Learning at the Edge" src="https://www.youtube.com/embed/0gekz5jW-hg?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="">视频</iframe></p>
<p> </p>
<p class="translated">这个项目基于一个<a class="ext-link ext-link" href="https://software.intel.com/en-us/iot/hardware/up-squared-ai-vision-dev-kit" rel="external  ">英特尔AI Vision X Kit </a>，一个运行英特尔凌动处理器的边缘设备。这个工具包带有一个摄像头，可以通过USB端口向设备传输图像(尽管许多其他网络摄像头也可以工作)。这里使用的套件的一个可选版本包括<a href="https://www.movidius.com/myriad2" target="_blank" rel="noopener noreferrer external " class="ext-link">英特尔Myriad VPU </a>(视觉处理单元)，该设备将推理任务卸载到它上面。该设备运行一个版本的Ubuntu Linux，它可以很容易地用<a href="/intel-openvino-brings-ai-inferencing-to-the-desktop/" target="_blank">英特尔OpenVINO Toolkit </a>安装。</p>
<p class="translated">该演示还部署了几个<a class="ext-link ext-link" href="https://store.arduino.cc/usa/arduino-yun-rev-2" rel="external  "> Arduino Yun </a>微控制器，一个驱动数字显示器，另一个驱动两个led，一个红色，一个绿色。它们通过WiFi连接到边缘设备，MQTT充当该系统的消息代理。</p>
<p class="translated">在本教程中，小型模型汽车和公共汽车被放置在摄像头前面，摄像头会将图像发送到设备。该设备卸载到推理到VU，以确定车辆是否存在以及它是小汽车还是更大的卡车或公共汽车。结果被传送到云单位。如果车辆类型是卡车，一个LED将发光，如果车辆是汽车，另一个将发光。显示屏上的数字显示了车辆的估计大小。</p>
<p class="translated">以下是本项目中使用的项目列表:</p>

<h2 class="translated">软件设置</h2>
<p class="translated">机器学习可以分为两个部分:训练模型，然后使用模型进行推理。训练包括系统学习如何识别不同类型的数据，而推理则是应用所学知识来做出决策。在这种设置中，推理必须通过VPU实时完成。</p>
<p class="translated">对于与该系统配合工作的软件，第一步是将预先存在的深度学习视觉识别模型优化为VPU可以使用的16位浮点格式。该功能由OpenVINO工具包提供，并产生两个输出，一个bin文件和一个XML文件，这两个文件随后都被集成到工具包中的开源计算机视觉库<a href="https://sourceforge.net/projects/opencvlibrary/" target="_blank" rel="noopener noreferrer external " class="ext-link"> OpenCV </a>使用。OpenCV文件被修改以将推理处理卸载到英特尔Myriad VPU。</p>
<p class="translated">为这个项目编写的Python程序遍历每一帧来识别对象，当一个对象出现时，程序通过MQTT发送消息，启动基于OpenCV的识别过程。结果发布到Arduino云设备订阅的MQTT主题。当检测到感兴趣的对象时，为一云编写的软件改变致动器的显示。另一个云点亮相应的LED。对于本项目的定制软件，请参见<a href="https://thenewstack.io/how-i-built-an-aiot-project-with-intel-ai-vision-x-developer-kit-and-arduino-yun/" target="_blank" class="local-link">本前期教程</a>。</p>
<p class="translated">当它部署在收费站时，LED的颜色和显示屏上显示的值会根据车辆类型而变化。</p>
<p class="translated"><a class="local-link local-link" href="https://thenewstack.io/how-i-built-an-aiot-project-with-intel-ai-vision-x-developer-kit-and-arduino-yun/aiot-1/" rel="attachment wp-att-8909982"> <img decoding="async" loading="lazy" class="aligncenter" src="../Images/856085b3a16513d5e97f54d8704ec017.png" alt="" data-id="8909982" data-original-src="https://cdn.thenewstack.io/media/2019/10/49a8af45-aiot-1-1024x373.jpg"/> </a></p>
<p class="translated">请继续关注我们新的演示视频播客系列。</p>


<div class="tns-logo-slug">
<svg xmlns:xlink="http://www.w3.org/1999/xlink" viewbox="0 0 68 31" version="1.1">
<title>Group</title>
<desc>Created with Sketch.</desc>
<g id="Page-1" stroke="none" stroke-width="1" fill="none" fill-rule="evenodd">
<g id="Group">
<path d="M24.002,29.619 L29.77,29.619 L29.77,15.808 C29.77,15.038 29.622,11.265 29.59,10.414 L29.77,10.414 C31.424,14.019 31.473,14.147 32.168,15.322 L39.65,29.618 L44.845,29.618 L44.845,0 L39.075,0 L39.075,11.064 C39.075,12.197 39.075,12.44 39.182,14.472 L39.325,17.468 L39.151,17.468 C39.034,17.267 38.596,16.173 38.467,15.929 C38.164,15.323 37.725,14.512 37.373,13.905 L30.031,0 L24,0 L24,29.619 L24.002,29.619 Z" id="Path-Copy" fill="#FF3287"/>
<path d="M56.948,0 C50.745,0 47.606,3.43 47.606,8.296 C47.606,14.114 51.036,15.404 55.518,17.132 C60.438,18.853 61.782,19.332 61.782,21.539 C61.782,24.225 58.969,24.867 57.401,24.867 C54.579,24.867 52.493,23.342 51.536,20.858 L47,24.185 C49.43,28.937 52.145,30.185 57.713,30.185 C59.364,30.185 62.059,29.74 63.727,28.694 C67.779,26.156 67.779,22.22 67.779,20.898 C67.779,18.129 66.531,16.207 66.178,15.726 C65.049,14.121 63.032,12.918 61.25,12.278 L57.084,10.914 C55.073,10.267 52.928,10.105 52.928,8.019 C52.928,7.707 53.008,5.528 56.288,5.319 L61.465,5.319 L61.465,0 C61.465,0 57.342,0 56.948,0 Z" id="Path-Copy-2" fill="#00AFF4"/>
<polygon id="Path" fill="#00AFF4" points="5.32907052e-15 1.77635684e-15 5.32907052e-15 5.319 7.572 5.319 7.572 29.564 14.132 29.564 14.132 5.319 21.544 5.319 21.544 1.77635684e-15"/>
</g>
</g>
</svg> </div>
</div>
</div>    
</body>
</html>