# 红帽代码侦探发现注册表服务中的神秘漏洞

> 原文：<https://thenewstack.io/red-hat-code-sleuths-uncover-mysterious-bug-in-storage-service/>

[](https://www.linkedin.com/in/alhandy/)

 [亚历克斯·汉迪

亚历克斯是红帽公司的技术营销经理。在他之前的生活中，他报道了第一台 iMac 的发布，然后开始了 20 多年的科技记者生涯。他的作品出现在《连线》、《亚特兰大宪法日报》和《奥斯汀美国政治家》上。](https://www.linkedin.com/in/alhandy/) [](https://www.linkedin.com/in/alhandy/)

*更新到 OpenShift 4.3.19 后，Quay.io 出现了间歇性的服务中断。该团队很快恢复到 4.3.18，恢复了服务并稳定了局势，但所有相关人员现在都参与了一场神秘的谋杀。*

你听过故事，但如果你很幸运，你从未经历过。虫子在你下面。它在你之上。它在墙里。它现在正在监听我们。

故障排除和调试是历史悠久的系统化排除可能性的传统。但是，如果因为您的团队对它没有深入的了解而不能排除一部分堆栈，会发生什么呢？或者更糟的是，如果你的堆栈中有一层是闭源软件呢？

可怕的是，如果你的栈是完全开源的，而 bug 在其中一层中，那会怎么样？在库伯内特斯？在 Linux 中？你的团队能开始理解追踪这种类型的错误吗？他们甚至能在不阅读数百页代码和文档的情况下排除这种可能性吗？

## 增长到 10 位数的规模

**红帽的** [Quay.io](https://quay.io/) 是一个非常大的托管服务。最近有很多关于为企业云用户大规模托管容器映像的业务的新闻，Quay.io 自 2013 年以来一直在悄悄地履行这一功能，并稳步增长。仅在 2020 年 8 月，Quay.io 就服务了 10 亿次集装箱拉运，100%正常运行。

早在 2014 年，当 Quay.io 被 CoreOS 收购时，就决定在该服务中建立一个应用注册中心。这早于我们今天在 Kubernetes 中使用的云原生工件捆绑的现代方法，以及像 OCI 这样的解决方案，但该功能仍然包含在 Quay 的代码库中。因为这个特性并不是大多数用户采用 Quay.io 的目的，它并没有被高度使用，所以它没有得到很多工程上的审查。

App Registry 是 [quay.io](http://quay.io) 的一个鲜为人知的功能，它允许存储像舵图和容器这样的具有丰富元数据的对象。虽然大多数 [quay.io](http://quay.io) 客户不使用这个功能，但 Red Hat OpenShift 是一个大用户。OpenShift 中的 OperatorHub 使用 App Registry 来托管它的所有操作员。

每个 OpenShift 4 集群都使用来自嵌入式 OperatorHub 的操作符来服务于可用操作符的目录，以安装并向已经安装的操作符提供更新。随着 OpenShift 4 采用率的增加，全球集群的数量也在增加。这些集群中的每一个都需要下载运营商内容来运行嵌入式 OperatorHub，使用 [quay.io](http://quay.io) 内的应用注册表作为后端。

## 停电

快进到今年夏天，Quay.io 每月处理超过 10 亿次*图像请求，速度超过每小时 150 万次。这是一项大规模数据分发和保留服务，全球的企业都依赖这项服务。它还托管在 Red Hat OpenShift 上，这是一个面向全球基于容器的 It 团队的开放混合云平台。*

从 OpenShift 4.3.18 更新到 OpenShift 4.3.19 后，Quay.io 的数据库冻结，服务停止工作，导致服务间歇性中断。在此期间，用户经历了一系列后果，包括缓慢的容器图像访问时间和无法检索容器图像。该团队很快回到 4.3.18，恢复服务并稳定局势，但每个人都参与了一场谋杀之谜，就像他们自己的检查员 Lynley 一样。

但是罪魁祸首已经提到了:应用注册表。事实证明，这已经成为 Red Hat 内部团队构建 Kubernetes 操作符的方式。app registry 背后的代码从未被推进到这种规模，因此，整个系统都因此而受损。

我们在这里不讨论最终结果:与随之而来的巨大的 bug 搜索相比，它们几乎是无聊的，这表明当 Red Hat 参与进来时，CSI 风格的程序性搜索会变得如何。

相反，我们是来讨论捕虫的。曲折，疯狂的可能性，以及追踪它的方法。在崩溃后的几周内，红帽的员工在 Quay、OpenShift、Linux 内核和其他各种系统上工作，试图排除可能性，找出确切的罪魁祸首。

William Dettelback 是码头工程团队的工程经理。当 Quay.io 停机时，他首先看到的是由 Jay Ferrandini 和 Jonathan Beakley 管理的 Red Hat SRE 团队，该团队隔离了服务正常运行与其新降级状态之间发生的变化。

Dettelback 说，一开始就进行这种类型的监控和绩效评估是很重要的；否则，当事情变糟时，你实际上无法分辨。如果没有系统行为的基线，就几乎不可能准确定位问题开始的时间。

## 一英里宽，一英寸深

幸运的是，所涉及的系统中的变更数量很少。不幸的是，他们走得很深。从 OpenShift 4.3.18 到 OpenShift 4.3.19 的升级不仅包括 OpenShift 更新，还包括对用于支持容器的基本 Linux 系统和内核的一些更新。

这是因为 OpenShift 平台不仅仅是一些 PaaS，或者一些框架，甚至仅仅是 Kubernetes 的一些实现。相反，它是数千个开源项目的协调，从 Linux 内核的最底层一直到支持在 Knative 上运行的无服务器应用程序。Red Hat 工程师拥有整个开源堆栈的第一手专业知识。

在 OpenShift 4 中，Linux 操作系统是通过 Red Hat Enterprise Linux CoreOS 作为平台的一个特性提供的。这个操作系统的每个实例都是由 Kubernetes 自己提供和更新的，使用 Kubernetes 声明式 API 机器控制器作为 OpenShift 安装程序的一部分。整个堆栈包含了完全不可变的基础设施的概念。

Red Hat 工程师能够迅速将内核中的变化缩小到几个网络包。事实证明，这些只是一些值得提交的更改，但 Bill 说团队能够在一天内了解这一事实——而不是花时间研究 Linux 内核的变化。

Red Hat OpenShift 的工程总监 Stephen Cuppett 表示，Quay 团队、OpenShift 团队和 Linux 团队都试图找出可能的原因，尽快缩小问题空间。但这并不像听起来那么容易，因为这个问题只是在巨大的规模上表现出来，使得在实验室中复制很困难。

更复杂的是，遥测服务，远程调试数据流，在 4.3.18 到 4.3.19 更新后，一直在经历基于网络的中断，所以 Quay.io 和遥测团队最初都认为他们正在跟踪同一个错误。

“作为一个宏观层面的服务失误，”Dettelback 说，“有很多途径可以追查。我们有应用方面的事情要做，基础设施方面的事情要做，我们有 OpenShift 方面的事情，然后是 RHEL 方面的事情。我们知道我们面对的是少数几个三角洲。经过相当多的调查，我们发现遥测仪问题与网络有关，但[它]不是 Quay 看到的同一问题。”

此时，正确记录性能指标变得非常重要。当中断发生时，使用合成基准测试在暂存环境中对较小版本的 Quay 捕获并保存集群的性能指标。因为这个错误几乎不可能在实验室中重现，所以这个数据将是找出原因的生命线。该团队不能简单地备份 Quay.io 的更新版本，然后等待它再次失败，因为这将中断基于 Quay 构建关键系统的用户的服务。

因此，来自初始问题条件的数据对于故障排除至关重要。Dettelback 说，“我们发现在 OpenShift 4.3.18 和 4.3.19 上的 Quay 在那个转折点的表现非常不同。这就是线索。我们知道 4.3.19 不是确凿的证据，但它是我们关心的事情。它没有解释我们为什么会下降，但我们知道当我们必须进行升级时，我们必须小心。”

## 通常的嫌疑人

起初，备份系统被怀疑是原因，因为数据库在停机前一直在运行备份调用。然而，事实证明并非如此，在这个过程中关闭了所有的可能性，缩小了嫌疑人的范围。

不幸的是，最初的嫌疑人名单有阿加莎·克里斯蒂小说中的那么长。Cuppett 说:“我们在书库的各个级别都有不同的团队，所以我的人没有一个人需要调查所有的书库。这可能是一条非常漫长的道路。这很复杂，跨越了技能界限。从 Python 中 Quay 上的 Web 服务，到 Go 中的 Kubernetes，再到 C 中的 Linux 内核，还有网络……这些都是不同的团队，他们在 Red Hat 有多名工程师。”

Cuppett 说，这意味着“我们已经和多个团队一起在不同的层面进行了广泛的合作。这样，当一个团队发现确凿的证据时，其他团队可以迅速放弃其他昂贵而深入的调查途径。有很多错误的道路可供选择，因此在许多团队中缩小范围有助于防止任何一个团队浪费时间，或阻碍其他调查。”

最终，问题源于 Quay 的应用注册需求增加，这是一个从未进行过大规模测试的新功能，随着时间的推移，开发团队的使用量意外增加。底层应用程序注册代码已经过优化，使用这些功能的团队也以其他方式适应，减少了需求。

Dettelback 说，“正确的解决方案是多种因素:导致 Quay.io 崩溃的不是一件事，而是 Quay 代码库中相当脆弱的一部分上的大量流量，这些流量不是为承受它所承受的负载而设计的。在技术层面上，4.3.19 上的 DNS 解析速度较慢，但我们确定的方式是，该团队能够用 Python 构建一个重现器。”

## 深渊，避开了

这可能是对各种可能问题的无休止的探究。虽然可能遇到 Linux 内核中的错误的想法听起来像是被封为新的开源战士，但如果您的开发人员以前从未接触过内核，那么这真的是他们应该花时间去做的事情吗？这是红帽工程师的专长，他们在这类问题上的工作是红帽支持的优势之一。如果你的团队真的遇到了一个内核错误，并想接受修复它的挑战，我们将帮助他们做到这一点。我们喜欢为开源带来新的贡献者！

“内核是看起来很有可能出现的东西之一。哦，有一个内核的变化！这可能会对筹码数量产生向上的影响。但是我们很快就排除了这种可能性。

那么长远的解决办法是什么呢？“我要说的是，长期的解决方案不是删除应用注册(这是一个战术性的修复)，而是继续加强我们在 SRE、OCP 和 RHEL 的跨团队合作，以便我们可以更快地修复这些问题。因为我们在整个价值链中都有专家，并且我们以开放的方式工作，所以当您怀疑问题可能出在他们的后院时，很容易让合适的人关注这个问题。Dettelback 说:“如果我们是一个封闭的源代码商店或一个不太开放的组织，那么几乎不可能获得协作和洞察力来追查当 [quay.io](http://quay.io) 宕机时发生了什么。

<svg xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 0 68 31" version="1.1"><title>Group</title> <desc>Created with Sketch.</desc></svg>