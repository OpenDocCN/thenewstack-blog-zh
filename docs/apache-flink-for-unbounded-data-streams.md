# 面向无界数据流的 Apache Flink

> 原文：<https://thenewstack.io/apache-flink-for-unbounded-data-streams/>

除非你是一个严肃的数据开发人员，否则你很可能没有听说过 [Apache Flink](https://flink.apache.org/) 。但我可以保证你和它互动过。Booking.com、Pinterest、Stripe、阿里巴巴和高盛只是依赖 Flink 的几个公司。

为什么？因为正如 [阿里巴巴](https://www.alibaba.com/) 最近在年度[Apache Flink Forward conference](https://www.flink-forward.org/)上解释的那样，其庞大的电子商务网站每天每秒钟的订单峰值超过 50 万。这些是你在美国黑色星期五最繁忙的时候看到的交易数字。弗林克毫不犹豫地处理了这件事。在两百万个 CPU 核心上运行 Flink 作业，阿里巴巴每秒钟运行 69 亿次交易。举出另一个可以日复一日可靠地做到这一点的交易系统。

曾几何时，谈论这种规模似乎很愚蠢。几十亿的交易？谁会这么做？欢迎来到 21 世纪 20 年代。

当然，我们仍然做批量工作。但是，当我们必须跟踪行驶的汽车、不间断的金融交易、手机信号塔和智能手机之间的持续信号舞蹈、从工业传感器到烤面包机的物联网(IoT)设备等等时，您需要另一种快速数据分析。这就是弗林克的用武之地。

这个开源框架和分布式处理引擎处理连续的事件流。来自生产的报告有 [Flink 应用程序每天处理数万亿个事件](https://flink.apache.org/flink-architecture.html) 。

从技术上讲，Flink 用于无界和有界数据流上的有状态计算。你会问，这些是什么？

你已经知道了有界数据流。它们是批处理作业中使用的数据。这是具有定义的开始和结束的数据。例如，昨天上午 9 点到下午 5 点之间的所有销售的老式隔夜销售报告是一个有界数据流，通常，所有数据都在执行任何计算之前被接收。

然而，无界数据流是一匹颜色完全不同的马，它越来越成为公司希望其数据被摄取的方式。这些实时流有起点，但没有明确的终点。这些原始的、无限制的流必须被连续处理。不需要等待所有数据到达，因为数据流永远不会停止到来，而且数据流中的事件可能会无序到达。

为了解决这个问题，Flink 提供了水印等工具来管理无序接收的事件，它可以在所有常见的集群环境中运行，并以内存速度执行计算。在那里，它运行任何规模的有状态流应用程序。

我再说一遍，“任何规模。”

Flink 通过将应用程序并行化为成千上万个任务来实现这一点，这些任务分布在一个集群中并发执行。Flink 应用程序可以利用您可以提供给它们的所有 CPU 处理能力、主内存、磁盘和网络 I/O。为了管理这一切，Flink 维护了一个非常大的应用程序状态。其异步和增量检查点算法确保对处理延迟的影响最小，同时保证恰好一次状态的一致性。

有状态 Flink 应用程序的速度很大程度上来自其本地状态访问。任务状态总是保存在内存中。如果它用完了 RAM，它就使用访问高效的存储数据结构。结果是您获得了非常低的处理延迟。有了 Flink，游戏的名字永远是速度，通过最有效地利用可用的内存和存储资源来获得更多的速度。

通过在数据在系统之间移动时以及在数据在数据库中找到归属之前对数据进行分析，可以在数据还在“内存”中时立即从数据中收集信息。因此，可以以低处理等待时间以高吞吐量实时快速处理数据。

你不能用更老、更慢的技术来做吗？算是吧，我们已经做了几十年了。但是你有没有注意到这会让我们怎么样？

例如，虽然 IT 事故远不是我们经历 2022 年旅行季节 的 [悲惨夏天的唯一原因，但它肯定也发挥了重要作用。正如 Ellen Friedman 和 Kostas Tzoumas 在他们的](https://www.cnbc.com/2022/09/09/airlines-chaotic-summer-is-over-heres-how-it-went.html) [介绍 Apache Flink](https://www.oreilly.com/library/view/introduction-to-apache/9781491977132/ch01.html) 中指出的，航空公司处理来自许多来源的大量实时数据，必须快速准确地进行协调。“例如，当乘客办理登机手续时，必须对照预订信息、行李处理和航班状态以及账单检查数据。在这种规模下，要跟上并不容易，除非你有强大的技术来处理流数据。四大航空公司中的三家最近出现的重大服务中断可以直接归因于大规模处理实时数据的问题。”

确实如此。随着全球经济将越来越多的业务转移到网上，源源不断的数据从未停止，而且越来越大。我们需要弗林克。

有了 Flink，我们能够创建事件驱动的应用程序，例如比以前更快的欺诈检测和支付处理。任何等待网站对购买做出回应的人都知道，这个过程越快越好。

此外，物联网设备越来越受事件驱动。例如，家用实时健康监测将很快成为每块手表的一部分。通过给予我们真正的情境意识，用户不仅会获得有用的信息，还会获得救命的信息。

至于应用程序本身，它有助于最近的 Flink 更新通过统一流和批处理顶级应用程序编程接口使其能够充当流数据仓库。Flink 的变化数据捕获能力也使依赖静态数据存储的公司，如 MySQL、MariaDB、Oracle、PostgreSQL 和 MongoDB，能够生成可以输出到 Kafka、Pulsar 和 Clickhouse 的实时世界的流。

此外，得益于 [Flink SQL](https://flink.apache.org/2020/07/28/flink-sql-demo-building-e2e-streaming-application.html) 的进步，开发者可以使用熟悉的 SQL，而不是学习新的方法来编写实时数据程序。开发人员、数据工程师、数据科学家和分析师已经知道 SQL“通用语”最近的 Flink SQL 改进也使版本之间的迁移变得更容易，为本地查询和 REST API 提供了一个表存储，这也解锁了对 Flink SQL 的 JDBC 访问。

初创公司和老牌厂商都在用 Flink 构建解决方案。我的公司 Decodable 就是其中之一。

这意味着 Flink 不仅仅是另一个有用的开源程序。它代表了我们处理数据方式的巨大变化。从传统数据库应用到实时流程序，我们仍在思考的 IT 未来属于 Flink。

<svg xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 0 68 31" version="1.1"><title>Group</title> <desc>Created with Sketch.</desc></svg>