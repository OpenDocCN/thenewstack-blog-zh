<html>
<head>
<title>Researchers Use AI to Give Amputees 'Shared Control' of Neuroprosthetic Hand</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">研究人员使用人工智能让截肢者“共享控制”神经假体手</h1>
<blockquote>原文：<a href="https://thenewstack.io/researchers-use-ai-to-give-amputees-shared-control-of-neuroprosthetic-hand/#0001-01-01">https://thenewstack.io/researchers-use-ai-to-give-amputees-shared-control-of-neuroprosthetic-hand/#0001-01-01</a></blockquote><div><div id="tns-post-body-content">


<p class="translated">失去肢体是一个改变生活的事件，会对一个人生活的各个方面产生重大影响。但是，今天新的和改进的假肢可能会在一定程度上简化调整过程，这要归功于最近的进步，如<a href="https://thenewstack.io/victoria-hand-project-applying-3d-printing-to-prosthetics/" target="_blank" class="local-link"> 3D打印假肢</a>既可以负担得起又可以为用户量身定制，以及增加了人工智能算法，可以帮助<a href="https://thenewstack.io/ai-algorithm-automatically-tunes-prosthetics-within-minutes/" target="_blank" class="local-link">快速有效地“调整”假肢</a>，以及其他机器学习技术，允许用户<a href="https://thenewstack.io/control-robotic-arm-mind-using-machine-learning/" target="_blank" class="local-link">只用思想控制机器人肢体</a>。</p>
<p class="translated">诸如此类的创新正在开辟新的领域，如<a href="https://en.wikipedia.org/wiki/Neuroprosthetics" class="ext-link" rel="external ">神经假体</a>，它将神经科学与生物医学工程的元素交织在一起，创造出可以替代或增强受损运动、感觉或认知能力的设备，如使用微电极阵列处理听觉信号的耳蜗植入物。</p>
<p class="translated">但是，即使有了所有这些改进，对于截肢者来说，在精确抓取东西时，控制假肢仍然不容易。为了解决这个问题，瑞士洛桑联邦理工学院(<a href="https://www.epfl.ch/en/" class="ext-link" rel="external "> EPFL </a>)的研究人员正在使用机器学习来让假肢手的用户更好地控制每个手指，同时也自动化抓取和操作过程。听他们解释这个“共享控制”系统是如何工作的:</p>
<p class="translated"><iframe loading="lazy" title="A smart artificial hand for amputees merges user and robotic control" src="https://www.youtube.com/embed/L_jhQxMF8R4?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="">视频</iframe></p>
<p class="translated">这里的想法是让人工智能翻译和增强假肢用户的预期运动，特别是在用户的肌肉活动不足以完成任务的情况下，比如抓瓶子。也许这个人可能会失去抓力，这意味着在物体开始下落之前，他们只有几毫秒的时间做出反应并重新调整抓力。这就是人工智能可以提供帮助的地方，它可以自动解释用户的肌肉信号，以确保机器人的手不会在不应该松开的时候松开，甚至在人脑可能察觉到瓶子即将滑落之前。</p>
<p class="translated">“因为肌肉信号可能有噪音，我们需要一种机器学习算法，从这些肌肉中提取有意义的活动，并将它们解释为运动，”<a href="https://actu.epfl.ch/news/a-smart-artificial-hand-for-amputees-merges-user-a/" class="ext-link" rel="external ">解释道</a>凯蒂·庄，<a href="https://www.nature.com/articles/s42256-019-0093-5" class="ext-link" rel="external ">研究</a>的第一作者，最近发表在<em>自然机器智能</em>上。</p>
<p class="translated">该系统的工作原理是，首先让假肢佩戴者通过一系列手部运动“训练”一个机器学习模型，而放置在用户截肢末端的传感器收集肌肉活动的数据。然后，该算法能够通过分析和识别这些数据中的模式，学习如何实时解读用户的意图，然后允许它预测用户打算的手部动作。一旦学习了这些模式，这就允许系统帮助用户更精确地控制假手的单个手指，从而为用户提供比传统假肢更大的灵活性。</p>
<p class="translated"><img decoding="async" loading="lazy" class="aligncenter size-full wp-image-8694381" src="../Images/6b90cab4ff6d0914d9b213f0a2e6b22d.png" alt="" data-id="8694381" data-original-src="https://cdn.thenewstack.io/media/2019/09/534c4151-shared-control-neuroprosthetic-epfl-3.jpg"/></p>
<p class="translated"><img decoding="async" loading="lazy" class="aligncenter size-full wp-image-8694382" src="../Images/64dd06d55fbd9f0e8b9b83834f3f6f73.png" alt="" data-id="8694382" data-original-src="https://cdn.thenewstack.io/media/2019/09/36d99325-shared-control-neuroprosthetic-epfl-2.jpg"/></p>
<p class="translated"><img decoding="async" loading="lazy" class="aligncenter size-full wp-image-8694380" src="../Images/38ed6a4f44e9b6035e66b3e4b0c53599.png" alt="" data-id="8694380" data-original-src="https://cdn.thenewstack.io/media/2019/09/201af7c6-shared-control-neuroprosthetic-epfl-4.jpg"/></p>
<p class="translated">但仅仅预测运动只是开始:下一步是进一步调整算法，以便当假肢佩戴者试图捡起一个物体时，自动化过程就会发生。由于压力传感器排列在假手的每个手指上，当手指实际接触到物体时，算法将发送信号让假手关闭。这是该团队开发的一个方便(没有双关语)的功能，基于之前的工作，即利用仅从触觉收集的数据，赋予机器人肢体检测和抓取物体的能力。当这个人想要释放对象时，他们会启动放手的动作，算法会将控制权交还给用户。因此，通过用户手臂上的传感器、机器人手和算法的协同工作，该过程在某种程度上是自动化的，允许用户以足够的力轻松抓住目标物体，而不用担心他们会意外掉落。</p>
<p class="translated"><img decoding="async" loading="lazy" class="aligncenter size-full wp-image-8694384" src="../Images/def21cc5d4c70c453f84636eb2ef0571.png" alt="" data-id="8694384" data-original-src="https://cdn.thenewstack.io/media/2019/09/5c613789-shared-control-neuroprosthetic-epfl-1.png"/></p>
<p class="translated">根据该团队的说法，他们的智能假肢成功地应用于三名截肢者和七名健全的测试对象。虽然这种“共享控制”系统准备投入商业市场还需要一段时间，但研究人员预计它将用于<a href="https://thenewstack.io/elon-musks-neuralink-brain-reading-threads-will-be-robotically-implanted/" target="_blank" class="local-link">脑机接口</a>，以及其他需要某种程度自动化和辅助运动的仿生假肢。随着我们的人口老龄化，人们可以想象这种人工智能辅助设备不仅可以帮助截肢者，还可以帮助那些行动受限或其他年龄相关疾病的人改善他们的整体生活质量。</p>
<p class="translated">更多阅读请点击<a href="https://www.nature.com/articles/s42256-019-0093-5" class="ext-link" rel="external "> <em>自然机器智能</em> </a>。</p>
<p class="attribution translated">图片:EPFL</p>


<div class="tns-logo-slug">
<svg xmlns:xlink="http://www.w3.org/1999/xlink" viewbox="0 0 68 31" version="1.1">
<title>Group</title>
<desc>Created with Sketch.</desc>
<g id="Page-1" stroke="none" stroke-width="1" fill="none" fill-rule="evenodd">
<g id="Group">
<path d="M24.002,29.619 L29.77,29.619 L29.77,15.808 C29.77,15.038 29.622,11.265 29.59,10.414 L29.77,10.414 C31.424,14.019 31.473,14.147 32.168,15.322 L39.65,29.618 L44.845,29.618 L44.845,0 L39.075,0 L39.075,11.064 C39.075,12.197 39.075,12.44 39.182,14.472 L39.325,17.468 L39.151,17.468 C39.034,17.267 38.596,16.173 38.467,15.929 C38.164,15.323 37.725,14.512 37.373,13.905 L30.031,0 L24,0 L24,29.619 L24.002,29.619 Z" id="Path-Copy" fill="#FF3287"/>
<path d="M56.948,0 C50.745,0 47.606,3.43 47.606,8.296 C47.606,14.114 51.036,15.404 55.518,17.132 C60.438,18.853 61.782,19.332 61.782,21.539 C61.782,24.225 58.969,24.867 57.401,24.867 C54.579,24.867 52.493,23.342 51.536,20.858 L47,24.185 C49.43,28.937 52.145,30.185 57.713,30.185 C59.364,30.185 62.059,29.74 63.727,28.694 C67.779,26.156 67.779,22.22 67.779,20.898 C67.779,18.129 66.531,16.207 66.178,15.726 C65.049,14.121 63.032,12.918 61.25,12.278 L57.084,10.914 C55.073,10.267 52.928,10.105 52.928,8.019 C52.928,7.707 53.008,5.528 56.288,5.319 L61.465,5.319 L61.465,0 C61.465,0 57.342,0 56.948,0 Z" id="Path-Copy-2" fill="#00AFF4"/>
<polygon id="Path" fill="#00AFF4" points="5.32907052e-15 1.77635684e-15 5.32907052e-15 5.319 7.572 5.319 7.572 29.564 14.132 29.564 14.132 5.319 21.544 5.319 21.544 1.77635684e-15"/>
</g>
</g>
</svg> </div>
</div>
</div>    
</body>
</html>