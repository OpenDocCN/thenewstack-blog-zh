# PyTorch Lightning 和开源人工智能的未来

> 原文：<https://thenewstack.io/pytorch-lightning-and-the-future-of-open-source-ai/>

这篇文章是我们为迎接 4 月 6 日至 7 日在纽约举行的“扩大规模:人工智能大会”而撰写的系列文章之一。有关 TNS“早鸟”折扣代码，请参见下面的注释。

[](https://www.williamfalcon.com/)

 [威廉·法尔肯

威廉·法尔肯是开源项目 PyTorch Lightning 的创始人，也是 Grid.ai 的创始人兼首席执行官，他之前联合创立了现在收购的 NextGenVest，并在高盛工作过一段时间。他的博士学位由谷歌 Deepmind 和美国国家科学基金会资助。](https://www.williamfalcon.com/) [](https://www.williamfalcon.com/)

在研究、工业和学术环境中使用机器学习工具，使得我们提出和回答日益复杂的问题的能力有了显著的飞跃。然而，这些工具并非没有警告:管理机器学习操作(MLOps)，特别是对于在机器学习领域以外工作的团队来说，可能是资源密集型的，非常昂贵和耗时。我们建造了 PyTorch Lightning 开始解决这个问题。

当 Lightning 提供旨在处理复杂模型交互的用户体验的能力明显惠及全球用户时，我们随后构建了 Grid，这是我们用于在云上训练这些模型的内部平台。

![](img/8aa1615bd63900026e2ff6668e71cff3.png)

使用网格，任何人——不仅仅是拥有工业处理能力或深厚机构资源的人——都可以在云上从他们的笔记本电脑上训练模型。与我们的开源研究框架相结合，Grid 使得构建、部署和扩展 MLOps 比以往任何时候都更容易，而无需管理任何额外的基础设施。

在缺乏完全统一和灵活的研究框架的情况下，集成[机器学习](https://thenewstack.io/category/machine-learning/)工具对个人用户和大规模企业来说都是一个巨大的挑战。除了成本高和资源密集之外，构建、管理和部署 ML 工具经常占用手头的任务和研究问题的时间。想象一下，每次你开车去买杂货时，你都得制造一台内燃机。

像 PyTorch Lightning 这样的开源研究框架为 ML 工具的实现所带来的一系列问题提供了一个优雅、强大和可访问的解决方案。随着我们的框架迅速扩展到工业和学术界的用户，我们越来越致力于开发可持续、可访问和可互操作的开源 AI 工具。

除了减轻用户在部署 MLOps 时面临的现存压力之外，我们的一个关键优先事项是确保我们与我们的社区一起构建的解决方案将长期保持广泛可用和受支持。我们对开源框架的承诺源于这种愿望，即确保人工智能工具保持可访问和易于集成。

这一直是我们使命的核心:让机器学习的突破性进展能够为各种设置和用户所用，不管他们有什么资源。我们已经帮助神经科学家、顾问和机器人专家在他们的运营中利用机器学习工具，使他们能够在不重复工作或增加计算成本的情况下扩展这些运营。

通过加倍致力于开源技术和灵活响应用户需求，我们已经能够参与并依赖这个专家社区的支持。通过利用开源技术提供的灵活性，我们能够培养一个专家社区，同时开发和提供一个用户友好、直观和前沿的产品。

我们最初为研究社区构建 PyTorch Lightning，这些人已经是专家或者对 ML 工作流有重要的工作知识。然而，随着框架的发展，很明显，我们的开源创新和活跃社区的结合是一个有吸引力的前景，甚至——也许，特别是——对于在机器学习之外工作的人来说。

一旦我们意识到 Lightning 的社区驱动框架有可能为比我们最初预期的更广泛的用户带来显著的好处，我们就加倍努力提供灵活、集成和开源的工具。

我们的目标很简单:找出我们的社区成员在构建或部署人工智能工具时面临的问题，并与他们合作来缓解这些痛点。因此，我们通过响应和直接参与用户的需求，培养了一个强大的专家开发者和贡献者社区。

让这个社区的成员参与进来并不是一个挑战(也许是违反直觉的)，因为我们建立在相互信任的基础上，这种信任是建立在解决类似问题的愿望之上的。这使我们能够在学术界和工业界无缝合作:在集成 MLOps 或 AI 产品被证明非常困难的地方，可以使用 Lightning 开发解决方案。

当我们考虑开发、构建和部署人工智能产品的未来时，我们最关心的是我们积极参与的专家开发人员社区。PyTorch Lightning 已经使成千上万的用户能够专注于他们的 MLOps 的可扩展性，而无需管理任何基础架构。

Lightning 的驱动原则之一是让使用人工智能的最先进的研究能够大规模发生。我们设计它是为了让专业研究人员在不损失任何灵活性的情况下，在大规模计算资源上测试复杂的想法，这种灵活性使用户能够在很大范围的设置中比以往任何时候都更容易地利用人工智能工具。当我们谈论成功的人工智能部署时——这是今年 4 月 ScaleUp:AI 大会的首要主题——我们想到的是:扩大我们的社区驱动框架，使这些技术能够为越来越多的受众所用。

利用开源技术意味着降低部署最先进的人工智能工具的门槛。这个社区驱动的框架利用了全球贡献者的分布式专业知识，并使其对企业和个人用户都可用。闪电和网格节省了时间，减少了重复的基础设施管理，提高了解决日益复杂的研究问题的能力。

*新堆栈的母公司 Insight Partners 将于 4 月 6 日至 7 日在举办 [ScaleUp:AI 会议，合作伙伴花旗集团(Citi)和人工智能行业最具变革性的领导者也将出席。这个混合会议将人工智能和创新的远见卓识者、杰出人士和实干家聚集在一起，将释放思想，解决真正的商业挑战，并说明为什么我们正处于人工智能升级革命的中期——以及如何将其转化为商业现实。立即回复以获取早期报价并获得额外的 TNS 折扣:使用代码 TNS25。](https://scaleup.events/)*

![](img/6a8a53f44384205915676d7705009e15.png)

<svg xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 0 68 31" version="1.1"><title>Group</title> <desc>Created with Sketch.</desc></svg>