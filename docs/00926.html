<html>
<head>
<title>MIT and Yale's RoCycle Robot Can Sort Recyclables by 'Feeling' Them</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">麻省理工学院和耶鲁大学的RoCycle机器人可以通过“感觉”对可回收物品进行分类</h1>
<blockquote>原文：<a href="https://thenewstack.io/mit-and-yales-rocycle-robot-can-sort-recyclables-by-feeling-them/#0001-01-01">https://thenewstack.io/mit-and-yales-rocycle-robot-can-sort-recyclables-by-feeling-them/#0001-01-01</a></blockquote><div><div id="tns-post-body-content">


<p class="translated">我们中的许多人已经习惯于将我们的纸张、塑料、玻璃和铝放在路边回收专用的特殊垃圾箱中，以便这些材料可以被回收并转化为新的消费品。但是在这些材料可以被转换成其他东西之前，它们必须被正确地分类。然而，如果分类不正确，这些物品最终会加入每年被送往垃圾填埋场的大约25%的可回收材料中。这是一项重要的工作，大多数人会发现重复、枯燥、有潜在危险——更不用说对人类工人来说是劳动密集型的，对雇用他们的垃圾公司来说是昂贵的。</p>
<p class="translated">当然，这个过程可以自动化，通过使用机器人来更好地分类美国每年产生的6800万吨回收物。为了降低成本和提高回收率，麻省理工学院的<a href="http://csail.mit.edu/" target="_blank" rel="noopener noreferrer external " class="ext-link">计算机科学和人工智能实验室</a> (CSAIL)和耶鲁大学正在开发RoCycle，这是一种软机器人附加夹持器，与各种工业机器人平台兼容，能够“感觉”和“看到”物品，以便准确地对它们进行分类。观看并了解其工作原理:</p>
<p class="translated"><iframe loading="lazy" title="A Recycling Robot" src="https://www.youtube.com/embed/TdzbDoEh44U?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="">视频</iframe></p>
<h2 class="translated">感觉比看见更好</h2>
<p class="translated">令人惊讶的是，让机器人正确感知和识别物品并不像看起来那么容易。<a href="https://en.wikipedia.org/wiki/Computer_vision" target="_blank" rel="noopener noreferrer external " class="ext-link">计算机视觉</a>技术在最近几年已经取得了长足的进步，但是通常一台机器仍然不能仅仅通过视觉来区分物体(比如看起来像金属的塑料)。这就是RoCycle可以发挥作用的地方:它使用一只由特氟隆制成的柔软的手，指尖上装有触觉传感器，这使它可以确定一件物品的大小和硬度。</p>
<p class="translated">“我们机器人的感知皮肤提供触觉反馈，使它能够区分从坚硬到柔软的各种物体，”麻省理工学院教授和论文作者之一Daniela Rus在T2的新闻发布会上解释道。“单靠计算机视觉无法解决赋予机器类似人类的感知的问题，因此能够使用触觉输入至关重要。”</p>
<p class="translated">正如该团队在他们的<a href="http://lillych.in/files/Chin-2019-robosoft.pdf" target="_blank" rel="noopener noreferrer external " class="ext-link">论文</a>中所描述的那样，RoCycle是使用<a href="https://thenewstack.io/spider-like-microfluidic-soft-robot-is-built-for-precision-surgery/" target="_blank" class="local-link">流体驱动</a>的传统软机器人的一个进步，这意味着液体材料或空气被泵入使它们移动。然而，虽然这一方面使软机器人比它们的刚性对手更灵活，但缺点是这也使标准软机器人相当脆弱，容易被损坏或刺穿，特别是如果它们正在传送带上快速移动的可回收物流中进行分类。</p>
<p class="translated">为了防止可能的穿刺，研究小组的解决方案是使用一种称为<a href="https://en.wikipedia.org/wiki/Auxetics" target="_blank" rel="noopener noreferrer external " class="ext-link">auxitics</a>的新材料作为致动器，结合常规电机。这些偏心结构的尖端拉胀材料表现出奇怪的方式:例如，当拉伸时，它们不是像弹性带一样变薄，而是变厚了。在RoCycle的案例中，研究小组在机器人的两对手指上使用了“手动剪切拉胀”(HSA)材料，当每个手指向左或向右扭曲时，它们就会张开并互锁，允许机器人通过触摸同时抓住和感知物体。</p>
<p class="translated"><img decoding="async" loading="lazy" class="aligncenter size-full wp-image-7377640" src="../Images/dbdea3231d2e1524eaa1b54979484efb.png" alt="" data-id="7377640" data-original-src="https://cdn.thenewstack.io/media/2019/04/dc20a27d-rocycle-mit-yale-4.jpg"/></p>
<p class="translated"><img decoding="async" loading="lazy" class="aligncenter size-full wp-image-7377639" src="../Images/a4104d1eafeed8ce4a1c162c672d276d.png" alt="" data-id="7377639" data-original-src="https://cdn.thenewstack.io/media/2019/04/01c27484-rocycle-mit-yale-3.jpg"/></p>
<p class="translated">RoCycle还配备了柔软的电容式硅压力和应变传感器，这使它能够感知物体的软硬程度。该机器人还能够感知一个物体是否导电，从而进一步区分金属和非金属。此外，RoCycle使用一种算法，根据感应到的物体硬度和尺寸对纸张、塑料和金属物体进行分类。在测试中，该团队发现，RoCycle在静止时分类物体的准确率达到85%，在传送带上分类的准确率为63%。</p>
<p class="translated">那么，这可能是提高回收利用率的一个潜在解决方案吗？无论如何，该团队正在努力通过添加更多传感器和改进其底层分类算法来进一步开发该系统。研究人员希望这种软机器人附件可以融入已经在使用的光学分类系统，从而提高回收效率，促进更可持续的废物处理实践——这是世界各地迫切需要的。</p>
<p class="attribution translated">图片:麻省理工学院和耶鲁大学</p>


<div class="tns-logo-slug">
<svg xmlns:xlink="http://www.w3.org/1999/xlink" viewbox="0 0 68 31" version="1.1">
<title>Group</title>
<desc>Created with Sketch.</desc>
<g id="Page-1" stroke="none" stroke-width="1" fill="none" fill-rule="evenodd">
<g id="Group">
<path d="M24.002,29.619 L29.77,29.619 L29.77,15.808 C29.77,15.038 29.622,11.265 29.59,10.414 L29.77,10.414 C31.424,14.019 31.473,14.147 32.168,15.322 L39.65,29.618 L44.845,29.618 L44.845,0 L39.075,0 L39.075,11.064 C39.075,12.197 39.075,12.44 39.182,14.472 L39.325,17.468 L39.151,17.468 C39.034,17.267 38.596,16.173 38.467,15.929 C38.164,15.323 37.725,14.512 37.373,13.905 L30.031,0 L24,0 L24,29.619 L24.002,29.619 Z" id="Path-Copy" fill="#FF3287"/>
<path d="M56.948,0 C50.745,0 47.606,3.43 47.606,8.296 C47.606,14.114 51.036,15.404 55.518,17.132 C60.438,18.853 61.782,19.332 61.782,21.539 C61.782,24.225 58.969,24.867 57.401,24.867 C54.579,24.867 52.493,23.342 51.536,20.858 L47,24.185 C49.43,28.937 52.145,30.185 57.713,30.185 C59.364,30.185 62.059,29.74 63.727,28.694 C67.779,26.156 67.779,22.22 67.779,20.898 C67.779,18.129 66.531,16.207 66.178,15.726 C65.049,14.121 63.032,12.918 61.25,12.278 L57.084,10.914 C55.073,10.267 52.928,10.105 52.928,8.019 C52.928,7.707 53.008,5.528 56.288,5.319 L61.465,5.319 L61.465,0 C61.465,0 57.342,0 56.948,0 Z" id="Path-Copy-2" fill="#00AFF4"/>
<polygon id="Path" fill="#00AFF4" points="5.32907052e-15 1.77635684e-15 5.32907052e-15 5.319 7.572 5.319 7.572 29.564 14.132 29.564 14.132 5.319 21.544 5.319 21.544 1.77635684e-15"/>
</g>
</g>
</svg> </div>
</div>
</div>    
</body>
</html>