# Nate Silver 从特朗普的意外胜利中学到的大数据经验

> 原文：<https://thenewstack.io/lessons-big-data-unpredictability-trump-win/>

四年前，[内特·西尔弗](https://www.linkedin.com/in/natesilver)，杰出的数据分析师和 fivethirtyeight.com[的主编](https://fivethirtyeight.com)写了一本书，副标题为[为什么这么多预测失败——但有些没有](https://www.amazon.com/Signal-Noise-Many-Predictions-Fail-but/dp/0143125087)。它解释了为什么预测分析经常失败，根据书的封面，“当大数据遇到人性时会发生什么。”西尔弗继续正确预测了过去四年的每一次选举结果。直到去年 11 月。

美国当选总统唐纳德·特朗普(Donald Trump)的意外胜利现在加入了臭名昭著的预测失败名单，与 9/11 和 2008 年的住房危机一样，他在选举后不久在旧金山表示。

作为 FutureStack16 的晚间主题演讲，他向 New Relic 的客户讲述了大数据和预测之间的关系。现在有数 Pb 的数据需要整理，并且数据的可用性每天都在增加。

Silver 说:“我们仍然处于数据分析的初级阶段，因为我们现在正在处理数十亿字节的数据，而这些海量数据还没有那么长时间可用。记住这些数据不是知识是非常重要的。它需要解释。

在选举日，对特朗普获胜的预测从普林斯顿模型的 1%到 538%的 29%不等。西尔弗说，尽管所有的预测都使用了相同的数据，但它们确实是不同的预测。结果证明他们都错了。

诸如此类的问题是 IT 数据分析师每天面临的问题。

数据越多，复杂度越大。例如，如果你有五个变量，那么这些变量之间就有十个双向关系。

数据不是因为它本身而有趣，而是因为它与其他事物的关系。这就像一张地图，你需要看到数据是如何与其他一切相关联的。坐标本身并不能告诉你什么。但是随着你的数据集越来越大，你从五个变量到十个变量，你开始看到复杂性的指数增长。

一些领域数据的广泛可得性增加了这种复杂性。例如，在经济学中，你有 384，000 个由美联储实时发布的变量，因此你可以运行 73，727，000，000 个双向关系组合。当然，您会希望创建多向数据关系，这只会成倍地增加复杂性。

西尔弗说，这导致了大量的假正相关，或者说，虽然有数据联系，但实际上没有任何意义的相关。

回到 20 世纪 80 年代，谁赢得了超级碗和接下来一年的股市表现之间似乎有很强的相关性(不是因果关系，而是相关性)。当 NFC 部门的一支球队获胜，旧金山 49 人队大获全胜时，市场就会上涨。亚足联分区球队获胜的那几年，股市将会是糟糕的一年。直到 2008 年，所有的赌注都结束了。这在统计学上是有意义的，但是这种相关性背后没有因果关系，这种联系之间也没有任何意义。

“如果你正在寻找相关性，但没有找到背后的原因，”西尔弗说，“不要打这个赌。”

数据呈指数级增长，因此存在大量噪声。西尔弗告诉工程师们，他们需要运用常识和算法。仍然会有很多噪音。和假相关。

他说，你可以编程算法来消除一些假阳性，但常识或直觉仍然大有帮助。用你的算法完成 80 %,然后引入常识。如果有些事情看起来不应该是对的，那很可能就是不对的。

## 何时质疑你的发现

西尔弗建议说，如果你发现了一个你的竞争对手从未发现过的洞见，就要仔细检查你的数据。意识到你的竞争对手几乎和你一样聪明。可悲的是，很多时候，当你没有达成一致意见时，你的模型中有一个 bug，而不是一个新特性。

<svg xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 0 68 31" version="1.1"><title>Group</title> <desc>Created with Sketch.</desc></svg>