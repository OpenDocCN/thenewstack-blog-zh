# 实时数据库如何降低总拥有成本

> 原文：<https://thenewstack.io/how-real-time-database-design-boosts-total-cost-of-ownership/>

为了满足当今企业中严格的服务级别协议(SLA)的要求，实时应用程序必须在任何规模下提供可预测的性能、低延迟和可承受的成本。为此，他们必须在很短的时间内做出响应，因此需要可靠快速地访问所有数据。管理此类数据的实时数据库的成本、可伸缩性和可管理性取决于其设计。本文讨论了对效率至关重要的具体方面。

## 实时应用服务级别协议

实时应用的 SLA 可以定义为在指定的时间窗口内被服务的第 99 个百分位数的请求，并且对于不同的实时应用可以有很大的不同。SLA 范围的高端是对时间极其敏感的应用程序，如高频交易，在这种情况下，纳秒对于响应市场条件的变化以利用套利机会至关重要。在这种情况下，将逻辑和关键数据放在定制设计的芯片上，并最大限度地减少到服务器的信号路径等技术是必要的。范围的低端可能是设备监控应用程序，其发出警报的 SLA[分钟](https://thenewstack.io/slo-vs-sla-whats-the-difference-and-how-does-sli-relate/)分钟。

绝大多数面向用户的[实时应用程序](https://thenewstack.io/building-large-scale-real-time-json-applications/)位于中间领域。这些交互式应用程序必须在人类经验的时间范围内(通常在 1-2 秒内)为请求提供服务。体验交付的上游驱动因素，如个性化、推荐、广告等，有更严格的 SLA。例如，广告服务器必须在几十毫秒内响应出价。同样，欺诈检测必须在数百毫秒内完成，以保持良好的用户体验。这些驱动程序通常需要多次数据访问来处理一个请求，因此需要毫秒范围的数据访问来满足更广泛的 SLA。

面向用户的应用程序越来越需要处理大量用户并利用大量相关数据。由于社交媒体或市场变动，他们可能需要迅速扩大规模，达到意想不到的规模。因此，除了毫秒级的数据访问延迟 SLA 之外，他们还对数据量以及处理吞吐量和数据快速增长的能力有着严格的要求。

## 高效性能和可扩展性的支柱

以下因素决定了效率，将在以下章节中进行介绍:

*   数据存储:数据存储硬件必须支持必要的速度和有效的扩展。
*   数据库设计:数据库设计必须最有效地利用可用资源。
*   操作方面:系统必须易于扩展、有弹性且易于维护。

## 数据存储

许多现代实时数据库在易失性存储器或 DRAM 中实现数据存储，以在亚毫秒范围内提供快速数据访问。对于大量数据，这种解决方案的供应和维护成本会变得非常昂贵。由于单个节点的 DRAM 容量有限，在高端服务器中通常高达 TB，因此需要多节点集群解决方案来处理更大的数据量并满足可靠性目标。

另一方面，基于[混合内存架构](https://aerospike.com/products/features/hybrid-memory-architecture/) (HMA)的 [Aerospike 数据库](https://aerospike.com/products/database/)，将数据存储在固态硬盘(SSD)中，作为快速高密度存储，在大数据量上提供毫秒级的延迟。基于固态硬盘的存储的另一个主要优势是固态硬盘提供持久存储。存储在易失性 DRAM 中的数据必须被复制到别处，并且在恢复期间被重新填充到 DRAM 中。从永久或远程复制副本重新填充大量数据可能会导致系统在缓慢重启期间不可用。

让我们比较一下固态硬盘和动态随机存储器的数据存储成本特征。

### 大型集群的成本

数百 TB 到数 Pb 的大型数据量将需要数百到数千个节点的大型集群。拿一个 512GB DRAM 的 AWS 上的保留实例 [r6g.16xlarge](https://aws.amazon.com/ec2/instance-types/) 为例。其[月费用](https://aws.amazon.com/ec2/pricing/reserved-instances/pricing/)约 1500 美元。假设有 100TB 的数据，一个 200 节点的群集每月花费近 300，000 美元。

与[混合内存案例](https://thenewstack.io/databases-high-volume-transactions-scale/)相比，主索引驻留在 DRAM 中，数据保存在 SSD 中。假设索引与数据的大小比为 1:30(每 2，000 条记录 64 字节的索引条目)，DRAM 为 1 / 30，则索引的 SSD 数据大小是必需的。在云部署中，考虑一个提供 256GB DRAM 和 7.5TB SSD 的 AWS 实例 [i4i.8xlarge](https://aws.amazon.com/ec2/instance-types/) 。保留实例的[月成本约为 1，300 美元，13 个节点的集群(100TB 集群/每个节点 7.5TB)的成本约为 170，0090 美元/月，比纯 DRAM 数据库节省约 44%。](https://aws.amazon.com/ec2/pricing/reserved-instances/pricing/)

如果集群在本地托管，可以比较 DRAM 和 SSD 的价格，以得出硬件成本比较，因为内存是总硬件成本的重要部分。固态硬盘的价格因品牌、接口和其他因素而异，但在撰写本文时，它们通常不到每 GB 1 美元，而 DRAM 的价格约为每 GB 5 美元以上。因此，混合存储器数据库的存储成本比纯基于 DRAM 的数据库便宜大约五倍。假设内存成本约为服务器总成本的 50%，混合数据库提供的成本优势是纯 DRAM 数据库的两倍以上。

### 大型集群中的开销

纯基于 DRAM 的数据库会产生一个大型集群，这还会带来其他效率低下的问题。随着集群规模的增大，运行特性会随着维护集群的开销的增加而恶化。

**集群协调**

群集中的所有节点都需要通过心跳消息不断相互通信，以快速建立群集中其他节点和成员的状态。这种集群协议的开销随着集群大小呈指数增长，因为节点间消息具有 O(N^2 或对节点数量的二阶依赖性。因此，开销在大型集群中变得很大，并且随着更高百分比的资源消耗在集群的内务处理任务中，大型集群的资源效率变得越来越低。

**手动监督**

流行的横向扩展模型的效率基于廉价且易于更换的商用硬件。这适用于无状态集群，例如将状态信息保存在网络文件系统和数据库等持久性存储中的 web 服务器。后者必须复制持久信息以防止失败。复制不仅增加了硬件成本和更新开销，而且持久性存储中的有状态实例更难替换，因为从故障中恢复需要恢复数据，维护和扩展事件也是如此。大多数此类事件将通过强大的数据库设计和操作程序的自动化在没有人工干预的情况下处理。然而，其中的一部分最终需要人工监督。此类事件和手动干预的频率随着集群规模的增加而增加，导致维护开销增加。

## 数据库设计

### 平衡数据分布

假设数据随机且均匀地分布在集群节点中。在这种情况下，请求负载也均匀地分布在所有节点上，并且所有节点上的资源都得到均匀利用。这导致了更高的效率。

不仅优化了群集效率，还避免了在群集更改和故障期间因手动重新分配数据而产生的成本和错误。后者会导致不可用甚至数据丢失。通过自动重新平衡数据，始终保持统一的数据分布，从而确保更高的资源效率和可用性。

### 高效的服务器处理

为了最大限度地减少同步冲突和开销，请求处理应该在不同的点上得到简化。有效处理请求涉及许多方面，包括:

*   客户端直接连接到数据所在的节点，而不必通过协调器节点。
*   通过特定的技术和约定最小限度地锁定关键数据结构。
*   简化流程，最大限度地减少多个网卡、CPU 内核和数据分区之间的争用。
*   支持数据压缩的磁盘存储和网络流量。

### 增强的容错能力

虽然数据复制对于容错和读取性能是必需的，但它也会增加数据和群集的大小以及更新开销。一个典型的系统被设计为至少有两个副本来处理一个节点故障，合理的假设是，由于节点恢复时间远小于节点故障之间的平均时间(MTBF ),两个并发节点故障极其罕见。但是，在故障节点的恢复窗口期间，第二个节点发生故障的概率会随着群集大小的增加而线性增加。

任何节点在给定时间窗口内发生故障的概率为:
持续时间/平均故障间隔时间(MTBF)

因此，在具有 N 个节点的集群中，两个并发节点故障的概率为:

(N-1) x(平均修复时间(MTTR) /平均无故障时间)

如果有两个重叠的节点故障，部分数据将变得不可用，特别是在故障节点上有两个副本的数据。为了降低数据不可用的可能性，数据库可以通过在其他节点上重新创建故障节点上的数据的新副本来动态保留复制因子(RF)。这种动态复制有时被称为**迁移**。只要填充新副本所需的时间比 MTTR 少得多，这将改善由于并发故障导致的不可用性。只要节点上的数据量和网络速度允许快速迁移，迁移期间的数据传输成本就是合理的。

当已知恢复时间少于迁移时间时，应避免不必要的迁移，例如日常维护任务。在这种情况下，应该可以在维护期间禁用正在维护的节点的自动迁移。

### 智能客户端

如果客户端库跟踪集群中的数据放置并透明地处理集群转换，则可以避免数据从客户端到正确的服务器节点的多次跳跃。

## 操作方面

### 易于缩放

如果数据库不是线性扩展，快速增长的吞吐量和数据需求可能会成为性能、可靠性和成本问题，这不仅是因为大型集群成本高昂且难以支持，还因为如果没有自动重新平衡，扩展过程可能容易出错，如上所述。

当数据库无法满足实时应用程序不断增长的需求时，切换到更具可伸缩性的替代方案会非常昂贵和痛苦。这种转变涉及数据迁移、应用程序重写和架构/设计更改，例如潜在的缓存层及其操作复杂性和一致性问题。在新系统上线时，旧系统必须继续工作，并且切换必须无缝进行。因此，选择一个从一开始就可以无限扩展的系统可能会更有效，风险更小。

### 同步全球分布的数据

拥有一个允许集群在全球范围内分布的数据库，并根据需要以紧密同步或接近实时的异步方式保持数据同步，在操作上是高效的。

### 自动化运营任务

对于一个复杂的生产系统，自动化程度越高越好。Kubernetes 操作器是一种自动化操作任务的复杂方法，可以显著提高操作效率和系统可靠性。

绝大多数交互式应用程序需要毫秒级的数据访问。对于需要大量数据的应用，固态硬盘以比 DRAM 低得多的成本提供快速高密度存储。将数据存储在固态硬盘中可缩小集群规模，从而带来成本优势、操作简单性和可靠性。现代实时数据库必须设计为最有效地利用资源，具有统一的数据分布、自动平衡、简化的处理、从客户端的单跳访问以及用于存储和传输的数据压缩。Aerospike 旨在通过这些效率提供最低的总拥有成本(TCO)。

<svg xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 0 68 31" version="1.1"><title>Group</title> <desc>Created with Sketch.</desc></svg>