<html>
<head>
<title>Gain Two Extra VR-Controlled Robotic Arms with this Backpack</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用这个背包获得两个额外的虚拟现实控制的机械臂</h1>
<blockquote>原文：<a href="https://thenewstack.io/gain-two-extra-vr-controlled-robotic-arms-with-this-backpack/#0001-01-01">https://thenewstack.io/gain-two-extra-vr-controlled-robotic-arms-with-this-backpack/#0001-01-01</a></blockquote><div><div id="tns-post-body-content">


<p class="translated">我们认为拥有双臂和双手的便利是理所当然的，但机器人技术的最新发展表明，即使是身体健全的人也可以通过额外的可编程手臂(甚至是T2手指)做很多事情。</p>
<p class="translated">庆应义塾大学媒体设计研究生院的助理教授<a href="https://myamens.com/" class="ext-link" rel="external "> Yamen Saraiji </a>希望扩大人体的限制，他创造了<a href="https://myamens.com/?section=7" target="_blank" class="ext-link" rel="external "> Fusion </a>，这是一套可以由另一个人通过虚拟现实控制的机器人手臂。观察这些额外的附件是如何工作的:</p>
<p class="translated"><iframe loading="lazy" title="Fusion: Full Body Surrogacy for Collaborative Communication" src="https://www.youtube.com/embed/Nrc7gH6dydw?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="">视频</iframe></p>
<p class="translated">该原型与东京大学合作完成，具有可穿戴的21磅重的系统，可以像背包一样携带，包括机械臂和手和手指的机器复制品。除了有足够一个半小时电力的电池外，该包还包括一台小型计算机，可以在用户和远程操作员之间无线传输数据，以及一台摄像头。</p>
<p class="translated">通过摄像头，第二个人作为另一个位置的远程操作员，可以通过Oculus Rift VR耳机实时“看到”第一个用户看到的任何东西。由于耳机中的传感器，当远程操作者在虚拟现实中移动他们的头部时，摄像机也会相应地移动，可以说，这给了操作者一个行动中的环座。为了远程控制背包的机械臂，操作员使用Oculus的触摸控制器，该控制器将运动中继到连接到背包计算机的微控制器。</p>
<p class="translated"><img decoding="async" loading="lazy" class="aligncenter size-full wp-image-5528748" src="../Images/549082f396ec888a64feb51a232c039f.png" alt="" data-original-src="https://cdn.thenewstack.io/media/2018/08/52dad2b2-fusion-backpack-robot-arms-yamen-saraiji-2.jpg"/></p>
<p class="translated">目的是实现Saraiji和他的团队所说的“全身共享”，即远程操作者可以使用虚拟连接“潜入别人的身体”。由于这些手臂可以独立于佩戴它们的人而移动，机器人肢体不仅成为安装它们的“代理身体”的延伸，也成为控制它们的远处的人的延伸。</p>
<p class="translated">可选地，机械手可以被移除，并由可以连接到主持人的手腕的带子代替，使得远程操作者可以实际上为他们移动主持人的手臂。</p>
<p class="translated">对于我们中的一些人来说，这听起来可能有点令人毛骨悚然，但这样的系统有很多潜在的用途，例如协同使用它来完成任务，或者让一个人以动手的方式指导另一个人学习新技能。这里的主要思想是允许两个实体之间更流畅的交流和更顺畅的互动，<a href="https://myamens.com/?section=7" target="_blank" class="ext-link" rel="external ">Saraiji解释道</a>“有效的沟通是社交和职业环境中的一个关键因素，这涉及到分享多个人的技能和行动。[..]我们通过这个系统展示了将我们的身体动作从一个人真正体现和转移到另一个人身上的可能性，实现了真正的身体交流。”</p>
<p class="translated"><img decoding="async" loading="lazy" class="aligncenter size-full wp-image-5528749" src="../Images/a9a903e8d3cf1ee1ec8eee6bbb0b3ef6.png" alt="" data-original-src="https://cdn.thenewstack.io/media/2018/08/a0a1080b-fusion-backpack-robot-arms-yamen-saraiji-3.jpg"/></p>
<p> </p>
<p class="translated">该项目是对<a href="https://thenewstack.io/telepresence-robot-uses-virtual-reality-offer-immersive-experience/" target="_blank" class="local-link">远程呈现</a>技术便利性的一个有趣的扭曲，它允许人们通过机器人的眼睛“看”，而不必亲自到场。但这里有人类增强的因素，正如Saraiji所概述的，这个系统有三个层次的“身体驱动的交流”:定向、强制和诱导。最温和的味道是“直接”类型的身体交流，其中人形手正在帮助或教授代理宿主一项新技能。当机器人手臂直接绑在宿主的手臂上时，就会发生“强制”通信，允许远程操作员对代理人的肢体运动施加更多的物理控制。最后，当远程操作员使用更多的力量来控制主机的手臂时，就会发生“诱导”通信——可能会使它们左右晃动。</p>
<p class="translated">这不是Saraiji第一次进行人体增强实验；事实上，Fusion代表了他之前项目MetaLimbs的一次重大升级，MetaLimbs的特色是由脚踏板控制的机器人“第三只手臂”。但有了Fusion，它可以由另一个用户虚拟控制的事实开辟了更多的可能性:人们可以想象有一个远程专家使用手臂来帮助佩戴者处理一些困难的任务，如修理计算机，帮助医疗急救，或促进远程辅助物理治疗。该团队现在希望找到商业化实现核聚变的方法；要了解更多信息，请访问<a href="https://myamens.com/" class="ext-link" rel="external ">衙门撒莱吉</a>。</p>
<p class="attribution translated">图片:庆应义塾大学和东京大学。</p>


<div class="tns-logo-slug">
<svg xmlns:xlink="http://www.w3.org/1999/xlink" viewbox="0 0 68 31" version="1.1">
<title>Group</title>
<desc>Created with Sketch.</desc>
<g id="Page-1" stroke="none" stroke-width="1" fill="none" fill-rule="evenodd">
<g id="Group">
<path d="M24.002,29.619 L29.77,29.619 L29.77,15.808 C29.77,15.038 29.622,11.265 29.59,10.414 L29.77,10.414 C31.424,14.019 31.473,14.147 32.168,15.322 L39.65,29.618 L44.845,29.618 L44.845,0 L39.075,0 L39.075,11.064 C39.075,12.197 39.075,12.44 39.182,14.472 L39.325,17.468 L39.151,17.468 C39.034,17.267 38.596,16.173 38.467,15.929 C38.164,15.323 37.725,14.512 37.373,13.905 L30.031,0 L24,0 L24,29.619 L24.002,29.619 Z" id="Path-Copy" fill="#FF3287"/>
<path d="M56.948,0 C50.745,0 47.606,3.43 47.606,8.296 C47.606,14.114 51.036,15.404 55.518,17.132 C60.438,18.853 61.782,19.332 61.782,21.539 C61.782,24.225 58.969,24.867 57.401,24.867 C54.579,24.867 52.493,23.342 51.536,20.858 L47,24.185 C49.43,28.937 52.145,30.185 57.713,30.185 C59.364,30.185 62.059,29.74 63.727,28.694 C67.779,26.156 67.779,22.22 67.779,20.898 C67.779,18.129 66.531,16.207 66.178,15.726 C65.049,14.121 63.032,12.918 61.25,12.278 L57.084,10.914 C55.073,10.267 52.928,10.105 52.928,8.019 C52.928,7.707 53.008,5.528 56.288,5.319 L61.465,5.319 L61.465,0 C61.465,0 57.342,0 56.948,0 Z" id="Path-Copy-2" fill="#00AFF4"/>
<polygon id="Path" fill="#00AFF4" points="5.32907052e-15 1.77635684e-15 5.32907052e-15 5.319 7.572 5.319 7.572 29.564 14.132 29.564 14.132 5.319 21.544 5.319 21.544 1.77635684e-15"/>
</g>
</g>
</svg> </div>
</div>
</div>    
</body>
</html>