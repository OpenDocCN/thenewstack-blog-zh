<html>
<head>
<title>Camouflaged Graffiti on Road Signs Can Fool Machine Learning Models</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">路标上伪装的涂鸦可以愚弄机器学习模型</h1>
<blockquote>原文：<a href="https://thenewstack.io/camouflaged-graffiti-road-signs-can-fool-machine-learning-models/#0001-01-01">https://thenewstack.io/camouflaged-graffiti-road-signs-can-fool-machine-learning-models/#0001-01-01</a></blockquote><div><div id="tns-post-body-content">


<p class="translated">自动驾驶汽车背后的技术在过去几年里有了很大的改善，汽车制造商依赖雷达、激光、运动传感器和数码相机系统的组合来帮助它安全地在道路上导航。汽车的计算机视觉系统利用深度学习算法来帮助它识别行人和理解道路标志。但是在一个标志可能被破坏、被灰尘、积雪或树叶遮挡的世界里，这些计算机“眼睛”能有多准确和可靠呢？</p>
<p class="translated">不幸的是，正如最近的一项研究所示，只需稍微改变道路标志的物理外观，就不难欺骗视觉分类算法——这比电子侵入自动驾驶系统更容易实现，也更有可能实现。来自华盛顿大学、密歇根大学、石溪大学和加州大学伯克利分校的一组研究人员发现，通过在标志上添加一些贴纸或喷漆，会导致基于深度神经网络的分类器将它们与其他类型的标志混淆——可以理解，这是一个令人担忧的大问题。</p>
<h2 class="translated">一种新的对抗性攻击</h2>
<p class="translated">在人工智能和机器学习领域工作的专家熟悉“对立例子”的问题——机器学习模型中的输入，这些输入被故意设计成混淆机器，导致它们错误地将这些输入归类为其他东西。对于视觉输入系统，我们已经看到过以前的例子，研究人员在图像上应用像素梯度，这对人眼来说是不明显的，但往往会在大多数时候混淆机器。</p>
<p class="translated">但是，除非黑客能够直接访问车辆的所有电子和支持导航系统，否则这些类型的敌对攻击在现实世界中很难执行。另一方面，在现实生活中改变对象要容易得多，用那种方式愚弄计算机。在一篇题为“<a href="https://arxiv.org/pdf/1707.08945.pdf" target="_blank" class="ext-link" rel="external ">对机器学习模型的强大物理世界攻击</a>”的论文中，研究人员描述了他们如何开发出一种新的“攻击算法”，能够创造“敌对扰动”——通过以多种现实世界的方式在视觉上改变标志，以便计算机视觉技术将它们错误分类，而不管距离或视角如何。</p>
<p class="translated">将这些修改称为“强大的物理扰动”(或RP2)，物理世界中的这些变化——就像在真的标记上粘贴一个印刷的、掺假的标记，或者在它们上面贴上贴纸一样简单。最令人不安的可能是，这项新技术产生了人眼通常察觉不到的变化，但却欺骗了计算机，让它认为自己看到了一个完全不同的信号。</p>
<h2 class="translated">海报和贴纸</h2>
<p class="translated">该团队使用了多种方法来实现这种错觉，从伪装涂鸦和伪装艺术到微妙的褪色。他们首先测试了一个他们称之为“海报印刷攻击”的实现，其中使用他们的攻击算法产生一个微妙改变的标志，然后印刷并粘贴在一个真实的标志上。这些视觉上的变化只有在近距离观察时才能注意到。该团队发现，通过这种方法，他们能够100%地混淆机器，将停止标志分类为每小时45英里的限速标志，并将右转标志分类为停止标志。</p>
<div id="attachment_2961328" class="wp-caption aligncenter"><img aria-describedby="caption-attachment-2961328" decoding="async" loading="lazy" class="wp-image-2961328 size-full" src="../Images/f8f41f14bc7657ea5727d33f14369f2e.png" alt="" data-original-src="https://storage.googleapis.com/cdn.thenewstack.io/media/2017/08/faea0f7f-robust-physical-adversarial-attack-ai-2.jpeg"/><p id="caption-attachment-2961328" class="wp-caption-text translated">海报印刷的对抗性攻击的例子。</p></div>
<p class="translated">第二种方法被称为“贴纸攻击”，让团队将贴纸贴在标志上，使其类似于城市中常见的贴纸涂鸦。虽然这种方法比印刷海报更明显，但这些攻击更容易执行，因为他们可能的恶作剧只需要一台彩色打印机，不需要他们用打印输出覆盖整个标志。研究人员发现，通过贴纸伪装涂鸦干扰，使用贴纸形成“爱恨”配置，他们能够在大约67%的情况下使系统将停止标志误读为限速标志。随着贴纸伪装艺术的干扰，贴纸以更抽象的方式放置，系统在所有测试实例中100%地错误分类相同的标志。</p>
<div id="attachment_2961329" class="wp-caption aligncenter"><img aria-describedby="caption-attachment-2961329" decoding="async" loading="lazy" class="wp-image-2961329 size-full" src="../Images/1d4e8aa597f54853a74405eefb25ddb8.png" alt="" data-original-src="https://storage.googleapis.com/cdn.thenewstack.io/media/2017/08/b4f4a562-robust-physical-adversarial-attack-ai-3.jpeg"/><p id="caption-attachment-2961329" class="wp-caption-text translated">基于贴纸的对抗性攻击，展示迷彩抽象艺术攻击(上)和迷彩涂鸦攻击(下)。</p></div>
<p class="translated">为了进行他们的实验，该团队在TensorFlow中训练了他们的模型，采用了道路标志的公共数据集。虽然几千个训练示例的数据集相对较小，但结果清楚地显示了当真实对象被修改时，自动驾驶系统中使用的深度学习人工神经网络的潜在漏洞。</p>
<p class="translated">“与以前的工作不同，[……]这里我们专注于逃避攻击，攻击者只能修改测试数据而不是训练数据(中毒攻击)，”研究人员解释说。“在闪避攻击中，攻击者只能改变现有的物理路标。这里我们假设攻击者在分类器被训练后获得了对它的访问权(“白盒”访问)。”</p>
<p class="translated">该团队进行这些测试的动机很简单:调查目前使用的自主系统的潜在弱点，以便它们可以免受这种敌对攻击，这种攻击有可能造成巨大伤害，特别是在道路上的瞬间情况下。“这种假设是可行的，因为即使没有访问实际模型本身，通过探测系统，攻击者通常可以根据反馈找出类似的代理模型，”他们补充道。“我们需要评估最强大的攻击者，以便为未来的防御提供信息，保证系统的健壮性。”</p>
<p class="translated">与此同时，这些例子表明，自动驾驶汽车的发展仍然有很长的路要走。即便如此，它也提出了一个问题，即我们是否需要彻底反思基础设施本身:为了安全起见，道路是否应该完全交给自动驾驶汽车，人类控制、标志和其他人为错误和恶作剧的可能性是否应该完全消除？我们是否应该安装新的智能道路标记，以无线方式广播标志信息，并且可能不太容易修改？尽管无人驾驶汽车最终将在我们的道路上激增，但如何使它们安全并抵御各种攻击的许多问题仍然存在。</p>
<p class="attribution translated">图片:华盛顿大学、密歇根大学、石溪大学和加州大学伯克利分校。</p>


<div class="tns-logo-slug">
<svg xmlns:xlink="http://www.w3.org/1999/xlink" viewbox="0 0 68 31" version="1.1">
<title>Group</title>
<desc>Created with Sketch.</desc>
<g id="Page-1" stroke="none" stroke-width="1" fill="none" fill-rule="evenodd">
<g id="Group">
<path d="M24.002,29.619 L29.77,29.619 L29.77,15.808 C29.77,15.038 29.622,11.265 29.59,10.414 L29.77,10.414 C31.424,14.019 31.473,14.147 32.168,15.322 L39.65,29.618 L44.845,29.618 L44.845,0 L39.075,0 L39.075,11.064 C39.075,12.197 39.075,12.44 39.182,14.472 L39.325,17.468 L39.151,17.468 C39.034,17.267 38.596,16.173 38.467,15.929 C38.164,15.323 37.725,14.512 37.373,13.905 L30.031,0 L24,0 L24,29.619 L24.002,29.619 Z" id="Path-Copy" fill="#FF3287"/>
<path d="M56.948,0 C50.745,0 47.606,3.43 47.606,8.296 C47.606,14.114 51.036,15.404 55.518,17.132 C60.438,18.853 61.782,19.332 61.782,21.539 C61.782,24.225 58.969,24.867 57.401,24.867 C54.579,24.867 52.493,23.342 51.536,20.858 L47,24.185 C49.43,28.937 52.145,30.185 57.713,30.185 C59.364,30.185 62.059,29.74 63.727,28.694 C67.779,26.156 67.779,22.22 67.779,20.898 C67.779,18.129 66.531,16.207 66.178,15.726 C65.049,14.121 63.032,12.918 61.25,12.278 L57.084,10.914 C55.073,10.267 52.928,10.105 52.928,8.019 C52.928,7.707 53.008,5.528 56.288,5.319 L61.465,5.319 L61.465,0 C61.465,0 57.342,0 56.948,0 Z" id="Path-Copy-2" fill="#00AFF4"/>
<polygon id="Path" fill="#00AFF4" points="5.32907052e-15 1.77635684e-15 5.32907052e-15 5.319 7.572 5.319 7.572 29.564 14.132 29.564 14.132 5.319 21.544 5.319 21.544 1.77635684e-15"/>
</g>
</g>
</svg> </div>
</div>
</div>    
</body>
</html>