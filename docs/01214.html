<html>
<head>
<title>Explainable AI: Looking into the Black Box</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">可解释的人工智能:观察黑盒</h1>
<blockquote>原文：<a href="https://thenewstack.io/explainable-ai-looking-into-the-black-box/#0001-01-01">https://thenewstack.io/explainable-ai-looking-into-the-black-box/#0001-01-01</a></blockquote><div><div id="tns-post-body-content">


<p class="translated"><br/> <span class="media-direct-link"> <a href="https://thenewstack.simplecast.com/episodes/explaining-explainable-ai-camille-eddy-on-looking-into-the-black-box" class="ext-link" rel="external ">解释可解释的艾:卡米尔·艾迪把目光投向黑匣子</a> </span></p>

<p class="translated">在本期<a href="https://thenewstack.io/podcasts/makers" target="_blank" class="local-link"> The New Stack Makers </a>播客中，我们与<a href="https://www.linkedin.com/in/camilleeddy/" class="ext-link" rel="external "> Camille Eddy </a>聊天，她对可解释人工智能(XAI)的兴趣始于在惠普公司高级机器人实习期间，当时她开始担心社交机器人缺乏多样性的影响。</p>
<p class="translated">她在<a href="https://www.oreilly.com/ideas/recognizing-cultural-bias-in-ai" target="_blank" rel="noopener noreferrer external " class="ext-link"> 2018年奥赖利开源大会</a>上发表的演讲“<a href="https://www.oreilly.com/ideas/recognizing-cultural-bias-in-ai" target="_blank" rel="noopener noreferrer external " class="ext-link">认识人工智能</a>中的文化偏见”以这个问题开始:<span class="Apple-converted-space"> </span>“像一个人的肤色这样不变的东西怎么能阻止他们享受我创造的任何产品？”</p>
<p class="translated">埃迪说，当我们想到我们如何生活以及如何与科技互动时，我们并不总是想到其他人的互动。例如，著名的<a href="https://www.youtube.com/watch?v=YJjv_OeiHmo" target="_blank" rel="noopener noreferrer external " class="ext-link">史诗般的失败，脸书总部的洗手液分配器</a>没有给黑人的手分配肥皂，因为它没有被校准以观察肤色。</p>
<p class="translated">作为一名工程师，Eddy关注着她所创造的技术的意想不到的后果。</p>
<h3 class="translated">可解释的人工智能</h3>
<p class="translated">尽管Eddy最初认为自己是一名机械工程师，但她也对人工智能(AI)感兴趣。她经常同时玩弄双方。“当我打开一堆代码时，没有人奇怪地看着我，当我在机械车间时，也没有人奇怪地看着我，”她说。<span class="Apple-converted-space"> </span></p>
<p class="translated">这种观点使她能够进行对话，首先是在内部，然后是与其他人，讨论软件如何被放入硬件，以及软件如何影响客户的整体体验。</p>
<p class="translated">理解算法为什么做出决定的想法是XAI的精髓。她说:<span class="Apple-converted-space"> </span>我们已经看到了无法识别肤色或做出结论的例子，但不理解为什么人工智能算法会做出这样的结论。</p>
<p class="translated">随着行业正在处理关于创建更好的工具以及更好地理解和认识人工智能的想法，XAI或公平工具已经开始出现。</p>
<p class="translated">你必须非常小心，确保你得到的结果确实是你想要的结果，她说。Eddy引用了华盛顿大学的一项研究，他们认为他们在计算狼对哈士奇，但意识到该算法实际上是在计算交易照片中的雪对无雪。<span class="Apple-converted-space"> </span>算法工作正常，只是不像研究人员预想的那样。</p>
<p class="translated">因此，最近谷歌和IBM推出了一系列公平工具。<span class="Apple-converted-space"> </span> <a href="https://ai.googleblog.com/2018/09/the-what-if-tool-code-free-probing-of.html" class="ext-link" rel="external "> <b>谷歌的假设工具</b> </a>，允许你改变杠杆，四处移动，以了解你的数据的背景，从整体上看待数据，而不是专注于某些点，或问一些具体的问题，如我这样做对吗？我是否已经包含了我需要的所有用例？</p>
<p class="translated">对于一个研究人员来说，这是我的研究，这是结论，这是所有的数据点，回答关于结果背后的推理的问题。</p>
<p class="translated">这是一种可演示的方法，可以看到为什么算法会得出它返回的结果，也是一种观察人工智能黑盒内部的方式。“我们可以做出明智的决定，”埃迪说，“人们可以回去了解这些决定来自哪里。”</p>
<p class="translated">请收听有关哈士奇与斯诺项目的更多信息，以及我们使用算法的方式如何对我们的个人知识产生严重影响。</p>
<p class="translated">如果你有兴趣了解更多，Eddy女士将在今年晚些时候的敏捷测试会议上讲授一个关于在XAI工具中使用公平性的8小时教程。<span class="Apple-converted-space">T15】</span></p>
<h3 class="translated">在这个版本中:</h3>
<p class="translated"><a href="https://thenewstack.simplecast.com/episodes/explaining-explainable-ai-camille-eddy-on-looking-into-the-black-box?t=3:35" target="_blank" rel="noopener noreferrer external " class="ext-link"> 3:35: </a>处于硬件和软件交汇点的工程师。<br/> <a href="https://thenewstack.simplecast.com/episodes/explaining-explainable-ai-camille-eddy-on-looking-into-the-black-box?t=5:53" target="_blank" rel="noopener noreferrer external " class="ext-link"> 5:53: </a>“可交代的艾”又是什么。<br/> <a href="https://thenewstack.simplecast.com/episodes/explaining-explainable-ai-camille-eddy-on-looking-into-the-black-box?t=10:20" target="_blank" rel="noopener noreferrer external " class="ext-link"> 10:20: </a>从各方面看数据。<br/> <a href="https://thenewstack.simplecast.com/episodes/explaining-explainable-ai-camille-eddy-on-looking-into-the-black-box?t=13:04" target="_blank" rel="noopener noreferrer external " class="ext-link"> 13:04: </a>我们使用算法的方式会对我们的个人知识产生严重的后果。<br/> <a href="https://thenewstack.simplecast.com/episodes/explaining-explainable-ai-camille-eddy-on-looking-into-the-black-box?t=16:53" target="_blank" rel="noopener noreferrer external " class="ext-link"> 16:53: </a>将值应用到我们编写的软件中。<br/> <a href="https://thenewstack.simplecast.com/episodes/explaining-explainable-ai-camille-eddy-on-looking-into-the-black-box?t=19:42" target="_blank" rel="noopener noreferrer external " class="ext-link"> 19:42: </a>讨论算法的兴起。</p>
<p class="attribution translated">通过Pixabay的特征图像。</p>


<div class="tns-logo-slug">
<svg xmlns:xlink="http://www.w3.org/1999/xlink" viewbox="0 0 68 31" version="1.1">
<title>Group</title>
<desc>Created with Sketch.</desc>
<g id="Page-1" stroke="none" stroke-width="1" fill="none" fill-rule="evenodd">
<g id="Group">
<path d="M24.002,29.619 L29.77,29.619 L29.77,15.808 C29.77,15.038 29.622,11.265 29.59,10.414 L29.77,10.414 C31.424,14.019 31.473,14.147 32.168,15.322 L39.65,29.618 L44.845,29.618 L44.845,0 L39.075,0 L39.075,11.064 C39.075,12.197 39.075,12.44 39.182,14.472 L39.325,17.468 L39.151,17.468 C39.034,17.267 38.596,16.173 38.467,15.929 C38.164,15.323 37.725,14.512 37.373,13.905 L30.031,0 L24,0 L24,29.619 L24.002,29.619 Z" id="Path-Copy" fill="#FF3287"/>
<path d="M56.948,0 C50.745,0 47.606,3.43 47.606,8.296 C47.606,14.114 51.036,15.404 55.518,17.132 C60.438,18.853 61.782,19.332 61.782,21.539 C61.782,24.225 58.969,24.867 57.401,24.867 C54.579,24.867 52.493,23.342 51.536,20.858 L47,24.185 C49.43,28.937 52.145,30.185 57.713,30.185 C59.364,30.185 62.059,29.74 63.727,28.694 C67.779,26.156 67.779,22.22 67.779,20.898 C67.779,18.129 66.531,16.207 66.178,15.726 C65.049,14.121 63.032,12.918 61.25,12.278 L57.084,10.914 C55.073,10.267 52.928,10.105 52.928,8.019 C52.928,7.707 53.008,5.528 56.288,5.319 L61.465,5.319 L61.465,0 C61.465,0 57.342,0 56.948,0 Z" id="Path-Copy-2" fill="#00AFF4"/>
<polygon id="Path" fill="#00AFF4" points="5.32907052e-15 1.77635684e-15 5.32907052e-15 5.319 7.572 5.319 7.572 29.564 14.132 29.564 14.132 5.319 21.544 5.319 21.544 1.77635684e-15"/>
</g>
</g>
</svg> </div>

</div>
</div>    
</body>
</html>