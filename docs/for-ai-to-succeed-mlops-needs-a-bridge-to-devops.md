# 为了人工智能的成功，MLOps 需要一个通向 DevOps 的桥梁

> 原文：<https://thenewstack.io/for-ai-to-succeed-mlops-needs-a-bridge-to-devops/>

[](https://www.linkedin.com/in/luis-ceze-50b2314)

[![](img/d488262df6ad2bd79dddca8b21350a3c.png)](https://www.linkedin.com/in/luis-ceze-50b2314)

[Luis Ceze](https://www.linkedin.com/in/luis-ceze-50b2314)

[Luis 是 OctoML 的联合创始人兼首席执行官，OctoML 是华盛顿大学的一个子公司，旨在让每个人和每个硬件目标都可以访问高效安全的机器学习。Luis 是华盛顿大学计算机科学的获奖教授，他于 2007 年加入该校。他的研究重点是计算机体系结构、编程语言、分子生物学和机器学习的交叉。在 UW 大学，他是分子信息系统实验室的共同负责人，他们正在开发存储合成 DNA 数据的技术，并探索 DNA 纳米技术的新用途。他还共同领导 SAMPL 实验室，该实验室专注于机器学习的硬件/软件协同优化，也是 TVM 深度学习编译和优化堆栈的起点。他是 NSF 职业奖、斯隆研究奖学金、微软研究人员奖学金、IEEE TCCA 青年计算机架构师奖和 UIUC 杰出校友奖的获得者。他是 DARPA ISAT 和 MEC 研究小组的成员。](https://www.linkedin.com/in/luis-ceze-50b2314)

[](https://www.linkedin.com/in/luis-ceze-50b2314)[](https://www.linkedin.com/in/luis-ceze-50b2314)

人工智能被誉为软件应用的新“大脑”，这个角色长期以来一直由数据库扮演。遗憾的是，AI 对于应用开发者和运营团队来说，并不是那么容易被采用和吸收的。事实上，将[机器学习](https://thenewstack.io/category/machine-learning/)模型(为人工智能提供动力)整合到以生产力为中心的应用程序中——让它们变得更加智能——过于困难和复杂。此外，ML 模型依赖于硬件和软件基础设施的特定组合。如果没有合适的基础设施，这些模型要么不能很好地运行，要么在某些情况下变得过于昂贵。

今天，在 ML 模型的创建和将它们投入生产的过程之间没有有效的桥梁。举例来说:ML 模型的平均生产时间是 12 周。更糟糕的是，近一半的模型因性能或成本原因被搁置，这使得人工智能的转型程度不如许多人希望的那样。

如果人工智能是应用程序的“大脑”，那么在一个 ML 模型高度专业化的世界里，需要独特和定制的工作流和工具是有问题的。事实上，一旦一个 ML 模型被训练好并准备好了，我们应该能够像处理任何其他软件模块一样处理它，因为它只是代码和数据。包含一个 ML 模型并不意味着我们所知道的 DevOps 被抛弃。

ML 的部署需求通常很难适应，因为 ML 软件栈完全依赖于它运行的硬件。ML 开发人员应该能够构建模型，而不用担心硬件后端。具有讽刺意味的是，要实现像人工智能这样的先进技术，ML 模型必须手动调整以满足应用程序的性能 SLA。

今天，这一过程如此具有挑战性，以至于即使是熟练的数据科学家和人工智能从业者也会犯错误——模型往往会在自己独特的管道中结束。除了少数例外，这些管道都是定制组装的，非常脆弱。对部署硬件选择、环境、培训框架、软件库或集成堆栈所做的更改可能需要彻底的调试，甚至是完全的重建。

从数据科学家到应用程序开发人员和运营团队的转移具有反复试验的特点。这是对 AI 应用开发的拖累。为了减少障碍课程，机器学习方面需要重新调整并与 DevOps 工作流和最佳实践相结合。

## DevOps 先来的。MLOps 必须适应 DevOps 的世界

在企业人工智能的早期，MLOps 最初是一个术语，指的是在生产中设计、构建、部署和维护机器学习模型的一系列最佳实践。然而，随着它的发展，范围已经扩展到整个 ML 生命周期管理。根据您询问的对象(以及他们销售的产品)，它涵盖了从模型生成、编排和部署到健康、诊断、治理和业务指标的所有内容。

作为一名机器学习工程师，模型创建是一门独特的学科，有自己的流程和工具集。然而，当模型创建和模型部署被强制合并到一个大型流程中时，它限制了灵活性和选择，从而造成了障碍。MLOps 希望解决从模型创建到部署的每一个步骤，这要求太高了。它创建了一个并行的开发过程，该过程需要特殊的资源和专业知识，而这些资源和专业知识在今天是短缺的。另一方面，DevOps 的既定学科中有成熟的流程和丰富的人才。

要求软件开发人员学习全新的方法来使用 ML 模型可能是不切实际的。他们太忙，也太贵，坦率地说，应该专注于他们的核心竞争力。事实上，ML 模型是智能应用程序中的元素，熟悉的 DevOps 实践和工具实际上工作得很好。我们需要的是将 ML 模型融入软件世界的方法。如果没有这一点，基于 ML 的应用程序的成功率可能会保持在不可接受的低水平。

## 机器学习模型本质上仍然是软件

为了查看是什么阻碍了 ML 模型的部署，我们可以从 ML 训练框架、模型类型、低级库和编译器以及所选硬件之间的典型依赖关系开始。大多数用户无法自行解决依赖性问题；他们需要工具来抽象复杂性，绕过依赖性，并将模型作为生产就绪的软件功能来交付。

典型的 ML 部署工作流是专门的和手动的。在人工智能改变世界的道路上，这是一个巨大的坑洞。部署程序需要让应用程序开发人员、开发运维工程师和 IT 运营团队能够访问和操作。他们需要能够使用他们自己的 DevOps 工作流和工具，以与处理他们的应用程序堆栈的其余部分相同的方式处理模型。

在 ML 和 DevOps 端，都需要一个桥。现在出现的平台可以将 ML 模型转换成高性能、可靠和可移植的功能，这些功能可以在不同的硬件上工作。

## 未来

应用程序开发人员和 DevOps 团队应该是 ML 部署的一个组成部分，而不是成为机器学习的专家。这些从业者需要一种更简单的方法来处理模型，就像他们处理软件一样。人工智能需要变得更容易理解，因此低代码/无代码解决方案可能会在未来几年发挥重要作用，抽象人工智能/ML 的复杂性。一旦模型创建和部署到智能应用程序之间的鸿沟被弥合，人工智能在商业和其他领域的贡献将开始发挥其潜力。

<svg xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 0 68 31" version="1.1"><title>Group</title> <desc>Created with Sketch.</desc></svg>