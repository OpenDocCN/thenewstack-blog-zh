# 运行融合卡夫卡的最佳实践

> 原文：<https://thenewstack.io/best-practices-for-running-confluent-kafka/>

[](https://www.linkedin.com/in/cvlc/)

[Calum Lacroix](https://www.linkedin.com/in/cvlc/)

[Calum 是 Ondat 的一名解决方案架构师，他帮助客户和合作伙伴实现他们在 Kubernetes 上持久数据的战略和战术目标。他将自己在软件开发和运营工程方面的经验应用于银行、媒体、出版和咨询领域，对云原生架构、安全性和 DevOps 文化有着特别的热情。](https://www.linkedin.com/in/cvlc/)

[](https://www.linkedin.com/in/cvlc/)[](https://www.linkedin.com/in/cvlc/)

超过 80%的财富 100 强公司使用 Kafka，可以说它是应用程序间流式数据的行业标准解决方案。像网飞和谷歌这样的大企业以及小型创业公司和个人项目都依赖 Kafka 来代理消息、跟踪网站活动、监控运营数据、聚合日志、处理数据流等等。公司使用 Kafka 来驱动视频元数据、实时车辆信息和金融交易等事件。

值得注意的是，Kafka 通过充当消息代理，使组织能够集成大型应用程序和微服务组合，使其成为基于 Kubernetes 的基础架构的理想解决方案。但是作为一个与所有这些不同的微服务交互的分布式系统，Kafka 可能很难独自管理。

## 卡夫卡与融合

由于这种复杂性，像 [Confluent](https://www.confluent.io/?utm_content=inline-mention) 这样的供应商提供企业级 Kafka 发行版和托管服务。企业团队不是构建自己的连接器、流处理、数据治理和安全性、灾难恢复以及其他功能和组件，而是使用 Confluent 来立即投入运行。

当然，与 DIY 实现相比，使用任何管理框架都会自动提供较少的控制和灵活性。希望获得最大灵活性、拥有独特的应用程序生态系统和/或拥有技术能力强、资源充足的团队的组织可能希望自己实施和管理 Kafka。

然而，对于绝大多数组织来说，使用 Confluent 节省的时间、金钱和精力远远超过任何运营控制的损失。

## 与融合的卡夫卡一起工作时要避免的主要陷阱

### 将 Kafka 视为有状态的持久数据库

虽然 Kafka 确实将实时事件流式传输到一个不可变的、可重放的分类帐中，但是这个分类帐不应该被视为有状态的数据库。Confluent Kafka 缺乏专门构建的数据库通常包含的功能，如最小化停机时间和最大化灾难后的可恢复性、复杂的查询功能等。

为了避免这种情况，开发人员应该使用[发件箱模式](https://microservices.io/patterns/data/transactional-outbox.html)，它包括将 Kafka 消息的历史存储在一个持久的关系数据库中，比如 PostgreSQL。这样，您可以随时重新创建和恢复 Kafka 队列，实现高弹性和可伸缩性，并降低管理 Kafka 的总体运营成本。

### 依靠一个卡夫卡集群

您正在使用 Kafka 来统一您分散的微服务和应用程序，因此尽可能保持集中化是有意义的，对吗？不幸的是，如果您用来托管单个 Kafka 实例的集群出现问题，这样做会使您的整个生态系统面临风险。

相反，更好的做法是使用 Kubernetes 来创建多个更小的 Kafka 集群，每个集群都是为其特定环境量身定制的。然后，使用 Kubernetes 的本地功能和 Confluent 的托管服务，尽可能多地自动化部署。这样，即使您的系统更加分布式，您也不会增加环境的复杂性，并且您保留了分布式系统带来的弹性。

### 在接受和处理 Kafka 数据时过于自由

Kafka 处理某些消息时，这些消息将会无效并导致意外行为。在努力实现自动化的过程中，一些开发人员可能会尝试实现一个“尽力而为”的模型来处理这些消息，但是这可能会在其他系统中导致更大的问题。

相反，开发者应该利用卡夫卡的死信队列。此功能存储无效消息或未能传递到自己队列的消息。开发人员可以配置当消息到达该队列时发出的警报，使支持团队能够手动处理这些无效消息。尽管应该尽可能减少人工干预，但最好允许人眼检查无效的信息，而不是将它们传递给其他系统，以免破坏某些东西。

### 低估卡夫卡的存储敏感性

不幸的是，当 Kafka 的底层存储系统性能不佳或可用性不稳定时，Kafka 的表现会很差。当数据不是立即可用或高度一致时，Kafka 自己的工作负载和操作可能会出错。即使由合流管理，Kafka 仍然需要极高性能的存储才能正常运行。

为了获得可靠的底层存储基础设施，融合的 Kafka 用户通常转向亚马逊的弹性块存储(EBS)。然而，EBS 的问题是众所周知的。虽然性能很高，但 EBS 仅限于单个区域(AZ)中的单个弹性计算云(EC2)实例，并且仅在 Amazon Web Services (AWS)上可用。因此，希望在其生态系统中扩展和使用多个 Kafka 集群的组织将需要跨多个 AZ 购买多个 EBS 卷，并且必须准备好手动干预以在 AZ 停机期间保持可用性。

幸运的是，这个可伸缩性挑战是 Ondat 的一个完美用例。

## 翁达特对融合卡夫卡的存储方法

融合的 Kafka 需要缓解其存储挑战的是数据层。 [Ondat](https://docs.ondat.io/docs/install/) 作为一个高性能、加密和可用的数据层，跨节点汇集存储。因此，融合的 Kafka 实例可以访问共享的存储资源，即使它们分布在多个集群和可用性区域中。

例如，如果企业决定将 Ondat 与 EC2 实例存储一起使用，它可以利用上面的指导以最低的成本实现最大性能的 Kafka 集群。即使他们使用 EBS，他们也可以使用 Ondat 的 delta sync 技术实现自动化复制，以确保跨 AZ 故障的可用性。相同的应用程序配置可以用于任何基础设施，Ondat 可以在任何平台上提供相同的功能，从内部部署到云。因此，企业获得了一种成本和资源效率更高的方式来消费存储服务。

这种存储方法与 Confluent 针对 Kafka 的应用程序级增强功能(如 Confluent Replicator)非常契合。Replicator 支持将主题从一个 Kafka 集群快速复制到另一个集群。利用 Ondat 作为 Kafka 集群的底层数据平台，企业可以获得同类最佳的灾难恢复，而无需考虑其底层存储基础架构。企业还受益于单一的数据界面，该界面增强了数据可用性，确保了所有团队的一致性和可访问性。

注册 Ondat 的新[社区版](https://portal.ondat.io)，免费提供无限节点和高达 1tb 的每集群容量！欲了解如何开始的更多信息，请访问我们的[文档网站](https://docs.ondat.io/)。

<svg xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 0 68 31" version="1.1"><title>Group</title> <desc>Created with Sketch.</desc></svg>