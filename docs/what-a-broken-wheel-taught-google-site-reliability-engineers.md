# 一个坏掉的轮子教会了谷歌网站可靠性工程师什么

> 原文：<https://thenewstack.io/what-a-broken-wheel-taught-google-site-reliability-engineers/>

谷歌云可靠性倡导者史蒂夫麦克格曾经分享了该公司在 T2 的站点可靠性工程(SRE)团队(T3)学到的一个基本真理。

"在谷歌的范围内，百万分之一的机会总是在发生."

麦克格在谷歌云博客的[中写道，古怪条件的完美风暴迟早会触发“其他地方看不到的复杂、紧急的故障模式”。“因此，谷歌内部的 sre 已经能够熟练地开发系统，跟踪深入到我们基础设施许多层的故障……”这有时会把他们带到令人惊讶的地方。](https://cloud.google.com/blog/products/management-tools/sre-keeps-digging-to-prevent-problems)

但这也是将问题视为学习机会的更大现象的一部分——被调查、分析，并最终与努力变得更好的全球社区分享。这是一种最受欢迎的极客消遣，让学习变得简单，就像分享曾经解决的最棘手的谜题的故事，以及一些建议，一些有趣的知识和过去的传说。

一路上，你会听到一些非常有趣的故事。

## 堆栈的底部

谷歌工程师在服务器上遇到了一个问题，原因是谷歌低延迟边缘网络上缓存的频繁访问的内容。换上新服务器后，他们发现旧服务器遇到了[路由问题](https://en.wikipedia.org/wiki/Route_flapping)，内核消息警告 CPU 节流。谷歌的硬件团队最终确定了问题的根源——而且技术含量低得惊人。

“后轮上的脚轮失灵了，”他们写道，“机器因倾斜而过热。”倾斜影响了冷却剂的流动，这意味着机架上破裂的轮子最终会导致“导致一些 CPU 升温到被节流的程度”的后果。

博文的标题？“在谷歌堆栈的底部找到一个问题。”开发者 Dilip Kumar 后来在《黑客新闻》上开玩笑说,“我想象不出一种更好的方式来使用‘谷歌栈底’这个短语。”

但就像任何好故事一样，也有值得吸取的教训。“我们在 SRE 团队常用的另一个短语是‘所有事件都应该是新奇的’，”麦克格写道，意思是“它们应该不会出现超过一次”。在这种情况下，SREs 和硬件运营团队通力合作，确保此类故障不会再次发生。”

硬件团队随后提出了未来的解决方案，包括车轮维修套件和更好的安装和机架移动程序(以避免损坏)。更重要的是，他们知道在其他可能处于自己车轮问题边缘的机架中寻找什么，这“导致系统地更换所有具有相同问题的机架，”麦克格写道，“同时避免任何客户影响。”

但从更广泛的意义上来说，它表明了问题也可以是“可教的时刻”——而这些教训可能具有惊人的深远意义。麦克格最近与谷歌云解决方案架构师 James Brookbank(今年早些时候由 O'Reilly 出版)合著了[*SRE*](https://sre.google/resources/practices-and-processes/enterprise-roadmap-to-sre/)企业路线图。

这份长达 62 页的报告一度认为，SRE 现在正在发生，特别是因为“基于互联网的服务的复杂性最近明显上升，最值得注意的是云计算的兴起，”一个“T4 预计会失败的架构选择的世界”，因为系统运行只需要一部分组件。

这需要一种新的思维方式。

## 课程还在继续

当这个帖子第一次出现在[黑客新闻的讨论中时，麦克格的故事也吸引了更多关于“小说”问题的故事。一位评论者](https://news.ycombinator.com/item?id=22573467)[记得](https://news.ycombinator.com/item?id=22584415)一个主机托管设施“替换了机架中一些缺失的封闭面板，并导致架顶式交换机回收热空气…

“两台交换机的系统温度都在 100 摄氏度以上，值得称赞的是(Dell/Force10 s4820Ts)它们运行完美，没有降低任何流量，并向报告电子邮件发送了适当的通知。如果不加检查，像这样的良性问题可能会摧毁整个基础架构。”

他们接着说，他们听说了基础设施方面更糟糕的问题。“一位数据中心经理讲述了一个机架从高架地板上掉下来的故事……”(他们补充说，即使在灾难发生后，“它也一直在运行，直到被一名技术人员在巡视时发现。”)这引发了另一个更有哲理性的评论。“公共云时代的一个副产品是，在考虑运营艺术时，不再需要考虑事物的物理方面。”

“人们是否没有足够频繁地访问他们的数据中心，以至于没有注意到倾斜的机架？”

在一个努力学习更多信息的社区中，评论者很快就开始思考为什么谷歌似乎对问题原因的监控更少，而对“用户可见的”问题的监控更多。一个用户最终[找到了](https://news.ycombinator.com/item?id=22585013)谷歌的[用于监控分布式系统的完整工具集](https://sre.google/sre-book/monitoring-distributed-systems/)，包括仪表板、警报和一个方便的常用术语词汇表。果然，它包括“黑盒监控”(定义为“测试用户看到的外部可见行为”)和“白盒监控”，即“系统内部暴露的指标，包括日志……”后来，该文档解释说，黑盒监控可以提醒您“系统目前工作不正常”，最终深入探讨这如何符合每页都应可操作的基本原则。

“花大力气抓症状比抓病因好得多；谈到原因，只担心非常明确，非常紧迫的原因。”

谷歌网站可靠性工程师 Rob Ewaschuk 曾经[分享了他自己的哲学](https://docs.google.com/document/d/199PqyG3UsyXlwieHaqbGiWVa8eMWi8zzAn0YfcApr8Q/preview#heading=h.6ammb5h32uqq)，写道基于原因的警报“是不好的(但有时是必要的)”，同时认为基于症状的通知允许 sre 专注于修复“重要的警报”

## 传说中的虫子

也许这一切都证明了关于角落案例的讨论会导致令人惊讶的富有成效的方向。

系统管理员埃文·安德森(Evan Anderson)曾经修复了一个间歇性的 WiFi 连接，这个连接只在“一个特定的循环午餐会议”期间关闭，他在黑客新闻上回忆道，这个会议“安排在稳定的工作人员进入大厅对面的休息室并用微波炉加热食物的时候……”

然后有一个传说中的票抱怨“ [OpenOffice 在周二](http://catless.ncl.ac.uk/Risks/25/77#subj14.1)不打印。”这是因为该实用程序使用文件中的文件头检测虚拟机上的文件类型，这些文件头通常包含星期几，会错误识别 PostScript 文件的格式，但仅在星期二。)

软件架构师 Andreas Zwinkau 在他的[“软件民间传说”网站](http://beza1e1.tuxen.de/lore/index.html)上收集了几十个类似的故事——IT 专业人士随时准备加入与[more](https://www.reddit.com/r/sysadmin/comments/qcn4yu/what_is_your_funniest_it_ticket_story/)[stories](https://old.reddit.com/r/sysadmin/comments/a8vqep/what_is_the_most_ridiculoussilly_ticket_you_have/)[of](https://news.ycombinator.com/item?id=11717010)T8 他们自己的的对话。

但这不仅仅证明了你永远不知道调查会有什么结果。在一个充满数据的企业中——所有的警报、通知、页面和仪表板——能够自动化的仍然有限。因此，人类特有的探究和直觉能力，以及与好奇心相结合的能力，总会有一席之地。

然后是一些非常重要的庆祝故事，分享你所学到的东西。

* * *

## WebReduce

<svg xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 0 68 31" version="1.1"><title>Group</title> <desc>Created with Sketch.</desc></svg>