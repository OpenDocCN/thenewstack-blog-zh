# 机器学习如何将你从可观察性超载中拯救出来

> 原文：<https://thenewstack.io/how-machine-learning-can-save-you-from-observability-overload/>

随着高度分布式、复杂环境的日益采用——当然包括 [Kubernetes](https://thenewstack.io/category/kubernetes/) 和[微服务](https://thenewstack.io/category/microservices/)——[devo PS](https://thenewstack.io/category/devops/)团队比以往任何时候都更需要适当的[可观测性](https://thenewstack.io/category/monitoring/)度量，以帮助他们评估和改善系统的健康状况。

可观察性指标可用于发现“未知的未知”，以提高跨多云环境部署的系统的性能，其中多个微服务和 API 连接相互依赖地运行。

这些指标不仅对于了解如何提高应用性能和用户体验至关重要，还可以节省运营资源，例如避免过度配置。

然而……

与此同时，DevOps 团队淹没在度量中，团队解释它们并对它们采取行动变得越来越困难。组织通常缺乏正确分析数据和应用收集的信息所需的人员。

“每个人都有多个数据中心、多个内部部署和传统孤岛，他们有多个公共云提供商、边缘位置和所有这些不同的东西。与此同时，IT 行业到处都存在技能短缺，”ESG Global 的分析师斯科特·辛克莱尔说。“弄清楚你的应用程序需要什么变得越来越困难。”

## 机器学习的前景

针对 DevOps 挑战的一个有希望的解决方案是:使用[机器学习(ML)](https://thenewstack.io/category/machine-learning/) 来解释大量的可观测性数据。

例如，ML 可以用来识别可以提高应用程序运行性能的具体操作。这有助于减轻巨大的压力和资源，否则必须手动解析可观测性数据。

这样一个 ML 系统，集成了组织首选的可观察性工具，将传达操作团队应该采取的最佳行动过程。运营工程师只需验证 ML 提出的几个选项中的一个，就可以改善应用的性能和运行环境。

基于 ML 的系统还将处理可观测性数据，并为分布式 Kubernetes 和其他要优化的环境的配置提供特定的方法。自动化优化过程应该提供信息，以便例如 Kubernetes 集群能够以更低的成本更高效地运行。

“随着应用程序变得更加多样化和分布式，特别是随着 Kubernetes 和微服务的兴起，弄清楚基础设施到底需要什么变得越来越困难，”Sinclair 说。“大多数人认为他们知道，但实际上并不知道，尤其是在环境可能更加分散的情况下。

“没有人有额外的时间去检查和分析你的应用程序，并找出他们需要什么，这就是 ML 系统所做的，它可以分析你的应用程序，找出他们需要什么，并给你可操作的结果。”

ML 可以提供的可操作结果包括关于如何调整系统的具体建议。它还可以分析不同的场景，以显示某些配置设置更改时的权衡和意外情况。

辛克莱指出，当 ML 处理可观测性数据时，“更有趣的结果之一是基础设施变得更加智能。它允许您分析某个应用程序，以优化其性能或做不同的事情。”

## 不仅仅是一个智能算法

能够分析可观测性指标并为多云架构生成可操作结果的 ML 系统的概念相当简单。然而，运行在系统内部的这种计算密集型 ML 系统的算法涉及高度的复杂性。

虽然许多组织(如果不是大多数的话)缺乏在内部创建这种 ML 系统的资源，但是来自供应商的适当系统应该能够容易地证明它在简单的测试环境中是否工作。运营团队将立即知道该工具是否输出有用的和他们需要的相关的可操作的结果。

ML 系统也应该易于使用。负责 [StormForge](https://www.stormforge.io/?utm_content=inline-mention) 机器学习的副总裁 [John Platt](https://www.linkedin.com/in/john-platt-363b69103/) 说:“公司通常不一定有时间或专业知识去深入研究 Kubernetes 是如何分配资源的——他们需要一些抽象的东西，因为他们没有时间或技能来管理这些东西。

“ML 应该‘观察’可观察性数据，在某种程度上抽象出权力和抽象平衡中涉及的更好的细节，这样您就可以灵活地完成工作，同时使其在任何环境下都能工作。”

在 StormForge 的案例中，ML 被用于大规模自动化 Kubernetes 的资源效率流程。其产品包括适用于[持续集成/持续交付(CI/CD)](https://thenewstack.io/category/ci-cd/) 的测试工具，而其周三发布的 StormForge Optimize Live 工具则通过与性能测试和可观察性工具(如 Datadog 和 Prometheus)的集成来优化 Kubernetes 的生产环境。

它允许 Kubernetes 基础设施通过 ML 生成的指令进行优化，例如，调整 CPU 或内存配置，以便应用程序更有效地运行或修复性能问题。

StormForge 产品营销副总裁 [Rich Bentley](https://www.linkedin.com/in/rich-bentley-b88121/) 表示:“通过接触 StormForge Optimize Live 应用程序实际生产的生命周期的更多运营阶段，我们提出了更新应用程序配置的建议，以使其更有效地运行。

“作为一个标准的 DevOps 生命周期流程，目前还没有像这样的基础。但我们的使命是让优化成为一个系统的、持续的过程，而 ML 只是常规开发运维流程的一部分。”

## 控制成本

正如前面提到的，根据 Acquia 产品管理副总裁 [Charley Dublin](https://www.linkedin.com/in/charleydublin/) 的说法，ML 系统的基本任务是能够处理 Kubernetes 环境通常生成的大量可观测性数据，并“简化”这些数据，以便运营团队可以根据需要采取行动，Acquia 是 Drupal 应用程序的平台提供商，也是 StormForge Optimize Live 的早期采用者。

Dublin 说:“Kubernetes 涉及到如此多的变量和领域，需要在 pod 或 cluster 级别进行优化。都柏林说:“有了成吨成吨的数据，最重要的是最大似然法要过滤掉最相关的数据，这些数据会影响你的业绩或成本变量。”。

然后，它必须反复运行不同类型的测试，让您看到选择不同选项时的资源配置，因为 ML 变量将指示哪些因素影响性能，哪些因素影响成本

换句话说，ML 帮助组织在优化资源的同时降低成本，这是组织通常所缺乏的，即使他们继续支付令人惊讶的高额云提供商成本来运行 Kubernetes。

Sinclair 说:“令人惊讶的是，由于速度和质量的优化压力，降低成本往往被搁置一旁。”“通常你听到的故事是，你收到一份巨额亚马逊账单，你会说，‘天哪，我们在花什么钱？’

“通过能够利用像 StormForge 提供的 ML 工具，您能够确保您的应用程序获得他们需要的东西，而不会给您的员工带来过多的负担。但你也可以说，“我们正在减少现有生产应用的预算。”"

<svg xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 0 68 31" version="1.1"><title>Group</title> <desc>Created with Sketch.</desc></svg>