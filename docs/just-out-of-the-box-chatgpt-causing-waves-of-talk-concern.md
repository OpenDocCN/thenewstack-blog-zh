# 刚一推出，ChatGPT 就引发了一波又一波的讨论和关注

> 原文：<https://thenewstack.io/just-out-of-the-box-chatgpt-causing-waves-of-talk-concern/>

尽管这项技术正式公开只有八天，但 ChatGPT 已经吸引了大约 100 万人访问其登录页面，并迅速成为对话式人工智能领域最新的亮点。这个新的智能聊天机器人，表面上是这种类型的一个重大进步，使用了一种自然语言模型，能够与用户进行真正的智能对话。它还旨在为用户提供一般性问题的答案，为软件开发人员提供解决方案选项，从而提供全局思维。

多年来，人工智能[聊天机器人](https://thenewstack.io/chatbots-will-bring-ai-smarts-to-your-organization/)的反应一直受到限制，只能执行特定的短期任务。由 [OpenAI](https://openai.com) 开发的 ChatGPT，水平如他们来；据说它能够讲笑话(其质量显然是全面的)，编写代码，并帮助撰写大学水平的论文、营销文案和个人博客。由于聊天机器人正处于研究和反馈收集阶段，目前免费向公众开放使用，但预计这不会是一个漫长的时间窗口。

## 文本完成、代码完成

[ChatGPT](https://beta.openai.com/overview) 为[训练 AI 模型](https://thenewstack.io/dealing-with-distributed-data-when-training-ai-models/)进行文本完成、代码完成、图像生成、嵌入和微调。那么，这样的事情对企业世界，乃至整个世界到底意味着什么呢？有多可信？当然，现在知道太多还为时过早，但有些人确实有一些洞察力。

例如，[Fiddler AI](https://www.fiddler.ai/)CEO[Krishna Gade](https://www.linkedin.com/in/krishnagade/)在最近的 [LinkedIn 帖子](https://nam12.safelinks.protection.outlook.com/?url=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fkrishnagade_i-asked-chatgpt-to-write-a-poem-on-explainable-activity-7005573991251804160-ZcSq%3Futm_source%3Dshare%26utm_medium%3Dmember_desktop&data=05%7C01%7C%7Cd3c0baea63bd4f550f7708dad7148928%7Cbf0b48c768944eb6bf538621676ccee4%7C0%7C0%7C638058780505795560%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000%7C%7C%7C&sdata=7UujvLWP5ILQfNb1YtiKAov0T7R6EzpphUhNLtAwTFs%3D&reserved=0)中总结道，很明显没有解释 ChatGPT 是如何得出其结果的。

“我请 ChatGPT 以约翰·济慈的风格写一首关于可解释的人工智能的诗，这是我得到的结果，”Gade 写道。具有讽刺意味的是，我无法解释 ChatGPT 是如何得出这个结果的。尽管人们对生成性人工智能非常兴奋，但越来越多的人认为，它将导致我们无法看到、控制或解释的黑盒模型，从而成为信任、道德和问责的巨大盲点。像 Stackoverflow 这样的网站已经禁止了 ChatGPT 帖子。这是对我们整个行业的一个警示！"

## 面向客户的角色

Mindtickle 产品营销全球副总裁 Parth Mukherjee 表示，面向客户的聊天机器人主要用于对话智能或基本客户问题的联络中心，取代了自助网站或常见问题解答的需求。

慕克吉说:“ChatGPT 唯一会变得更好的是找到基本问题答案的能力。”“它不能解决的是处理客户体验的交互，这需要技巧、情感和人类体验的知识；这也是人类仍将占据上风的地方。”

“ChatGPT 确实有可能将一些基于编写内容的工作置于危险之中，例如用户手册和用户帮助网站内容。由于人工智能自动化，这种类型的工作可能会在未来几年逐渐消失，但需要更多人类智能的工作，如销售，仍将存在，因为你不能完全自动化它。”

开发人员使用 [StackOverflow](https://thenewstack.io/stack-overflow-rust-remains-most-favored-but-clojure-pays-the-most/) 来获得编码问题的正确答案。由于 ChatGPT 生成编码问题答案的速度如此之快，一些时间紧迫的用户在输入由它生成的答案时，没有先对答案进行语法分析以确保准确性。这不是个好主意。

## 补充工具

[网络安全管理提供商](https://www.linkedin.com/in/mpsencik/) [Tanium](https://www.tanium.com) 的终端安全总监马特·普森奇克告诉新栈，“ChatGPT 应该被用作你腰带上的补充工具，但它的好坏取决于它被问的问题、它被训练的模型——最重要的是——首先提出问题的大脑的理解能力。

“ChatGPT 是第一批给我留下深刻印象的聊天机器人之一，它能够被问到非常复杂的问题，然后提供一个可以理解的答复。是不是没有 bug，很完美？不，但它从未声称是，因为它仍处于测试阶段。即使一旦投入生产，它也很可能不会把所有事情都做对，因为所有的学习模型都有一些缺陷，这些缺陷会影响到个人的答案。”

[AI 安全平台制造商](https://www.linkedin.com/in/davidhabusha/?originalSubdomain=il) [Ironscales](https://ironscales.com) 产品管理高级副总裁大卫·哈布沙告诉 TNS，“需要注意的是 [OpenAI](https://thenewstack.io/openais-gpt-3-makes-big-leap-forward-for-natural-language-processing/) 设计界面是为了拒绝可能不合适或有害的请求。以这种可访问的方式向公众提供这种最新模式的原因之一是测试和获取反馈(学习到的或直接的)，以提高其拒绝此类请求的能力。

“根据他们关于 ChatGPT 的博客帖子:“虽然我们努力让模型拒绝不适当的请求，但它有时会对有害的指令做出反应或表现出有偏见的行为。我们正在使用[审核 API](https://openai.com/blog/new-and-improved-content-moderation-tooling/) 来警告或阻止某些类型的不安全内容，但我们预计目前会有一些误报和漏报。我们渴望收集用户反馈，以帮助我们不断改进这个系统。"

## 安全呢？

安全性是一个问题。Habusha 说，在目前的状态下，ChatGPT 可以用来创建用于网络钓鱼、商业电子邮件泄露攻击和其他基于欺骗的计划的“成分”。

“这些类型的攻击通过令人信服和命令式的指令击中了人类的弱点，通常是基于恐惧或对损失的恐惧——例如，“验证你的身份，以确保你的账户不会被关闭”——通过提供坏人正在寻找的信息，”他说。

“每个人都熟悉使用不寻常的语言、糟糕的语法和拼写的网络钓鱼邮件。在我们最近的一次测试中，我们能够使用 ChatGPT 来写这样一封邮件。这份请求是一位首席执行官发给员工的备忘录，宣布一项新的股票期权计划。测试中使用的指令没有任何可检测到的恶意信号，但这样的电子邮件可以用来迫使收件人点击有害的链接或附件。”

ChatGPT 需要新的安全方法吗？

“对于信息和网络安全，人工智能和机器学习已经被要求检测人工智能支持的攻击，而人类和传统的基于规则和政策的安全技术无法检测到这些攻击。人工智能支持的攻击不仅太有说服力，而且对于传统方法来说，它们也非常有针对性或短暂，”哈布沙说。

这个对话还在继续。

<svg xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 0 68 31" version="1.1"><title>Group</title> <desc>Created with Sketch.</desc></svg>