# 将 AI/ML 用于对象存储的架构师指南

> 原文：<https://thenewstack.io/the-architects-guide-to-using-ai-ml-with-object-storage/>

随着企业的不断进化，机器学习和人工智能已经成为董事会层面的举措。

 [布莱恩·科斯塔

Brian 是 MinIO 的高级技术高管，他专注于多云机器学习和人工智能用例。此前，Brian 曾在 Fidelity Investments、State Street、Progress 和 Manetu 领导人工智能/人工智能项目。此外，Brian 还是几家初创公司的创始人，包括 Power Control Solutions 和 BuySideFX。](https://www.linkedin.com/in/costabrian) 

抛开市场宣传不谈，随着 AI/ML 融入到每一个软件栈和架构中，几年前看起来近乎神话的功能现在被认为是理所当然的。这被称为人工智能优先的架构。

在人工智能/人工智能的世界中，重点是找到准确捕捉数据中错综复杂关系的模型，并使用这些模型通过准确的预测来创造商业价值。

AI/ML 的现实是，在这个崇高的目标实现之前，需要大量的数据处理。尽管对 AI/ML 的宣传和关注集中在使用最新、最酷的建模技术上，但一次又一次的事实表明，通过适当的数据管理和找到一种将数据呈现给模型的方法，以便模型在训练时学习细微差别，可以实现对复杂关系建模能力的最大收益。

简而言之，主要是关于数据，而不是模型。

在构建人工智能优先的架构时，有几个关键要求，特别是当它与存储相关时。在架构师指南的这一部分中，我们将概述什么需要考虑以及为什么。

## **可扩展性**

设计 AI/ML 架构首先要考虑的是可扩展性。虽然可伸缩性有多个方面，但我们主要关注数据基础架构的可伸缩性。一些非常有趣的工作正在受限制的环境中进行，在这些环境中没有太多可用的训练数据，然而最好的结果仍然来自于在涉及非常大规模训练的用例中进行的工作。

大规模训练不是几百 TB——往往是几十到几百 Pb。从管理和性能角度来看，这一容量都超过了旧式 SAN/NAS 体系结构的能力。

一旦你通过了几个 Pb，你就看到了对象存储。对象存储是唯一适合这种规模的问题的，因为它可以无限扩展，跨网络扩展，并随着您的增长提供线性性能。

此外，对象存储天生适合不同类型的数据—半结构化、非结构化、结构化。随着访问数据的 AI/ML 框架寻求创建功能，越来越多不同类型的数据变得重要，在单一位置存储、版本化和管理所有这些数据的能力变得非常重要。

此外，随着这些不同类型的数据增长到许多 PB 领域，为不同类型的数据建立和维护不同的存储解决方案变得非常昂贵。将持久性整合到对象存储中可以节省基础设施成本。

## **RESTful API/S3**

由于前面提到的关于可伸缩性的需求，几乎每个 AI/ML 平台都支持对象存储。对象存储为所有类型的训练数据提供了单一存储库，并且可以几乎无限地扩展。单一存储体系结构简化了部署并降低了运营成本。

S3 API 是对象存储的事实上的标准，因此，它是 AI/ML 数据架构领域的事实上的标准。事实上，大多数现代 AI/ML 平台都是为 S3 API 构建的，后来通常由社区进行扩展，以支持遗留的 SAN/NAS 解决方案。

理由很简单:RESTful APIs 是设计分布式软件系统和对象持久性的现代方法，S3 正好符合这个定义。再加上部署在 [AWS](https://aws.amazon.com/?utm_content=inline-mention) 上并使用 S3 构建的 AI/ML 项目的流行，很明显 S3 API，即对象存储，是大规模 AI/ML 项目的有效需求。

可以用 POSIX(可移植操作系统接口)做小范围的工作吗？是的，但那是更多的沙盒工作。对于真正的大规模人工智能/人工智能，S3 将是你的数据基础设施的 API。

## **对象锁定(监管或合规保留)**

在受监管的环境中，如金融服务、医疗保健和政府部门，对象锁定就是赌注。话虽如此，但并不是所有的对象存储都支持对象锁定，而且很少针对操作部署进行了优化。

核心功能是确保一个对象在一段时间内不会被删除或覆盖。需要适应不同的模式，但总体目标是确保在源上不会发生篡改。版本控制很容易适应。

这对于 AI/ML 模型和训练文件尤其重要，因为它们的目标是将被操作化的科学实验。确保训练数据的有效性与验证模型本身一样重要。

## **对象生命周期管理**

现代企业中的模型不是一成不变的。久而久之和越来越多不同的数据变得可用，模型需要相应地更新。这不应该是一个手动过程，因为这将使模型从一开始就是静态的。

对象存储可以提供完整的生命周期管理功能。这包括随着型号老化从热层到热层的分层，以及管理有关数据更新、转换和删除的策略。

与这个领域相关的是对象存储近乎无限的可伸缩性。在一个你能想象多少存储就有多少存储的世界里，它们都可以存在于单个名称空间中。从对象生命周期管理的角度来看，这提供了无数的可能性——所有这些都通过 RESTful APIs 实现了自动化。

在一个名称空间中包含不同的数据类型大大简化了数据管理和验证过程。在规模上，这提高了运营效率并节省了资金。

## **性能**

与规模一样，性能也有多个方面。在讨论大规模性能之前，我们先来看看读写性能。

发现给定模型的一组超参数来优化训练能力是具有挑战性的。没有办法用给定的训练数据集先验地确定给定模型的最佳超参数。

超参数调整与其说是一门科学，不如说是一门艺术，通常归结为对每个参数范围内的离散点进行智能或非智能搜索，直到找到合适的集合为止(“网格搜索”)。

更复杂的是，在给定一组选定的超参数的情况下，模型在整个训练过程中的收敛速度不是线性的，这意味着当在给定的训练集上为给定的模型评估给定的一组超参数时，必须允许每个模型完成收敛训练，以便评估所得模型的适合性和超参数集的可取性。

简单地说:它可以是大量重复的试错训练。对于非常大的数据集，需要大量阅读训练文件。

在当前的“Auto ML”库中，这些工作对数据科学家或开发人员来说是隐藏的。只是因为它被隐藏并不意味着它没有发生。随着我们将训练集群的规模增加到数百或数千个计算节点，以便并行化“Auto ML”流程，我们会创建一个给定训练文件被读取数百或数千次的情况。

如果该训练文件很大，那么 I/O 量的增加速率大约等于被评估模型的数量乘以我们决定测试的每个超参数的离散点的数量乘以给定模型的超参数的数量。

简而言之，从持久性存储中读取训练文件的性能很重要。您可以随意优化代码，但是模型训练仍然依赖于读取性能。缓存当然有所帮助。但归根结底，这是一个文件 I/O 挑战。

多快才算快？对于上下文，运行在 [NVMe 的 32 个节点上的 MinIO 以 325 GiB/sec](https://min.io/resources/docs/MinIO-Throughput-Benchmarks-on-NVMe-SSD-Speedtest.pdf) 的速度读取。这应该是 AI/ML 设置的目标。

## **更复杂的 AI/ML 用例——Lambda 计算事件**

一旦开发出一个看起来运行良好的模型，通常需要在投入生产之前进行验证。在金融服务组织中，这通常由单独的模型验证团队来完成，这不属于数据科学开发工作的一部分。他们是有意分开的，任务是验证组织使用的数学/模型的正确性。除了验证模型的正确性之外，模型验证团队通常还负责测试和理解模型在各种未预料到的不利经济条件下的表现，这可能不是模型训练的一部分。

例如，如果我们讨论的是金融模型，并且使用的训练数据是最近的历史数据，这是很常见的，那么模型验证团队可能会根据不利数据运行模型，例如大萧条或全球冲突时期(如战争、极端市场波动、反向收益率曲线或负实际利率)的历史数据。他们也可以用理论数据测试模型，以评估稳定性。模型验证团队在评估数学/模型的行为以及组织的整体风险方面发挥作用。这可是不小的努力。

为了用对象存储操作 AI/ML，一个真正强大的特性是 Lambda 计算事件(LCE)。LCE 有助于自动化这一复杂的模型验证工作流程。通常，为建模过程生命周期中的每个步骤创建单独的存储桶，并且使用 LCE 来通知相关方新对象到达每个存储桶。该事件触发模型进展阶段的适当处理，以及满足法规遵从性要求或内部检查所需的任何业务级审计。

## **总结**

尽管最近的技术炒作让我们都相信，找到下一个伟大的、复杂的建模方法是数据科学的圣杯，但在实践中，真正为组织创造价值的是数据的收集和适当的监管，以及保证建模过程的安全性和可重复性的适当操作。MinIO 本质上提供了在现代企业中促进大规模 AI/ML 的创建和使用所需的能力。

<svg xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 0 68 31" version="1.1"><title>Group</title> <desc>Created with Sketch.</desc></svg>