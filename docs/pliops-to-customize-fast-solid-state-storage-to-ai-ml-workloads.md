# 根据 AI/ML 工作负载定制快速固态存储

> 原文：<https://thenewstack.io/pliops-to-customize-fast-solid-state-storage-to-ai-ml-workloads/>

机器学习(ML)和其他更高级的软件开发将需要硬件制造商争相提供的计算能力——尤其是在预测的 ML 应用需求飙升之前。

为此，包括芯片巨头英特尔在内的一批投资者在软银的带领下向以色列的存储处理器制造商 Pliops T1 投资了 3000 万美元。

该公司表示，预计开发人员将能够在年底该设备预计推出时利用 Pliops 存储技术。

Pliops 总裁兼首席商务官 [Steve Fingerhut](https://www.linkedin.com/in/stevefingerhut) 表示，除其他外，该技术将支持 ML 软件存储栈，并将以多种方式提供，包括作为云原生开发者和应用程序的服务。

最近，组织在标准 CPU 和服务器上开发和运行 ML 应用程序时遇到了瓶颈。然而，在适应随之而来的数据爆炸方面，差距越来越大，尤其是在云上。

Fingerhut 说:“云中的数据管理涉及到许多软件元素，这两条线使它产生了分歧。”“它开始真正给数据中心带来许多麻烦和蔓延。我们不只是在 ARM 上卸载和运行它，它是专门为加速这些更高层的数据管理而构建的产品。”

对于更有助于将机器学习和其他高级应用所需的高度密集计算与存储(特别是闪存)配对的硬件，也出现了必要性。 [Objective Analysis](https://objective-analysis.com/) 的分析师[吉姆·汉迪](https://objective-analysis.com/jim-handy/)说，通过这种方式，Pliops 技术旨在消除降低闪存(将位存储在 SSD 中)性能的抽象层。

“在我们拥有固态硬盘之前，没有人太在意这些层有多慢，因为它们对访问硬盘上的数据的整体延迟贡献很小。现在，固态硬盘比硬盘快大约 1000 倍，这些层大大增加了整体延迟，”Handy 说。“通过移除它们，计算可以以同样的成本运行得更快。因此，简而言之，Pliops 让计算机速度更快，而没有增加太多成本。”

Fingerhut 说，从一开始，Pliops 的 R&D 团队就着眼于代码的主要部分和正在执行的功能。“所以，我们说，‘好吧，他们有处理 VIO 和数据管理的 API。“我们将提供同样的 API，但我们将以完全不同的方式执行功能，”Fingerhut 说。[功能将变得]高效，针对硬件进行了优化，从多层到驱动器都有软件堆栈，同时消除了所有冗余，并从一张白纸的角度出发以最高效的方式实施。"

发展的时机很好，[企业管理协会(EMA)](https://www.enterprisemanagement.com/) 的分析师 Torsten Volk 说。

“简而言之，NAND 存储以线性方式扩展，而 AI/ML 的存储需求只是处于指数增长期的开始，这是由主流用户越来越多地使用 AI/ML 技术推动的，”Volk 说。

在许多方面，Pliops 和其他人正在解决软件堆栈开发的一个非常现实的问题，在 Pliops 的情况下，随着 AI 和 ML 应用程序开发的起飞，存储也是如此。

“我个人的估计是，目前只有不到 1%的人工智能/人工智能项目能够启动，因为人工智能/人工智能技术太难部署和成功运营，”沃尔克说。“随着 AI/ML 开始最终为企业内的每个人所用，企业可能会训练成千上万个模型，而不是每个月训练几个 AI/ML 模型，每个模型在容量和性能方面都有很大的存储需求。”

通过 Pixabay 的特征图像。

<svg xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 0 68 31" version="1.1"><title>Group</title> <desc>Created with Sketch.</desc></svg>