# 脑机接口如何让我们暴露在黑客攻击和操纵之下

> 原文：<https://thenewstack.io/brain-computer-interfaces-expose-us-hacking-manipulation/>

一种可以直接连接你的脑电波与外部设备进行交流的设备的想法似乎是非常未来的事情，但事实是，这些组件已经存在。这些所谓的[脑机接口](https://en.wikipedia.org/wiki/Brain%E2%80%93computer_interface) (BCIs)或脑机接口(MMIs)可以让[残疾人控制假肢](https://thenewstack.io/control-robotic-arm-mind-using-machine-learning/)(如手臂)，只需用他们的思想指挥它。

有一天，这样的技术可能会帮助[的老年人控制他们的辅助外骨骼](https://www.sciencedaily.com/releases/2015/08/150817220240.htm)。研究人员还在研究这些设备如何帮助工厂工人用他们的思维控制机器人，或者司机管理他们的无人驾驶汽车。像 Neuralink 的 Elon Musk 这样的企业家正在推动在未来几年内开发微小的可植入脑机接口，这将有助于增强人类的自然智能，这样他们就不会被人工智能机器的快速发展完全超越。

脑机接口和其他神经技术广泛融入社会可能还需要一段时间。但是，一个由科学家、临床医生、伦理学家和人工智能专家组成的国际跨学科小组在最近发表在[](https://www.nature.com/news/four-ethical-priorities-for-neurotechnologies-and-ai-1.22960)*自然杂志上的一篇文章中警告说，应该更深入地检查和讨论神经技术的影响、最佳实践和伦理，以防止未来出现问题。他们指出，虽然这些技术可能有很大的好处，但如果不仔细考虑和监督，它们也可能产生深远的负面影响。*

 *“这种进步可能会彻底改变许多疾病的治疗，从脑损伤和瘫痪到癫痫和精神分裂症，并改善人类的体验，”专家组写道。“但这项技术也可能加剧社会不平等，并为企业、黑客、政府或其他任何人提供剥削和操纵他人的新方式。它可能会深刻地改变人类的一些核心特征:私人精神生活、个体能动性以及对个人作为受其身体约束的实体的理解。”

特别是，他们指出了脑机接口即将到来的发展，这些发展由像 [Neuralink](https://thenewstack.io/elon-musks-neuralink-wants-enhance-humans-symbiosis-superintelligent-ai/) 和 [Kernel](https://thenewstack.io/biomedical-startup-augments-human-intelligence-electric-stimulation/) 这样的公司带头，创造了将人类直接连接到“强大的计算系统”的无线设备，这些系统不仅能够“读取”人类的大脑活动，还能够将神经数据“写入”大脑。根据该组织的说法，他们预见到技术变革的速度将远远超过政府或社会的适应能力，从而导致一个未知且潜在危险的领域，用户及其数据不仅可能被利用来获取经济利益，甚至可能失去自我意识。

特别是，该小组确定了新兴神经技术领域中需要“立即行动”的四个主要领域:保护隐私和建立给予或拒绝同意的方法；面对神经技术化的集体，保护个体的能动性和身份；处理人类增强的社会影响，并对抗[算法偏差](https://en.wikipedia.org/wiki/Algorithmic_bias)。

## 神经权利

毫无疑问，隐私是重中之重。大公司和广告商已经可以获得难以想象的庞大个人信息宝库，在算法的帮助下，这些信息可以帮助他们以令人毛骨悚然的准确度锁定广告。神经营销是下一步:随着 BCIs 读取(甚至覆盖)我们的生物或情绪状态，这些更精细的神经数据可以被公司用于他们的利益。

“我们认为，公民应该有能力——也有权利——保护他们的神经数据隐私，”该组织写道。"我们建议严格监管神经数据的销售、商业转让和使用."神经数据的集中处理也应该受到限制。替代计算方法，如"[联合学习](https://research.googleblog.com/2017/04/federated-learning-collaborative.html)(即。大规模、分散的机器学习)和基于区块链的方法可以用来透明地跟踪数据，从而可以更好地保护用户的隐私。

除了隐私问题，我们的身份和自我意识的本质可能会被神经技术以无法量化的方式改变。如果几个大脑被连接在一起协同工作，这些情况可能会被进一步放大，导致对个体机构的潜在抑制，其中[抵抗变得无效](https://en.wikipedia.org/wiki/Borg_(Star_Trek))。

“神经技术显然会扰乱人们的认同感和能动性，动摇关于自我和个人责任本质的核心假设——法律或道德，”作者写道。“如果机器学习和大脑接口设备能够更快地将意图转化为行动，人们最终可能会以自己难以声称的方式行事。”

为了解决这个问题，该小组建议保护人类的“神经权利”,以确保精神和身体身份的完整性，以及我们在没有神经操纵的情况下自由选择的意愿。

## “扩大军备竞赛”

专家们还预计可能会出现“增强军备竞赛”，政府创造“[超级士兵”](https://thenewstack.io/darpa-tech-will-treat-disease-electricity-light-sound-magnetic-fields/)或普通公民增强自身能力以获得新的能力或重获失去的能力。

该小组解释说:“采用增强神经技术的压力，例如那些允许人们从根本上扩展其耐力或感官或心理能力的技术，可能会改变社会规范，提出公平获取的问题，并产生新形式的歧视。”除了设备本身，作者还强调，系统的算法必须纠正任何可能使社会不平等永久化的偏见。

最终，该组织呼吁国际科学界和政府走到一起，讨论“负责任的神经工程”将会是什么样子:什么是允许的，什么是不允许的，为什么？如何保护用户及其数据和身份？如何防止基于增强的歧视？随着这些伦理界限的辩论和划定，公司、机构和社会如何以造福人类的方式向开发者、工程师和研究人员灌输这些价值观？没有快速简单的答案，但是在继续前进之前，我们至少应该问这些问题。

图片:亚历克斯·伊比

<svg xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 0 68 31" version="1.1"><title>Group</title> <desc>Created with Sketch.</desc></svg>*