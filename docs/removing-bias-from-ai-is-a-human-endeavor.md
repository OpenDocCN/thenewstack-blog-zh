# 消除人工智能的偏见是人类的努力

> 原文：<https://thenewstack.io/removing-bias-from-ai-is-a-human-endeavor/>

麦肯锡全球研究所最近[报告](https://www.mckinsey.com/featured-insights/artificial-intelligence/notes-from-the-ai-frontier-modeling-the-impact-of-ai-on-the-world-economy)称，采用所有五种人工智能形式的公司——计算机视觉、自然语言、虚拟助手、机器人流程自动化和高级机器学习——将比其竞争对手受益更多。然而，在组织能够享受人工智能的好处之前，他们必须确保他们用于计划的数据是可用的和无偏见的。

毕竟，[机器学习](/category/machine-learning/) (ML)算法的好坏取决于它们被训练的数据。而且，一个令人担忧的趋势正在显现，那就是有偏见的算法。为了消除算法偏差，组织必须首先确保他们使用的训练数据尽可能没有偏差。

ML 训练数据中的偏差可以采取多种形式，但最终结果是它会导致算法错过特征和目标输出之间的相关关系。无论您的组织是小型企业、全球企业还是政府机构，在人工智能(AI)计划的每个阶段，您都必须减少训练数据中的偏差。

## 训练数据让 AI 发挥作用

机器学习模型通常分三个阶段构建:训练、验证和测试。在训练阶段，大量数据被标注——由人类或其他方法标记——并输入到机器学习算法中，以获得特定的结果。该算法在训练数据中寻找将输入数据属性映射到目标的模式，然后输出捕获这些模式的模型。为了使模型有用，它需要准确，而准确需要指向必要目标或目标属性的数据。验证和测试有助于改进和证明模型。

## 高质量的训练数据必须是无偏的训练数据

机器需要大量的数据来学习。准确地标注训练数据和学习算法本身一样重要。最大似然模型在准确性方面不足的一个常见原因是它们是基于有偏见的训练数据创建的。

如果没有高质量、无偏见的数据来训练机器学习模型，对人工智能计划的投资就是浪费金钱。印孚瑟斯最近的一项研究发现，49%的 IT 决策者报告说，他们的组织无法部署他们想要的人工智能技术，因为他们的数据还没有准备好支持人工智能技术的要求…

## 什么导致了训练数据偏差，后果是什么？

 [彭伟信

Wilson Pang 于 2018 年 11 月加入阿彭，担任首席技术官，负责公司的产品和技术。Wilson 在软件工程和数据科学领域拥有超过 17 年的经验。在加入阿彭之前，Wilson 是携程中国的首席数据官，携程是全球第二大在线旅行社公司，他带领数据工程师、分析师、数据产品经理和科学家改善用户体验，提高运营效率，推动业务发展。在此之前，他是加利福尼亚州易贝的高级工程总监，领导过多个领域，包括数据服务和解决方案、搜索科学、营销技术和计费系统。在易贝之前，他在 IBM 担任架构师，为各种客户构建技术解决方案。Wilson 在中国浙江大学获得了电子工程硕士和学士学位。](https://www.linkedin.com/in/wilsonpang/) 

工程师和数据科学家，以及首席技术官等高管角色，应该仔细考虑他们在构建人工智能解决方案时固有的偏见，并尽可能纠正这些偏见。

ML 模型的偏差——或“机器偏差”——可能是不平衡数据的结果。想象一个电子商务网站的搜索查询分类器的数据集，预测给定搜索词“女鞋”的相关结果一个典型的数据偏差示例可能是一个主要由高跟鞋、凉鞋和靴子组成的数据集，只有很少的运动鞋样本。用这种不平衡数据集训练的分类器模型将严重倾向于与给定样本数据一致的鞋子，并且无法将相关结果返回给正在寻找女子网球鞋的人。这是行动中的偏见。直截了当，但纠正至关重要。

随着机器学习项目变得越来越复杂，需要识别微妙的变量，以完全公正的方式对训练数据进行人工注释变得至关重要。在训练数据时，人类的偏见可能会对机器学习模型的准确性造成严重破坏。设想创建一个 ML 模型，目的不仅是区分洗衣机和干衣机，而且是区分电器的状况。

如果您有一个内部人员团队对用作训练数据的图像进行注释，他们必须坚持完全公正的方法对图像进行分类。假设他们将按性别对各种鞋子进行分类，这可能是对许多款式的主观判断。如果没有多样化的方法，您可能会创建一个不太准确的机器学习模型。

例如，如果你的移动应用基于在特定价格范围内的特定条件下搜索电子商务网站的能力，一个有偏见的、不准确的 ML 模型不会推动成功所需的采用。

## 我们如何确保我们的训练数据没有偏差？

为了帮助确保最佳结果，组织必须拥有由不同成员组成的技术团队，负责构建模型和创建训练数据。除了建立一个多元化的团队，组织在试图减少数据中的偏差时，还应该考虑以下建议。

*   如果训练数据来自内部系统，尝试找到最全面的数据，并使用不同的数据集和指标进行实验。
*   如果训练数据是由外部合作伙伴收集或处理的，那么招募多样化的人群进行注释是很重要的，这样数据才能更具代表性。
*   正确设计数据注释任务，并仔细传达说明，以便在不知道数据将如何使用的情况下，群众能够正确执行任务。了解数据的用途可能会影响注释者的判断。
*   一旦创建了训练数据，检查数据是否有任何隐含的偏差是很重要的。

## 减少机器偏差是人类的责任

在内部执行数据注释的组织可能会发现，很难可视化高维训练数据并检查偏差。ML 团队应该定期验证机器学习模型并测试偏差。在一天结束时，重要的是要记住，机器学习算法将像收集、情境化和提供训练数据的人一样有偏见。虽然在人工智能采用的竞赛中领先于竞争对手可能对商业成功至关重要，但重要的是要记住，人类仍然必须监督算法。

最终，由我们——首席技术官、首席执行官、首席信息官、数据科学家、机器学习工程师和产品经理——来决定机器学习算法的发展道路。作为人工智能从业者，我们应该仔细考虑我们在创造这些技术时固有的偏见，并加以纠正。

通过 Pixabay 的特征图像。

<svg xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 0 68 31" version="1.1"><title>Group</title> <desc>Created with Sketch.</desc></svg>