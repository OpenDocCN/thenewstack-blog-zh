# 利用实时数据提高客户参与度

> 原文：<https://thenewstack.io/boost-customer-engagement-with-real-time-data/>

实时经济正在到来——硅谷的技术颠覆者正在评估你的行业。

“数字优先”对企业来说已经足够的日子已经一去不复返了:在后大流行时代，在线池非常拥挤，数年的数字迁移[被压缩在短短几个月内](https://www.microsoft.com/en-us/microsoft-365/blog/2020/04/30/2-years-digital-transformation-2-months/)。超过一半的组织(53% )现在拥有企业范围的数字化转型战略。

区别在于实时性。那些成功的人将是分析公司 IDC 所称的“数字优先发烧友”——那些在客户参与方面进行创新的人。这可能是通过他们使用实时数据管理和处理技术，在客户网上购物或网上银行时提供量身定制的服务，或者他们在交易中识别和处理欺诈活动的能力，或者在机器损坏前更换零部件。

这种互动是硅谷巨头和越来越多的数字化纯创业公司擅长的。例如，[亚马逊和网飞在他们各自的购物和电影领域通过提供](https://digital.hbs.edu/platform-digit/submission/the-origin-of-netflixs-success/)[个性化](https://netflixtechblog.com/artwork-personalization-c589f074ad76?gi=a60ffca1c4eb)服务和定制产品，重新定义了客户体验。

> 简而言之:深入了解客户。

亚马逊在这里解释说，这不仅仅是挑战，而是如何克服它的需求:“亚马逊选择众多的问题之一是它太多了。对于亚马逊来说，深入了解客户，让客户轻松找到他们想要的东西变得至关重要。”

简而言之:深入了解客户。

要做到这一点，意味着要建立一个 360 度的客户视图，这个视图是“新鲜的”,具有基于实时行为和需求的最新见解。建立这种全新的视图需要将流事件数据与静态系统中的历史数据相结合，这些流事件数据来自网站点击、机器通信和设备交易等在几毫秒内生成的动作，可以说明当前发生的事情，而历史数据则提供了上下文并有助于确定这些事件的价值。这必须在需要的精确时刻交付，使其具有可操作性，而不是等待数据库写入数据。

实现这一目标需要能够进行实时流处理的 IT 基础设施。然而，尽管许多人可能认为他们正在走向实时，但他们错了。

## **事实上的** **但没有数据库**

阿帕奇卡夫卡已经成为实时流式传输事件数据的事实上的标准。事实证明，这种开源事件流技术因其速度快、易于实现而在一类特别重要的 IT 采纳者中广受欢迎:开发人员。流分析公司 Swim 的“流数据状态”报告[发现](https://www.businesswire.com/news/home/20210913005172/en/New-Survey-Shows-Significant-Opportunities-for-How-Enterprises-Can-Use-Event-Driven-Data-Applications-and-Analytics-to-Improve-Customer-Experience)近一半的组织正在流中产生洞察力，Kafka 是使能技术的首选。

值得注意的是，Swim 忽略了流媒体技术堆栈中的一个关键企业数据，它是丰富的上下文数据的来源，对于构建 360 度视图非常重要:快速数据存储。

正如 Swim 首席执行官 Ramana Jonnala 所指出的，将数据保存到“易延迟的数据存储”会限制组织“对关键业务事件做出快速响应和行动的能力。”

> 构建实时应用程序意味着用实时流处理平台重新思考您的架构，这种平台能够快速接收和处理来自不同来源的数据。

提取、转换、加载(ETL)是一个障碍:写入大量流数据、运行聚合、处理和呈现结果在历史上是在一天结束时成批完成的，但现在是以微批处理的形式。该序列中的每一步都会引入延迟，导致数据进一步落后于事件，并限制其价值。

构建实时应用程序意味着使用实时流处理平台重新思考您的架构，这种平台能够快速接收和处理来自不同来源的数据，无论是网站交易等流数据还是 CRM 或其他数据库等记录系统等静态数据。

那个流数据平台的标志是什么？

*   **流传输:**这是一种“管道”,能够将数据从源传输到接收器，这是一种软件功能，有助于连接和传递来自各种数据源的数据，这些数据源发出的信息被称为事件。
*   **流媒体引擎:**这是获取、转换、分发和同步数据的关键。它应该能够处理生成的数据，并将结果反馈给你的分析。引擎应该能够连续处理流中的数据，并包括诸如窗口功能以查看给定时间段内的数据，以及水印功能以处理失序事件。它还应该具备仅从状态快照重启作业的能力，以实现弹性、一致性和可用性。
*   **数据处理:**实时数据的丰富和处理需要快速一致的分布式计算。当必须在无法保证处理和网络可用性的大型环境中处理数据时，这是一个挑战。

答案是利用您可以支配的资源:利用本地服务器和集群中的内存池进行处理，这样数据就不需要通过网络传输到数据中心，也不需要用额外的硬件来增强本地处理。流媒体引擎应该与该计算层集成，以实现大规模性能。内存架构可提供实时分析所需的亚毫秒级响应，每秒可执行数百万次复杂的事务，以将存储数据与流数据相结合。

*   **机器学习界面:**这张地图中的最后一英里是机器智能。ML 提供了潜在的自动化，以智能地与客户互动并进行大规模交易，然而大约一半的 ML 项目[未能从试点进入生产。缩小差距意味着使机器模型可操作。要实现这一点，需要一个内存网格接口，它既能跨集群进行自动并行处理，又能在不同的流水线中共享机器模型。这提供了规模、性能和可靠性，而无需额外的编码或硬件。](https://www.gartner.com/en/newsroom/press-releases/2022-08-22-gartner-survey-reveals-80-percent-of-executives-think-automation-can-be-applied-to-any-business-decision)

## **结论**

在实时经济中取得成功需要一种新的信息架构，这种架构具有实时流处理能力，能够支持涡轮增压分析、客户促销、监控等。它必须在投入和产出不断变化的极其紧张的时间窗口内做到这一点。

<svg xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 0 68 31" version="1.1"><title>Group</title> <desc>Created with Sketch.</desc></svg>