# Kubernetes:异构 GPU 集群上的分布式深度学习

> 原文：<https://thenewstack.io/kubernetes-distributed-deep-learning-on-heterogeneous-gpu-clusters/>

[](http://www.mapr.com/)

[![](img/c961b50ea671d5a8d45e86187a4aac63.png)](http://www.mapr.com/) [董萌，MapR 数据科学家

董萌是 MapR 的数据科学家，他帮助客户解决大数据的业务问题，将客户数据的价值转化为可操作的见解或机器学习产品。他最近的工作包括将 PredictionIO 和 XGBoost 等开源机器学习框架与 MapR 的平台集成。他还创建了时间序列 QSS 和深度学习 QSS 作为 MapR 服务产品。董在统计机器学习、数据挖掘和大数据产品开发方面拥有多年的经验。此前，他是 ADP 的高级数据科学家，利用工资单数据为人力资源构建机器学习管道和数据产品，为 ADP Analytics 提供支持；他还是 IBM SPSS 的软件工程师，是构建 Watson analytics 团队的一员。在俄亥俄州立大学读研究生期间，董担任研究助理，主要研究压缩感知和从贝叶斯角度解决点估计问题。](http://www.mapr.com/) 

深度学习是一类机器学习算法，它学习数据的多种级别表示，潜在地降低了产生可以解决困难问题的模型的难度。在最困难的问题中，这种减少表现为可以做的事情的进展。在更简单的问题中，它可能会导致性能的提高或建模过程的简化。许多深度学习应用程序现在超过了人类的表现，例如在图像识别、下棋或围棋方面。其他著名的用例包括最有能力的系统使用深度学习的部分领域，包括语音识别、文本识别、机器翻译和自动驾驶。

这种性能很大程度上是由于机器学习数学的最新进展，但至少有一部分是由于原始计算性能的进步和利用这种性能的技术的改进。

许多组织已经开始探索在集群上以分布式方式训练和服务深度学习的方法。许多人选择构建一个专用的 GPU HPC 集群，该集群在研究或开发环境中运行良好，但一个始终存在的问题是，随着训练数据的准备，数据必须在集群之间来回移动，以用于训练和服务。通常，存在多个模型训练群集，这只会使数据移动的问题变得更糟。光是这样的数据移动就已经是相当大的成本，但是将数据存储在多个位置会导致管理用于训练深度学习模型的数据以及管理研发和生产之间的模型的高度复杂性。

在本文中，我们将概述一些我们用来使分布式深度学习更容易训练和服务的技术。我们在由异构 GPU 和 CPU 资源组成的环境中这样做。一个关键的结果是，分布式深度学习训练工作流可以变得更简单。我们还描述了如何利用流架构在 GPU 上实现全局实时深度学习应用。

## 深度学习模型的分布式训练

我们发现，对于构建一个更加简单的机器学习和服务管道来说，以下能力是必要的，也是充分的:

*   所有数据，无论是存储在流、表还是文件中，都可以使用传统的基于目录的路径名树来组织和访问。
*   所有数据都以完全分布式的方式存储，但可以从任何使用相同路径名的授权计算机上访问。
*   所有数据都可以通过标准的 POSIX 文件操作来访问。
*   卷是可用的，它允许根据那些目录的内容存储在哪里来管理目录结构。
*   所有数据访问的性能都达到或非常接近硬件极限。密切相关的限制是非本地数据的网络带宽和计算过程本地数据的本地磁盘速度。

## 数据要求

我们提出的分布式深度学习解决方案有三层；底层是数据层，由数据服务管理，使您能够为您的培训数据创建专用卷，并为组织提供机会，使深度学习开发、培训和部署更接近他们的数据。数据层应支持安全性、快照和镜像等企业功能，以在企业环境中保持数据的安全性和高度可管理性。

中间层是编排层，我们建议使用 Kubernetes 来管理 GPU/CPU 资源，并以 pods 为单位启动参数服务器和训练工人来完成深度学习任务。中间层还应该支持异构集群，其中您可以使用 CPU 节点来服务模型，同时使用 GPU 节点来训练模式。高级功能将支持用不同的 GPU 卡标记节点的能力，以便您可以在较旧的 GPU 卡上启动较低优先级的任务，并在较新的卡上启动高优先级的任务。

顶层是应用层。在这一层中，对深度学习工具(如 Tensorflow)的支持用于利用模型输出，然后将它们投入部署。一种最佳设计是将某个分布式训练作业的训练数据存储在位于相同计算节点的网络邻居中的容器中，以减少网络拥塞。需要支持 Docker 等容器技术和 Kubernetes 等编排技术，以分布式方式部署 Tensorflow 等深度学习工具。根据同样的概念，您可以为了 CPU/GPU 计算而协同定位数据。借助可水平扩展的底层数据，数据可以通过高速数据流持续流入 GPU，从而避免计算资源匮乏。

## 部署应用程序

在我们提出的分布式深度学习解决方案上，通常有 5 个步骤来将您的深度学习应用投入生产。

1.  修改 Tensorflow 应用程序以添加分布式服务器，有多种方法可以在 Tensorflow 中启用数据并行。总体而言，同步训练和图间复制是更实用的方法(单击此处了解更多信息)，例如，在 Tensorflow 中，我们可以添加如下代码片段:

```
cluster  =  tf.train.ClusterSpec({"ps"  :  "tf-ps0:2222,tf-ps1:22222",

      "worker":  "tf-worker0:2222, tf-worker2:2222"})

server  =  tf.train.Server(cluster,  job_name='ps',  task_index=0)

```

其中 ps/worker 主机名、作业名、任务索引可以通过用于启动 Kubernetes pods 的 YAML 文件传递。您还可以将代码放在分布式数据系统中，并在启动 Kubernetes 作业时将其挂载到多个 pods。

2.  准备训练数据，并将其加载到分布式数据系统上，最佳实践是为不同的深度学习应用程序创建专用的逻辑卷，以便更好地管理它。
3.  选择要使用的容器映像，例如，我们使用最新的 Tensorflow GPU 映像，这些容器将受益于对完全分布式数据系统的本机访问。
4.  编写一个 YAML 文件来创建 Kubernetes 作业，我们要挂载所需的 Nvidia 库、Tensorflow 应用程序、持久和检查点的目标文件夹以及所使用的训练数据。在这里，我们可以轻松地创建一个挂载到分布式文件系统卷的持久卷，并授予多个 pods 对附加到该持久卷的持久卷声明的访问权限。
5.  检查持久化的结果，如果结果看起来令人满意，则进一步部署模型。

## 其他挑战

实时深度学习训练和推理的部分挑战在于数据的快速、可靠分发。随着广播技术的进步，我们将继续提高视频质量。这也推动了深度学习技术的发展。像压缩感知这样的技术有可能被用来减少流端的负载。深度学习模型可用于重建低维空间的特征，使压缩感知在实时视频应用中成为可能。

同样是分布式训练，与 Yarn 和 Mesos 相比，Kubernetes 更适合托管在线应用。

通过 Pixabay 的特征图像。

<svg xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 0 68 31" version="1.1"><title>Group</title> <desc>Created with Sketch.</desc></svg>