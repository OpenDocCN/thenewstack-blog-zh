# CUDA 12 利用了 Nvidia 更快的 GPU 架构

> 原文：<https://thenewstack.io/cuda-12-harnesses-a-nvidias-speedier-gpu-architecture/>

GPU 制造商 Nvidia 将很快发布下一个版本的 [CUDA 并行编程框架](https://developer.nvidia.com/cuda-zone)，版本 12，以配合其代号为 Hopper 的新 GPU 架构的发布。

“这是我们有史以来最大的一次发布，”英伟达 CUDA 架构师[斯黛芬·琼斯](https://www.linkedin.com/in/stephen-jones-profile/)在本月早些时候举行的英伟达 GPU 技术会议的分组会议上说。

CUDA 在 2007 年 6 月开始作为一种简单的编程语言，目标是图形，目前是 11.7 版本，有一个主要的更新，11.8 版本，在转移到 12 版本之前到期。

Jones 没有提供 CUDA 12 的确切发布日期，但过去的发布时间表表明版本 12 将在今年年底或明年年初可供下载。

Nvidia 通常会随着每个新的 GPU 架构发布新版本的 CUDA。这是两年来 CUDA 用户第一次经历重大版本变化。

GPU 最初在图形领域很受欢迎，但芯片的并行计算能力为 Nvidia 的硬件在非图形应用中的使用埋下了种子。如今，英伟达的 GPU 作为人工智能、模拟、图形和超级计算的加速器主导着市场。但是专有的 CUDA 并行编程模型只在 Nvidia 的 GPU 上运行得最好，这迫使客户购买该公司的硬件。

英伟达现在正试图通过销售在 CUDA 中开发的人工智能软件应用程序来推动软件业务的增长。该公司看到了软件领域 1 万亿美元的市场机会，基于 CUDA 的应用程序将进入自动驾驶汽车、机器人、医疗设备和其他人工智能系统。

一个典型的 CUDA 程序有一个 GPU 代码段和一个 CPU 代码段，GPU 代码段包括在图形核心上执行的代码，CPU 代码段设置包括内存分配和硬件管理在内的执行环境。CUDA 还有一个运行时系统，包括库和一个编译器，编译器将代码编译成可执行文件。

CUDA 二进制文件有 CPU 和 GPU 部分，以及一个单独的 PTX 汇编代码部分，它作为回溯到 2007 年第一版的所有 CUDA 版本的向后兼容层，在某种程度上也是向前兼容层。

## 升级挑战

但是 CUDA 12 应用会在 CUDA 11 上崩溃。从 CUDA 11 开始，Nvidia 包括了一个兼容层，因此 API 不会在内嵌版本中中断，例如，基于 CUDA 11.5 构建的应用程序将与 CUDA 11.1 一起工作。但是兼容层并不适用于全新的版本。

“比如说，你不能在安装了 11.2 版本的系统上运行 CUDA 12 应用程序，因为 API 信号可能会在一个主要版本中发生变化，”Jones 说，并补充道:“这意味着两件事。首先，你需要关心你的[系统]上运行的是 CUDA 的哪个主要版本，其次，一些 API 和数据结构会发生变化。”

CUDA 12 专门针对名为 Hopper 的新 GPU 架构进行了调整，该架构取代了 CUDA 11 支持的代号为 Ampere 的两年前的架构。基于 Hopper 的旗舰 GPU H100 的速度比上一代 Ampere 旗舰 GPU A100 快五倍。Hopper 的速度提升来自一系列新功能，如更强大的吞吐量和互连技术，更快的人工智能张量内核，以及矢量和浮点运算。

Hopper 拥有 132 个流多处理器、PCIe Gen5 支持、HBM3 内存、50MB 三级高速缓存和 900GB/s 带宽的新 NVLink 互连。

如果您想从 Hopper 中获得最佳性能，您只能从 CUDA 12 中获得。Nvidia 对其硬件和软件守口如瓶，如果你使用 Khronos 的 OpenCL，AMD 的 ROCm 和其他并行编程工具，你将无法利用 Hopper 的全部功能。

Hopper H100 GPU 专注于将数据保存在本地，并减少执行代码所需的时间。H100 中的 GPU 有 132 个流多处理器(SM)单元，而十年前开普勒只有 15 个。琼斯说，跨 SMs 扩展是 CUDA 12 的核心。

CUDA 编程模型的核心是要求用户将工作(如处理图像)分解成块，这些块在网格中一个挨着一个地组织起来。每个块在 GPU 上运行就像它是一个独立的程序，Hopper 可以一次运行几千个块。每个模块处理自己的问题，并被进一步分解成线程。

Nvidia 进一步打破了网格-块-线程的层次结构，推出了一个称为“线程块集群”的新层。“线程块集群”基本上打破了旧的结构，并在块级别上编织成互连的迷你网格，所有这些加起来就是更大的网格。由于其巨大的规模，“我们采用了由完全独立的工作块组成的网格构成的概念，”琼斯说。

SMs 被组织在线程块集群层次结构中，线程块集群以同步的方式同时交换数据。琼斯说，16 个块同时运行近 16，384 个线程，这是一个巨大的并发量，并补充说，集群中的每个块都可以读写集群中每个其他块的共享内存。

琼斯说:“我们所做的是将网格的本地化子集定位到一组本地化的执行资源，这为可编程性和性能提供了更多的机会。”

编程模型中的线程块集群功能具有新的语法，允许开发人员定义任务所需的启动大小和资源，而不是依赖 CPU 来正确完成任务。

Hopper 的另一个新特性是异步事务屏障，它减少了数据的来回传输，从而加快了代码的执行。异步事务屏障更像是一间卧室，等待线程在其中打盹，直到来自其他线程的数据到达以完成事务。这减少了移动数据所需的能源、工作量和带宽。

“你只需说‘数据到达时叫醒我’我可以让我的线程等待…期待来自许多不同地方的数据，只有当所有数据都到达时才醒来，”琼斯说。

在芯片中，工作通常被分解成线程，这些线程必须相互协调。对于普通的屏障，线程通常会跟踪数据来自哪里以及它与哪个源同步，但在 Hopper 中却不是这样，它只是一个单写操作。

“异步内存拷贝知道它携带了多少字节。屏障知道它期待有多少。当数据到达时，它就把自己算进去。这些是单面内存副本，它们的[通信]速度快 7 倍，因为它们只是单向的，不必来回移动，”琼斯说。

Hopper 还有一个新的处理单元，称为张量存储加速器，该公司将其归类为数据移动引擎。该引擎支持大型数据块在全局和共享内存层次结构之间的双向移动。TMA 还接管集群中线程块之间的异步内存复制。

“你呼叫[TMA],它就开始复制，这意味着硬件接管了计算地址和步幅、检查边界等所有类似工作。它可以剪切出一部分数据…并将其放入共享内存或以其他方式放回。你不必写一行代码，”琼斯说。

Hopper 为 Nvidia 称为“动态编程”的东西提供了新的 DPX 指令，通过递归解决重叠的子问题，人们可以有效地找到更大问题的解决方案。这可以使 CUDA 12 与涉及跟踪轨迹以优化或解决问题的计算的应用程序相关，如地图绘制或机器人路径跟踪。

“这非常类似于分而治之的方法……只不过重叠数据更难解决，”琼斯说。

Nvidia 还增强了动态并行的概念，允许 GPU 直接启动新的内核，而无需调用 CPU。“通过向动态并行编程模型添加一些特殊的机制，我们已经能够将启动性能提高三倍，”琼斯说。

Nvidia 的一位主持人没有澄清动态并行性是否会推进到 OpenMP 或 OpenACC 标准，他说“它是否会作为一种明确的语言功能进入标准取决于委员会。”

Nvidia 正在积极尝试将 CUDA 工具包中的一些功能作为标准 C++版本的一部分。CUDA 有自己的编译器 NVCC，它是为 GPU 设计的，运行时 API 有一个简单的类似 C++的接口。GPU 通常具有向量处理等计算元素，这些元素更适合人工智能等应用程序，运行时构建在驱动程序 API 之上。

<svg xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 0 68 31" version="1.1"><title>Group</title> <desc>Created with Sketch.</desc></svg>