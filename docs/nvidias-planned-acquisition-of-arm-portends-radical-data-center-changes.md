# 英伟达收购 Arm 的计划预示着数据中心的彻底变革

> 原文：<https://thenewstack.io/nvidias-planned-acquisition-of-arm-portends-radical-data-center-changes/>

尽管 400 亿美元的交易仍然面临监管机构的长期审查，随着 AMD 宣布计划收购 FPGA 制造商 Xilinx，Nvidia 的[提议收购](https://nvidianews.nvidia.com/news/nvidia-to-acquire-arm-for-40-billion-creating-worlds-premier-computing-company-for-the-age-of-ai)[的](https://www.arm.com/)的背后原因变得越来越清晰。

英伟达首席执行官[黄仁勋](https://www.linkedin.com/in/jenhsunhuang/)多次表示，英伟达不打算改变 Arm 的 IP 授权业务模式，也不打算用英伟达技术取代其 Mali GPU(Arm 授权厂商已经可以在他们构建的 SOC 中自由混合搭配不同的 GPU 和加速器)。从尽可能广泛的意义上来说，这是针对数据中心的，但也是通过 Arm 生态系统捕捉 Nvidia 可以为数据中心带来的所有价值。

Nvidia 不仅仅是一家在人工智能加速方面有所建树的 GPU 公司。去年，它收购了 Mellanox 用于网络硬件，Cumulus 用于网络虚拟化，SwiftStack 用于数据存储和管理(尤其是在云中)。收购 Arm 将增加 CPU，使其能够提供几乎全套的硬件和软件，但它也给 Nvidia 带来了一个庞大的合作伙伴生态系统和一个全新的商业模式。

这些收购不仅仅是英伟达可以提供自己的硬件集成；他们还可以使该公司成为数据中心硬件架构的一站式商店，以此与高通和英特尔竞争，这两家公司都采用平台方法。

黄在会议上告诉我们:“新的计算单元是数据中心，无论是在整个数据中心运行的云原生应用程序，还是有一天在芯片上实现整个数据中心的边缘计算。”。“我们想为人工智能时代建立一家计算公司。”

## **数据中心即堆栈**

正如黄所说，英伟达已经是一家“全栈公司”，但它不是垂直整合的。除了销售 GPU 和片上系统(SOC)，Nvidia 还设计了 DGX 服务器和 EGX edge 设备，您可以租赁、从云提供商那里获得服务或从戴尔等合作伙伴那里购买。它将向这些合作伙伴出售 GPU、主板或包括系统软件在内的一切。

今天，那些使用英特尔和 AMD 处理器；现在，Nvidia 将向产品线中添加 Arm 处理器，并提供创建数据中心系统和完整平台的专业知识，而不仅仅是组件。“它始于伟大的芯片，但堆栈要复杂得多，就像云计算平台不只是一台服务器，”黄说

根据黄的说法，Arm 生态系统的优势在于 SOC 是定制的，通常是特定于应用的，成千上万的客户生产了数十亿芯片，Arm 开发者可以解决这些问题，但 x86 生态系统的优势在于它是一个可配置的开放平台。黄说，数据中心和边缘计算环境不仅需要 x86 软件生态系统(越来越多地用于 Arm)，还需要平台的其余部分。

> Arm 能够提供的并行性和能效一直很有吸引力，但只是在最近几年，它才能够提供数据中心服务器所需的每线程性能。

“我们确切地知道如何处理平台的其余部分:我们带来了网络、存储、安全性、所有的 IO、所有必要的系统软件，用于你想要考虑的每一个操作系统版本，用于我们真正关心的应用程序，即加速计算和人工智能。”

Nvidia 希望提供尽可能多的数据中心和边缘平台。未来，英特尔和英伟达将在独立 GPU、数据中心 CPU、人工智能加速、从网卡到 SoC 级互连(以及物联网)的网络硬件以及软件开发 API(特别是人工智能和机器学习)方面展开竞争。这就只剩下存储和内存，黄确认这是英伟达不会涉足的领域。

“我们只会进入市场需要我们的市场，如果市场不需要我们，我们宁愿不做。我们只生产我们需要的东西，”他说。英伟达是一个计算平台，而不是一家计算设备公司，但它希望向制造存储服务器的原始设备制造商出售芯片。

Nvidia 收购 SwiftStack 的一个原因是其云连接器，该连接器旨在让云数据顺利通过机器学习和高性能计算(HPC)管道，而无需转移到全闪存存储进行缓存。这符合英伟达对大规模人工智能的愿景，而不会将他们拖入内存和存储的主要商品市场，也不会试图与英特尔在联合开发下一代持久内存解决方案方面的长期和重大投资竞争。

## **挽着云朵**

Arm 能够提供的并行性和能效一直很有吸引力，但只是在最近几年，它才能够提供数据中心服务器所需的每线程性能。Arm 的 Neoverse 平台(及其[项目 Cassini 标准化倡议](https://community.arm.com/developer/ip-products/processors/b/processors-ip-blog/posts/taming-of-the-edge))正在使该架构更有能力运行标准数据中心工作负载，如 Java、NGINX、MySQL、Redis 和 Kubernetes。

> “在 128 个内核的情况下，我们相信我们的 N1 CPU 将在插槽吞吐量和每线程性能方面超越市场上的任何产品。”——Chris Bergey，Arm。

迁移没有进行，因为它计划使用的主板提供商退出了市场，但 Cloudflare 准备迁移 Arm 服务器，因为它需要的所有软件都已重新编译以在 Arm 上运行，性价比将会有显著提高。

Arm 基础设施事业部总经理 [Chris Bergey](https://twitter.com/ctbergey) 告诉我们:“云提供商通常会受到配电限制，他们可以在每个机架上托管更多客户，从而为他们的业务带来更高的收入和更多的计算周期，并且客户可以获得更好的每核性能。Azure 已经使用 Arm 服务器处理一些内部工作负载，亚马逊网络服务提供 Arm 虚拟机，Ampere 已经计划在 2020 年底推出 128 核 Neoverse N1 处理器；“在 128 核的情况下，我们相信我们的 N1 CPU 将超越市场上的任何产品，无论是在插槽吞吐量上，还是在每线程性能上，”Bergey 说。

新的 Neoverse V1 平台针对 CPU 性能进行了优化，即使这意味着要为处理器使用更多的功率或空间。“我们正在增加更大的缓冲区、更大的缓存、窗口和队列；所有的微体系结构都允许单线程更快地执行。”它还将运行[可扩展向量扩展](https://community.arm.com/developer/tools-software/hpc/b/hpc-blog/posts/why-arm-s-sve-will-bring-vector-computing-from-hpc-to-the-edge-303246189)——首先在 Fugaku 使用的富士通 Arm 处理器中实现，目前是世界上最快的超级计算机。“从根本上说，对于 HPC 和机器学习工作负载，更宽的向量可以提供更高的应用性能，”Bergey 声称。

他将 2021 年推出的 Neoverse N2 称为云和边缘设备的“横向扩展性能级核心的更高性能选择”。“它们没有 V1 的每线程性能，但在恒定的 TDP[散热设计功率]下，将支持更多内核。如果您的应用程序对 CPU 和带宽要求很高，那么 V1 将为您提供最佳的线程性能。但是，如果您的应用更加横向扩展，需要更多内核，那么 N2 可能是更好的选择，因为您会发现更多实例，具有更高的内核数量。”

英特尔在数据中心市场的主导地位以及已经半途而废的 Arm 服务器主板供应商的数量意味着，即使有这些令人印象深刻的处理器，现成的 Arm 服务器可能也不是一个重要的机会。

半导体制造商 Marvell [在今年夏天宣布](https://blogs.marvell.com/2020/08/arm-processors-in-the-data-center/)将为其 96 核 ThunderX3 处理器(今年晚些时候发货)转向定制 Arm 服务器开发，特别是为超大规模云提供商。首席执行官[马特·墨菲](https://www.marvell.com/company/leadership/matt-murphy.html)在收益电话会议上对[说:“长期的机会是为他们的特定用例定制的 Arm 服务器处理器，而不是标准的现成产品。](https://www.fool.com/earnings/call-transcripts/2020/08/27/marvell-technology-group-mrvl-q2-2021-earnings-cal/)

虽然 Neoverse 平台将使供应商(可能包括 NVidia)更容易构建 Arm 服务器，而无需进行 Marvell 和富士通投资的那种处理器开发，但如果 Arm 服务器市场正在形成更多的定制集成，Nvidia 在这方面处于非常有利的位置。

## **艾的时代**

它还拥有日益重要的加速硬件；在硬件中运行算法比在软件中运行更有效。与英特尔和 AMD 相比，Arm 架构在抵御摩尔定律终结方面有更长的跑道(Arm 的弱内存模型更容易以更低的成本获得更多的并行性，从而提高可并行工作负载的性能)。但黄指出，同样的问题最终也会出现在他们身上。

“数据中心现在需要加速计算，这是一个必然的结论。”

尽管许多初创公司正在开发比使用 GPU 更有效的定制人工智能加速器(微软、谷歌和脸书都建立了自己的硬件来为自己的定制工作负载做这件事)，英特尔也在向 CPU 添加指令来运行人工智能任务和建立加速器，但 Nvidia GPUs 目前是事实上的数据中心 GPU 和人工智能硬件加速选项，用于从 VDI 到 Kubernetes 上的机器学习的一切。除了进行图形渲染的常用着色器核心之外，它们还包括“张量核心”(并且可以重新用于 CUDA 的并行计算)；张量核针对作为机器学习训练基础的矩阵运算进行了优化。

Arm 和 Nvidia 也在支持人工智能开发的软件方面做出了巨大努力；Nvidia 将 CUDA(及其特定领域的加速库)引入 Arm，大大扩展了它适用的工作负载。

但是，仅仅将 GPU 放入服务器机架并不能利用所有的集成选项。网络是其中的一部分；正如 Kubernetes 的联合创始人 Brendan Burns [最近向新堆栈指出的](https://thenewstack.io/microsoft-azure-brings-confidential-computing-to-kubernetes/), Azure 有足够的 InfiniBand 可用于互连绑定的 GPU，AKS 需要能够调度工作负载，以利用特定硬件上的速度。

微软今年内置的“人工智能超级计算机”Azure 使用了 Nvidia A100 张量核心 GPU——Azure 首席技术官马克·鲁斯诺维奇[在最近的 Ignite 大会上说](https://myignite.microsoft.com/sessions/40aca11c-8e28-4914-a6d8-b3a7efb4eee1)是“优化 DNN 的当前艺术状态——[与高带宽、低延迟 NVLink 和 NVSwitch 互联](https://www.nvidia.com/en-us/data-center/nvlink/)，并在 GPU 集群之间使用 InfiniBand，从一个集群中的八个 GPU 扩展到数千个 GPU，用于大规模训练。这是 OpenAI 运行其 1750 亿参数 GPT3 模型的基础设施。它是用 AMD Rome CPUs 构建的，但这是一款专为市场部门设计的新一代 Neoverse CPUs。

英特尔在数据中心的机器学习工作负载方面领先于 Arm，TIRIAS Research 的首席分析师 Kevin Krewell 告诉 New Stack。“英特尔在 CPU 中有一系列加速器和 DLBoost 指令。Arm 的加速器战略还在发展中。现在 Arm 与 Nvidia CUDA 生态系统的结合肯定会改变这一等式。这就是为什么这一组合可能成为英特尔(和 AMD)的强大竞争对手。”

[Mellanox 收购](https://nvidianews.nvidia.com/news/nvidia-completes-acquisition-of-mellanox-creating-major-force-driving-next-gen-data-centers)不仅给了 Nvidia InfiniBand 的专业知识(对集成高速存储也很有用)；它带来了基于 Arm 处理器的 SmartNIC 架构，Nvidia 将其称为一种新型处理器——数据处理单元(DPU)，用于移动数据。

SmartNIC 的理念是，对于某些工作负载，网卡可以卸载原本会降低 CPU 速度的工作，无论是从网络硬件转移到商用服务器的网络功能虚拟化，还是运行防火墙等服务器上的功能。AWS 在 Arm 芯片上构建了其 Nitro SmartNICs，但当网络开始消耗微软希望用于 Azure 中 IaaS 托管的 CPU 时，微软转向 FPGA 来提供没有 CPU 负载的智能网络，并且相同的 FPGA 基础设施现在支持从 Bing 索引到加密的工作负载，特别是 AI 加速。

很少有企业需要或有能力使用 FPGAs，虽然可编程智能网卡也有类似的优势，但 Mellanox 很难找到足够成熟的客户来利用存储服务器供应商和超大规模云之外的优势；这就是英特尔智能网卡可编程性较差的原因，它允许用户从图库中加载预写的加速。

> “我们和业内许多人都认为，今后，每台服务器无论执行何种工作负载，都需要内置其中一个数据处理单元。”——马努维尔达斯，Nvvidia

BlueField 2 具有 CPU 和 tensor 内核，用于将各种 IO、存储和安全功能从服务器 CPU 卸载到网卡，如存储 RMDA 处理、100GBps IPsec、实时流量检查和视频文件在线分析。

“我们将人工智能的力量带入了带宽和存储，”Nvidia 企业计算主管 Manuvir Das 告诉我们。“我们可以使用张量核心对网络上正在发生的事情进行智能分析，如入侵检测，在这种情况下，您需要做的是识别什么是正常行为，什么是异常行为，以便您可以主动检测和阻止异常行为。”

Das 指出，在网卡中进行安全保护可以提供更多的隔离(因为恶意软件可以在不影响 CPU 性能的情况下被分析和阻止)。“在现代数据中心中，安全性不仅要在外围实现，还要在服务器级别实现，这样每个应用程序都可以保护自己免受其他应用程序的攻击。这就是为什么我们和业内许多人都认为，今后，每台服务器无论其执行的工作负载如何，都将需要其中一台 DPU 设备。”

Das 告诉我们，Nvidia 与 VMware 达成协议，通过将功能从 ESXi 虚拟机管理程序转移到 DPU 来支持 vSphere 中的 BlueField-2 DPA(包括 Kubernetes ),这使得高级功能更易于使用。“客户将能够透明地从 DPU 中受益；他们甚至不用考虑，只需升级到最新版本的 vSphere 即可。”Nvidia 也正在与主流服务器原始设备制造商进行谈判，并提供一个软件框架 DOCA——片上数据中心基础设施架构——以及一个 SDK 和 API，用于与现有的加速网络和存储驱动程序(如 DPDK 和 PSDK)配合工作，以便软件供应商和开源项目可以建立 DPU 支持。

## **软化英伟达 IP**

Mellanox 一直在使用 Arm 芯片开发 BlueField DPUs，从未考虑过收购 Arm。Nvidia 已经拥有自己的 Arm 许可证，可以生产用于手机、平板电脑、汽车和任天堂 Switch 的 Tegra SoCs。“我们希望将 Nvidia 加速计算引入 Arm，这是世界上最受欢迎的 CPU，并为 Arm 生态系统提供加速，”黄说——但这为什么意味着收购 Arm？

他告诉我们，这是因为如果英伟达在不拥有 Arm 的情况下将其知识产权及其合作伙伴和开发者生态系统带入 Arm 市场，它将无法获得拥有许可和分销渠道的好处。

“所有成功的公司都有分销渠道，他们的客户网络是最有价值的部分之一。我可以授权 Arm 的 CPU 核心，但我不能授权分销渠道。他们的分销渠道，我用的词是生态系统，因为它是成千上万的硬件制造商，它是数百个系统制造商。是上百万的软件开发者。作为 CPU 授权厂商，我们并没有从中受益。我们希望将英伟达架构和英伟达加速人工智能纳入该渠道。这就是我支付 400 亿美元的原因；花了 30 年才建成。这不是我们不收购公司就能得到的东西。”

黄表示，当英伟达设计和 EGX 等参考系统时，他们会出售“少量”完整系统，但他们总是向供应商出售组件。正如黄所说，“我们创造系统，然后把它们分解成芯片”。现在，Nvidia 可以对自己的 IP 采用 Arm 的授权模式——拥有现成的受众——而不是只卖硬件(并把 CUDA 作为购买的理由)。

Krewell 警告说，说起来容易做起来难。“英伟达如何交付其知识产权(以及收取多少费用)将是一个有趣的挑战。Jensen 认为 Nvidia 也是一家知识产权公司，但是以更加强硬的形式提供其知识产权。真正的挑战是 Nvidia 将如何自由地向整个 Arm 生态系统开放其 IP——包括潜在的竞争对手。英伟达将需要赢得 Arm 生态系统的信任。”

但他指出，英伟达确实有吸引开发者的经验。“集成故事中最重要的部分将是软件栈。英伟达在这里有一个伟大的故事。”

黄还认为，Arm 需要英伟达的能力来转向服务器。他将 Arm 和 Nvidia 可以提供的堆栈与亚马逊给云计算带来的创新进行了比较。“AWS 是当今世界上最有价值的计算平台公司之一，他们创新了云计算，当你深入了解 AWS 时，你就会知道里面是什么——一堆服务器。云计算涉及到服务器，但服务器不是云计算，它包括更多。软件栈非常新颖。它的管理方式非常新颖。云计算不只是数据中心里的一堆服务器，否则，一大堆服务器公司都会是云计算公司，但它们不是。”

## **堆叠未来**

服务器(包括云计算)的未来越来越异构，混合了内核和加速器——不仅仅是在服务器内部，而是在处理器级别使用开放式互连封装在一起。Arm 一直致力于芯片级接口，包括内核间通信的 CCIX 协议；这是从多插槽计算转向将多种技术打包在一起的小芯片架构(英特尔自 2018 年以来一直在投资这种架构，针对 CPU 和 FPGAs)。

“我们看到[小芯片]之后是紧密耦合的异构计算，”Bergey 说。“随着摩尔定律扩展的放缓，人们对 ARM CPU 复合体与各种加速器和内存的芯片间耦合产生了兴趣。”英伟达的知识产权在那里会非常有用。

Arm 首席执行官[西蒙·塞加斯](https://www.linkedin.com/in/simon-segars-5562a02/%5D)在本月早些时候的 [Arm 发展峰会](https://devsummit.arm.com/)上提到了这一点的重要性。“将采用完全不同的工艺制造的不同芯片放在一起，放在真正复杂的封装中，这很重要。能够将芯片堆叠在一起，实现真正的 3D。我认为这些创新将会一代又一代地持续提高性能。”

Bergey 补充说，Arm 还增加了对 CXL 的支持，支持需要缓存一致性互连的内存池和扩展。“这可能涉及在一组连接的节点之间共享一个大型内存池，也可能意味着只需将大量新兴内存连接到单个节点。事实证明，CSL 是连接加速器的首选方式，主机中的加速器可以一致地访问彼此的内存。这里最明显的用例是最大似然训练和推理，但我们预计在它上市时会出现新的用例。”

Krewell 说，这是 Nvidia 不具备的专业知识。“我们还没有看到英伟达拥抱小芯片。该公司倾向于押注于其制造大型芯片的能力。随着摩尔定律放缓，性能要求仍需提高，这种情况将会改变。CCIX 和 CXL 将在 2021 年变得重要，以支持 CPU 和加速器之间更智能的数据移动/共享。”

但也有一些新兴趋势是英伟达的收购还没有准备好的。

超大规模的云容易出现碎片化的问题；在客户之间共享固定资源意味着分割硬件的方式会留下孤立的未使用资源。为了避免这种情况，像 Azure 这样的超大规模公司正在研究如何在数据中心内部分解硬件；对主板固件和外围设备等的单一安全信任根，计算存储，如将 SSD 中的存储与控制器分离，以添加压缩的在线加速，或通过在光学互连上汇集和组合分散的 GPU 和 FPGA 来扩展 GPU 集群的松散耦合架构。

在今年的 OCP 峰会上，微软杰出的工程师 Kushagra Vaid 建议分解是保持 T2 摩尔定律的方法。“虽然许多人认为我们正在达到摩尔定律的极限，但我们相信摩尔定律可以应用于每两年将整个数据中心园区的成本减半，而不仅仅是芯片。这意味着网络、硬件和数据中心将作为一个系统进行整体优化，以实现这一目标。”

分解将在数据中心内推动如此多的流量，以至于可能需要转移到“共同封装”硅和光学网络(而不是当前的插件光学模块)，这可能需要硅光子学，以降低电力和冷却需求以及延迟。

微软和脸书正在合作设计[共同封装光学器件](http://www.copackagedoptics.com)，思科在 2018 年收购了硅光子公司 Luxtera，以帮助其开发使用“共同封装”光学器件的下一代 ASICs，英特尔和 Xilinx 都在研究利用 FPGAs 实现快速互连的封装光学器件。英特尔已经发运了 300 万个硅光子收发器，并在 Tofino 2 可编程片上以太网交换机中使用硅光子。去年，它收购了 Barefoot Networks，以获得其构建这些网络的专业知识，并且它已经构建了可能具有硅光子端口的 SmartNICs。

Mellanox 一直在研究硅光子学，但在 2018 年停止了这项开发，因此 Nvidia 可能需要重新启动这项工作，或者进行进一步的收购，以便在这里直接竞争。

但是，看起来交付数据中心的未来将越来越需要大量的技术组合。

AMD 现在宣布，它正在就收购 Xilinx 进行深入谈判，Xilinx 的 FPGAs 用于智能网卡、计算存储和人工智能推理加速器(有时使用 Arm 内核)。Xilinx 首席财务官 Brice Hill 最近预测，数据中心将是该公司增长最快的部门(并指出 Xilinx 需要更多与超大规模服务器合作的经验才能取得成功，AMD 已经拥有这些经验)。

同样，这一收购将使 AMD 更容易为 CPU 和加速器创建使用高速缓存一致性互连的异构计算包。AMD 也在软件方面进行投资，从其开源 ROCm(大致相当于英特尔的 oneAPI 编程模型)到与 CUDA-竞争对手 OpenCL 合作的新工具。

假设英特尔这次可以提供独立的 GPU(过去它没有这样做)，它将能够提供一个全栈软件和硬件平台，从 CPU 到 GPU 到网络硬件到加速到 oneAPI，它相信客户想要的。这是 Nvidia 想要竞争的水平，购买 Arm 是一种从平台方法中获得最大价值的方式。

英伟达将提前获得 Arm 的设计，提高许可费用将是诱人的，但为了保持 Arm 的行业价值，其知识产权将需要保持可负担和中立。问题是，它能否成功整合 Arm，在此基础上进行构建，改变自己的许可模式，并在不破坏 Arm 中立性的情况下创建全栈解决方案——因为基于同一知识产权的多个供应商是 Arm 生态系统中如此多创新的驱动因素。

<svg xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 0 68 31" version="1.1"><title>Group</title> <desc>Created with Sketch.</desc></svg>