# 来自首席技术官的 6 个可怕的停机故事

> 原文：<https://thenewstack.io/6-scary-outage-stories-from-ctos/>

[](https://www.linkedin.com/in/adamlagreca/)

 [亚当·拉格雷卡

亚当·拉格雷卡是 10KMedia 的创始人——一家针对 B2B DevOps 的精品公关机构。此前，他是 DigitalOcean、Datadog 和 Gremlin 的通信总监。](https://www.linkedin.com/in/adamlagreca/) [](https://www.linkedin.com/in/adamlagreca/)

闹钟响的时候，你睡得正香。已经凌晨 3 点了。你擦擦眼睛，看看手机。你知道事情不对劲。非常不对。

网站瘫痪了。您的应用程序已损坏。房间里唯一的光线来自你的电脑显示器。系统中的小鬼可能藏在任何地方，找到它是你的团队的工作。

尽快修好坏掉的东西。

作为一个为各种 DevOps 创业公司管理公共关系的人，我一次又一次地看到了这个故事。一次大停电的声誉成本足以让最有经验的工程师感到恐惧！

但事实是，每个公司都有系统故障。我们离让在线系统看起来更像公用事业还有一段距离，在那里你按下开关，它就工作了。因此，分享故事和让失败正常化(例如透明和无可指责的事后分析)是这个行业的积极趋势；这让每个人都不那么害怕和孤独。

我不会引用停机成本的一般数字。对于亚马逊来说，可能是每小时数百万；对你的公司来说，如果迅速处理，它可能仅限于令人沮丧的客户体验。但最终，这种情况会让企业损失金钱、损害声誉、耗尽工程资源并激发竞争兴趣。

因此，本着万圣节的精神，更重要的是本着分享经验以更好地防止它们在未来发生的精神，让我们来看看六个可怕的停机故事，这些故事是由 CTO 们自己讲述的。

## 慈善专业，蜂巢 CTO

![](img/f8f202ba934d42df238518fed94b3fa7.png)

慈善专业

“推送通知停机了！”

“不，他们不是。”

“不，真的，人们在抱怨——压力下降了。”

“推不可能下来。我们的推送在排队，我在接收推送。”

“已经过了五天了，推还是下来了。人们正在归档各种任务。”

…所以我不情愿地开始四处打探。我们所有的推送指标看起来都相对正常，我发送的每个测试推送都被及时交付。然而，支持团队是对的——整整五天以来，人们一直在抱怨推不成功。到底会是什么呢？

这些是 Android 推送通知，Android 设备需要保持一个对服务器开放的套接字来订阅推送通知。我们有数千万的 Android 设备，所以我们在一个自动缩放组中运行推送通知服务。为了平衡组内的连接负载，我们使用了循环 DNS，为了增加容量，我们只需增加 ASG[自动扩展组]的大小。最终，我们发现抱怨是在我们最后一次增加 ASG 的尺寸时开始的，所以这是一个很好的线索。另一个线索是，所有抱怨的人似乎都来自东欧。我们要求他们中的一些人运行详细的跟踪，这时我们得知 DNS 记录被返回为…丢失？

结果是，当我们增加 ASG 的大小时，循环 DNS 记录超过了 UDP 数据包的大小。通常这没什么大不了的；该协议说，在这种情况下，它应该回退到使用 TCP。对几乎所有人来说，的确如此。除了在罗马尼亚的一个主要路由器后面的用户。我们将该记录的 DNS 从 route53 委托给一个小型本地 python DNS 服务器，让我们随机返回四个 Android 推送通知服务器的子集，一切又恢复正常。💀

## Gremlin 的首席技术官 Matthew Fornaciari

![](img/fa1d29d6a14c6ae0f1c4ea539d8ce4c0.png)

马特·福尼萨里

停电发生在一个星期五的下午，就在我们准备去万圣节快乐时光的时候。页面显示我们只提供 500，这对客户来说是非常糟糕的体验。经过一番挖掘，我们意识到我们的主机已经填满了它们的磁盘，我们开始失败，因为我们不能写日志(也很可怕，因为我们是盲目飞行)。

我们最终刷新了主机，实现了日志轮换以防止这种情况在未来发生，并创建了一个警报来警告我们是否再次接近。但我们做的最有趣的事情是让我们的一名工程师为我们的平台编写了一个新的小精灵:磁盘小精灵，以确保我们可以主动进行修复，以确保我们再也不会以这种方式失败。然后我们自动化了那个测试，那个测试直到今天还在我们的生产环境中随机运行。😱

## Rookout 首席技术官 Liran Haimovitch

![](img/300587072468306d1bc1a532275f7ff5.png)

利兰·海莫维奇

还记得那个关于服务器每天在同一特定时间停机的都市传说吗？经过数周的调查，有人查看了监控录像…发现女佣正在断开服务器连接真空吸尘器！嗯，我们都知道壁橱里的小精灵并不总是像我们最初想象的那样可怕或神秘:)

最近，我们经历了类似的事情。

每周有几次，我们看到后端的延迟指标飙升。每次我们调查它的时候，我们都注意到其中一个表被锁定，并且所有的查询都超时。我们想知道:我们的一个客户是否在不停地重新部署他们的应用程序？主要问题是一个复杂的查询，它获取所有客户服务器的信息列表，因此他们可以选择他们想要调试的服务器。我们开始优化该查询，并看到了巨大的改进，但那些延迟峰值仍在发生。

几周前，在参加每周一次的“客户成功简报”时，延迟峰值再次出现，这让我大吃一惊。我注意到一个我们很少使用的查询，来自我们应用程序的后台，它真的很慢，因为我们从来没有优先修复它(它很少被使用)。显然，我们的客户成功经理一直在为会议收集数据，每次查询返回的速度不够快，他就不停地点击刷新并重试。这个很少使用的查询锁定了我们的数据库，并挑战我们的客户成功经理的理智！回顾数据，我们确认所有延迟峰值都与客户成功简报保持一致。最终，在优化该查询大约 20 分钟后，一切恢复正常。🎃

## Lightstep 的首席技术官丹尼尔·斯汤普·斯汤普霍

![](img/92779d5ad4ee3676f0cde8c7f3095b63.png)

丹尼尔“勺子”斯普豪

这是旧金山晴朗的一天。我当时在一家小型互联网公司工作，突然我们的应用程序停止为我加载。不只是一个视图，而是整个应用程序。硬装弹，但运气不好。我环顾四周，队友们也很迷茫；这个应用程序对他们也不起作用。我们的用户没有抱怨(还没有？)但我们还是开始挖了。那天还没有进行任何部署，基础设施也没有改变；然而，在不同的操作系统类型和浏览器中，这个问题总是被打破。有什么可以改变的？

我们在一个关键的(但无聊且永远不会改变的)API 调用中发现了一些错误，没有这些错误，应用程序将无法加载。但是为什么错误只发生在在公司工作的人身上呢？为什么是现在？结果是，对于内部用户，API 返回了一些额外的数据……这些额外的数据在过去几周内一直在缓慢增长，直到那天下午最终超过了请求的最大有效负载大小。👻

## LogDNA 首席技术官刘辉

![](img/a049ec0eb8bab548f3572ff04cfb96cc.png)

我们所依赖的 AddTrust 根证书颁发机构(CA)大约在太平洋时间 2020 年 5 月 30 日星期六早上 4 点到期。

当时，作为我们迁移到 Kubernetes 的一部分，我们正在将我们的一些基础设施转移到一个非营利性的认证机构 Let's Encrypt。传统系统日志客户端需要 AddTrust/UserTrust/Comodo。除了为一家主要的云合作伙伴运行多个全球环境之外，我们还运行自己的 SaaS 环境。在我们的 SaaS 环境中，到处都使用单个证书链，包括我们的摄取端点、Syslog 端点和 web 应用程序。我们以为我们已经为根证书的到期做好了准备…但我们没有。

证书链快速入门:所有基于证书的安全性都依赖于信任链。浏览器和操作系统附带了这些根证书的信任存储。

LogDNA 链:AddTrust 根 CA(已于 5 月 30 日过期)-> user trust CA--> Sectigo--> *。[logdna.com](http://logdna.com/)

现代浏览器允许:UserTrust CA -> Sectigo -> *。【logdna.com 号

UserTrust CA 本身也是许多浏览器的根信任存储的一部分，因此即使 AddTrust 过期，它也会被忽略，因为指向 UserTrust CA 的链仍然有效。

至少我们是这么认为的。

原来，旧的遗留系统将只能看到 LogDNA 链，如果四个证书中的任何一个过期，它将被视为无效链。他们也不承认 UserTrust 是可信的根证书。

我们收到的所有支持票都提到我们的 v1 代理不再向我们的摄取端点发送日志，但是我们的 v2 代理和其他基于 REST API 的客户端的现代实现都工作正常。

我们错误地开始更新我们的 v1 代理。具有讽刺意味的是，由于同样的 AddTrust 根 CA 过期，我们的 CI/CD 提供者也有自己的中断，这使我们部署该代理变得更加复杂。当我们意识到问题出在实际的证书链上，以及旧的遗留系统如何处理该证书链时，我们通过切换到一个基于 Let's Encrypt 的新证书链来快速纠正它。🧟

## Transposit 首席技术官 Tina Huang

![](img/7f871a5ec5f53fbea53b0122d4dad7ae.png)

黄婷婷

全面的站点中断是可怕的——但它们不会像随机的、不可预测的故障那样让你起鸡皮疙瘩。我当时在做 Twitter 的移动网络版，我们收到一些请求，对于一些随机的不幸的露营者来说，每当他们访问该网站时，都会导致一个可怕的错误页面。对其他人来说，天空是蓝色的，鸟儿在啁啾。但时不时会有人被撞。而且，一旦他们被击中，他们就陷入了绝望的深渊，无法阅读手机上的任何推文。

慢慢地，随着这些受损账户的数量增加，500 开始攀升至临界水平。我们可以看到我们使用的新库无法解析带有特定字符的会话 cookies。所以每次你重新登录时，你都在赌被这个讨厌的虫子咬了一口，如果没有在手机上重置 cookies 的神奇力量，你是无法治愈的。最终，我们修复了图书馆中的错误，每个人都能够回去阅读他们的推文…正如我们所知，这本身就是一件非常可怕的事情！🕸️

<svg xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 0 68 31" version="1.1"><title>Group</title> <desc>Created with Sketch.</desc></svg>