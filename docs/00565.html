<html>
<head>
<title>Google DeepMind Psychlab Assesses AI with Cognitive Psychology</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">谷歌DeepMind Psychlab用认知心理学评估AI</h1>
<blockquote>原文：<a href="https://thenewstack.io/google-deepmind-psychlab-assesses-ai-with-cognitive-psychology/#0001-01-01">https://thenewstack.io/google-deepmind-psychlab-assesses-ai-with-cognitive-psychology/#0001-01-01</a></blockquote><div><div id="tns-post-body-content">


<p class="translated">近年来对人工智能的研究一直专注于开发普遍智能的人工智能，这意味着人工智能不是专门掌握一项特定任务——例如玩一种游戏——而是可以学习和获得各种技能，就像人类一样。</p>
<p class="translated">但是，即使是最简单的任务也会涉及许多认知功能。因此，即使人工智能研究开始从人类大脑如何工作中获取更多线索，以开发新型算法和架构，但当人工智能代理成功完成任务时，仍然不总是完全清楚使用了哪些人工认知技能。</p>
<p class="translated">为了帮助更好地识别这些认知组件是如何发挥作用的，谷歌的人工智能研究实验室<a href="https://deepmind.com/" target="_blank" class="ext-link" rel="external "> DeepMind </a>最近发布了一个开源工具包，允许开发人员在受控环境中研究人工智能行为，类似于认知心理学家可能使用为研究人类行为过程(如注意力、感知、记忆、思维、创造力和解决问题)而设计的测试。</p>
<p class="translated">根据<a href="https://deepmind.com/blog/open-sourcing-psychlab/" target="_blank" class="ext-link" rel="external ">网站上的帖子</a>，DeepMind的<a href="https://github.com/deepmind/lab/tree/master/game_scripts/levels/contributed/psychlab" target="_blank" class="ext-link" rel="external "> Psychlab </a>平台建立在<a href="https://deepmind.com/blog/open-sourcing-deepmind-lab/" target="_blank" class="ext-link" rel="external "> DeepMind Lab </a>之上，这是一个可定制的第一人称模拟3D环境，用于在各种任务中训练和测试自主AI代理。</p>
<p class="translated">就像人类心理学实验在临床环境中的组织方式一样，Psychlab建立了一个等效的框架，在DeepMind实验室的虚拟环境中，测试人工智能代理和人类受试者的认知能力。</p>
<p class="translated">“这通常包括参与者坐在电脑显示器前，用鼠标对屏幕上的任务做出反应，”DeepMind研究员乔尔·雷博解释道。“同样，我们的环境允许虚拟主体在虚拟计算机显示器上执行任务，利用其凝视的方向做出反应。这使得人类和人工智能都可以进行相同的测试，从而最大限度地减少实验差异。它也更容易与认知心理学中的现有文献联系起来，并从中汲取真知灼见。”</p>
<p class="translated">Psychlab提供的一些“经典实验任务”包括:视觉搜索(测试在一系列项目中搜索目标的能力)；连续识别(测试记忆中不断增长的项目清单)；任意视觉运动映射(测试刺激-反应配对的回忆)；变化检测(测试检测延迟后重新出现的对象数组中的变化的能力)；视敏度和对比敏感度(测试识别小的和低对比度刺激的能力)；玻璃图案检测(测试整体形状感知)；随机点运动辨别(测试感知连贯运动的能力)和多目标跟踪(测试随时间跟踪移动目标的能力)。</p>
<p class="translated"><iframe loading="lazy" title="Psychlab 'visual search' task in DeepMind Lab" src="https://www.youtube.com/embed/54AS3a6niPo?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="">视频</iframe></p>
<p class="translated">转移这些指标有一些很大的好处。“Psychlab使分析实验数据的方法成为可能，这些实验数据在心理学中很常见，但在人工智能研究中相对未知，”论文作者写道。“例如，我们描述了可以直接与人类相比的人工制剂的心理测量功能、检测阈值和反应时间的测量方法。”</p>
<p class="translated">此外，人类测试对象在虚拟DeepMind实验室测试环境中获得的结果与现实世界中的测试结果相同。例如，在视觉搜索测试中，通过让参与者从许多不同的物体中找出一个特定的物体来测量选择性注意力，该团队发现，如果只有一个因素存在差异，人类能够在真实和虚拟环境中相对相同的时间内完成任务——与其他人相比，搜索一个不同颜色的条形或一个方向不同的条形。然而，当存在不止一个差异因素时，人类的反应时间会略有增加——例如在一组包括不同颜色<em>和</em>形状的条形中寻找一个粉色条形。相比之下，实验中的人工智能代理在相同的时间内完成了各种视觉搜索任务，而不管这些对象之间有多少不同。</p>
<div id="attachment_4491295" class="wp-caption aligncenter"><img aria-describedby="caption-attachment-4491295" decoding="async" loading="lazy" class="wp-image-4491295 size-full" src="../Images/720e96a65d03b051764c7458d73a56ed.png" alt="" data-original-src="https://storage.googleapis.com/cdn.thenewstack.io/media/2018/04/4061d644-deepmind-psychlab-1.png"/><p id="caption-attachment-4491295" class="wp-caption-text translated">Psychlab中视觉搜索任务中人类和人工智能反应时间的差异。</p></div>
<p class="translated">根据该团队的说法，这些发现表明，人工智能代理的某些认知功能与人类的工作方式不同，毫无疑问，这将有助于了解人工智能在未来是如何设计的。随着人工智能研究越来越多地从其他学科如<a href="https://thenewstack.io/stronger-artificial-intelligence-needs-neuroscience-inspiration/" target="_blank" class="local-link">神经科学</a>中汲取灵感，这样的发展是朝着创造人工智能迈出的一步，人工智能不仅像人类一样学习，而且可能像人类一样思考和行为。</p>
<p class="translated">其他人可以建立他们自己的认知任务，让他们的人工代理来执行。DeepMind的开源、“灵活易学”的Psychlab can可以在<a href="https://github.com/deepmind/lab/tree/master/game_scripts/levels/contributed/psychlab" target="_blank" class="ext-link" rel="external "> Github </a>上找到，此外还有他们的研究论文<a href="https://arxiv.org/pdf/1801.08116.pdf" target="_blank" class="ext-link" rel="external "> here </a>。</p>
<p class="attribution translated">图片:DeepMind。</p>


<div class="tns-logo-slug">
<svg xmlns:xlink="http://www.w3.org/1999/xlink" viewbox="0 0 68 31" version="1.1">
<title>Group</title>
<desc>Created with Sketch.</desc>
<g id="Page-1" stroke="none" stroke-width="1" fill="none" fill-rule="evenodd">
<g id="Group">
<path d="M24.002,29.619 L29.77,29.619 L29.77,15.808 C29.77,15.038 29.622,11.265 29.59,10.414 L29.77,10.414 C31.424,14.019 31.473,14.147 32.168,15.322 L39.65,29.618 L44.845,29.618 L44.845,0 L39.075,0 L39.075,11.064 C39.075,12.197 39.075,12.44 39.182,14.472 L39.325,17.468 L39.151,17.468 C39.034,17.267 38.596,16.173 38.467,15.929 C38.164,15.323 37.725,14.512 37.373,13.905 L30.031,0 L24,0 L24,29.619 L24.002,29.619 Z" id="Path-Copy" fill="#FF3287"/>
<path d="M56.948,0 C50.745,0 47.606,3.43 47.606,8.296 C47.606,14.114 51.036,15.404 55.518,17.132 C60.438,18.853 61.782,19.332 61.782,21.539 C61.782,24.225 58.969,24.867 57.401,24.867 C54.579,24.867 52.493,23.342 51.536,20.858 L47,24.185 C49.43,28.937 52.145,30.185 57.713,30.185 C59.364,30.185 62.059,29.74 63.727,28.694 C67.779,26.156 67.779,22.22 67.779,20.898 C67.779,18.129 66.531,16.207 66.178,15.726 C65.049,14.121 63.032,12.918 61.25,12.278 L57.084,10.914 C55.073,10.267 52.928,10.105 52.928,8.019 C52.928,7.707 53.008,5.528 56.288,5.319 L61.465,5.319 L61.465,0 C61.465,0 57.342,0 56.948,0 Z" id="Path-Copy-2" fill="#00AFF4"/>
<polygon id="Path" fill="#00AFF4" points="5.32907052e-15 1.77635684e-15 5.32907052e-15 5.319 7.572 5.319 7.572 29.564 14.132 29.564 14.132 5.319 21.544 5.319 21.544 1.77635684e-15"/>
</g>
</g>
</svg> </div>
</div>
</div>    
</body>
</html>