# 现成的黑客:机器视觉的三种方法

> 原文：<https://thenewstack.io/off-shelf-hacker-three-approaches-machine-vision/>

我最新的项目，机器人头骨，越来越复杂了。目前 JeVois 智能视觉传感器中有一个四核处理器，Raspberry Pi 中有一个四核芯片，Arduino 中有一个微控制器。我们可能会至少再添加一个 ESP8266。

我开发这个项目的主要原因之一是探索物理计算思想的试验台。能够用一个独立的设备来演示概念是很有意义的，使用树莓派作为中央“大脑”非常有用。只需连接 HDMI 显示器或投影仪，插入无线键盘/鼠标垫，我们就可以开始了。除了“展示”各种物理计算概念和子系统如何工作之外，如果需要，我还可以使用 LibreOffice 从头骨开始放幻灯片。

将 Raspberry Pi 集成到 skull 中还可以让我运行 [guvcview](http://guvcview.sourceforge.net/) ，它成为 JeVois 传感器的图形用户界面。启动 guvcview，选择一个分辨率，你可以立即看到 JeVois 传感器正在识别什么。每个分辨率都与某个机器视觉模型相关。例如，1280×480 分辨率对应于使用 [YOLO](https://pjreddie.com/darknet/yolo/) 深度神经网络对象检测算法的两个窗口(原始与识别)渲染。目前有相当多的[用户演示](http://jevois.org/doc/UserDemos.html)可用。

视觉模型是 JeVois 传感器与上一代技术(如 [Pixy](http://charmedlabs.com/default/pixy-cmucam5/) 相机)的区别。在充足的光线下，小精灵能够识别彩色斑点。虽然比它的时代超前了好几光年，但它很繁琐，也不像我希望的那样可靠。JeVois 也可以很容易地辨别彩色斑点，这只是它的许多功能之一。说 JeVois 塞满了软件是一种保守的说法。Linux 和 vision 引擎在 micro-SD 卡上占据了 7.3GB 的空间。

因此，Pi、视觉传感器和 Arduino 一起构成了一个极其强大和灵活的包。点击阅读计算机视觉[中关于过去一年的更多内容。](http://www.themtank.org/a-year-in-computer-vision)

矛盾的是，我想做的就是当我在舞台上来回走动时让头骨跟踪我。多复杂啊，对吧？

神奇的事情发生在机器视觉模型中。

## 魔法模型

有检测道路上的线、一对骰子上的点、识别物体和其他事物的模型。我认为适用于机器人头骨的三个视觉模型包括颜色识别、物体检测和显著性。

通过插入 JeVois 传感器，然后在您的 Pi 或外部 Linux 笔记本上启动 guvcview 程序，可以探索不同的模型。然后，从下拉菜单中选择与您想要运行的模型相对应的分辨率。将弹出一个窗口，显示您的视频馈送和来自视觉传感器的增强信息，以彩色框、圆圈和文本标签的形式显示。识别数据也通过一个单独的串行端口流向 Arduino，同时启动伺服系统。

## 颜色识别

这个模型模仿了旧的 Pixy 设备和键，分辨率为 320×254。该模型寻找特定饱和度、色调和颜色像素范围的值，然后找到对象的轮廓。然后，它通过串行端口发送对象中心信息。您可以用 Arduino 拾取它来移动伺服系统，或者将其发送到 Raspberry Pi 进行进一步的处理和分析。

小精灵当然可以完成这项任务，你实际上可以用板上的一个按钮来训练它。JeVois 稍微复杂一点，因为您使用外部应用程序来隔离所需的颜色范围，然后将这些参数输入到传感器上的文件中。

我已经尝试在 JeVois 上识别颜色，它大致和 Pixy 一样好。我应该指出的是，精灵可以以每秒 50 帧的速度识别物体，而 JeVois 以每秒 82 帧的速度嗡嗡作响。灵敏度似乎差不多，分辨率更好，两者都依赖于环境照明条件。我希望在选择在舞台上跟踪我的最终模型时，彩色斑点识别将是我的备用选择。

## 使用神经网络的物体识别

当你切换到 1240×480 分辨率时， [YOLO 神经网络开始工作](http://machinethink.net/blog/object-detection-with-yolo/)。YOLO 是首字母缩略词，代表“你只看一次”JeVois 传感器中的版本可以检测大约 1000 个物体，包括自行车、汽车、人、电视显示器、瓶子等。把各种各样的物体放在传感器前面，看看结果，这很有趣。

有时它认为我们的狗，亮片，是一只玩具狮子狗。其他时候，头骨正确地识别出她是马耳他人。

使用这种模型对人、狗、桌子或椅子的正常检测时间约为 2400 毫秒或 2.4 秒。对于一个大约 1 英寸立方、价格约为 50 美元的设备来说，虽然速度不快，但实际上相当不错。

物体识别可能会工作得很好，因为该模型似乎在挑选人方面没有任何问题。我将是舞台上唯一的一个人，尽管我还不确定头骨是否会注视它所识别的其他物体，比如桌子或椅子。测试总是现成黑客开发的一部分。

## 显著

对应于 640×300 分辨率的最后一个模型是显著性模型。显著性被描述为图像中最引人注目的特征。想象一个婴儿。他们自然地跟踪运动、明亮的物体和引起他们注意的事物。

我发现了一篇关于显著性的深度论文，读者可能会感兴趣。请注意，这种事情很快就会变得复杂。现在，显著性模型似乎是我的“舞台上的 Torq 博士”跟踪任务的最佳选择。我将是唯一一个在房间前面移动的东西，所以头骨不应该对跟踪什么感到困惑。

当然，传感器总有可能会在我的幻灯片或其他引人注目的物体上看到亮点，并停止观察我所做的事情。简单的解决方法:不要做任何幻灯片。

随着我对模型有了更多的经验，调整设置和环境因素，最终应该会提供可靠的跟踪。

## 包裹

将多种计算资源与尖端的机器视觉模型结合起来，有望使我跟踪一个人的看似琐碎的工作成为现实。这只是开始。我认为计算子系统的组合互相交谈，以及先进的，也许是人工智能装备的软件是下一个大浪潮。我们已经不仅仅是让 LED 闪烁了。

想想看，我们可以做所有这些很酷的事情，现在就用现成的黑客思维。

科技世界正变得越来越好。

<svg xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 0 68 31" version="1.1"><title>Group</title> <desc>Created with Sketch.</desc></svg>