# 透明人工智能:可解释和可训练的人工智能

> 原文：<https://thenewstack.io/transparent-ai-explainable-and-trainable-artificial-intelligence/>

[](https://www.moogsoft.com/)

 [亚当·弗兰克

亚当·弗兰克是一位产品和技术领导者，拥有超过 15 年的 AI 和 IT 开发和运营经验。他创造 AIOps 解决方案的想象力和热情正在帮助世界各地的 DevOps 和 SREs。作为 Moogsoft 的产品管理和 UX 设计副总裁，他专注于提供产品和战略，帮助企业实现数字化转型，进行组织变革，并获得持续的服务保证。](https://www.moogsoft.com/) [](https://www.moogsoft.com/)

随着人工智能(AI)承担越来越复杂的决策，其背后的人类正在失去对其如何得出结论的了解。许多算法不再能够被检查以理解决策路径，知道为什么 AI 会得出特定的答案。当信任非常重要时，比如当人工智能产生技术诊断时，人工智能决策背后的简单原理可以帮助用户更快地解决问题，在问题影响业务之前解决问题，并从他们的系统中获得更多价值。

为了建立对人工智能的信任，并简化人类与它的交互方式，团队应该投资于增加人工智能操作的透明度。这从开发可解释和可训练的人工智能开始。当你与供应商交谈时，请注意:有些人会试图用人工智能、机器学习或持续学习等正则表达式来冒充标签。这些只是规则，在当今的 IT 环境中，规则不会带你走多远。

## 可解释和可训练的人工智能提高了决策可见性

当系统更简单时，人工智能系统的决策引起的关注更少。语义推理等更直接的功能或决策树等内在可解释的功能允许人类跟踪 AI 做了什么，并清楚地遵循其逻辑。但是，随着人工智能用例以及所需数据量的增长，人工智能变得更加复杂，这使得人类需要理解所做的决策。复杂性增加了解释的难度，缺乏解释会滋生不信任。

这种不信任导致了最近的一项推动，即简化人类如何遵循人工智能决策中涉及的步骤和模型，以更好地理解其工作原理。理想情况下，这种可解释的人工智能让用户发现是什么导致了系统的最终答案，为什么它没有选择不同的答案，以及它在哪里成功或没有产生预期的结果。通过易于理解的图形、图表和可视化方式透明地访问这些信息，可以告知团队正在发生的事情，以及他们如何根据需要进行调整。

> 随着人工智能(AI)承担越来越复杂的决策，其背后的人类正在失去对其如何得出结论的了解。

团队也可以使用这些信息来影响和训练人工智能的决策。人工智能训练通常是一个复杂的过程，需要拥有数据科学高级学位的人类来管理它。但是，通过使信息和决策更加透明，复杂的训练过程可以简化为简单的 UX，任何人都可以通过几次点击来训练人工智能。它建立了对人工智能过程的信任，并为人类提供了对更复杂决策的真实可见性。

## 规则与规模斗争

IT 团队传统上依赖于基于规则的模板(例如 regex)，但是现代的复杂性现在已经使得人类无法遵守规则。规则看起来像是简单的解决方案，引用精确的值，甚至有时引用部分值(例如包含)，产生已知的输出。但是每个规则都有例外，这意味着构建更多的规则和正则表达式来解决它们。以至于 10 个规则可以有超过 300 万个例外和可能的组合。不太好。

管理这些规则的团队很快就陷入了创建、检查和修改每一个规则的无休止的过程中——更不用说他们经常不得不用他们想要首先使用的确切引用来“标记”数据。人类最终解决错误和问题，而不是真正的创新。曾经简单而廉价的过程变成了消耗团队时间和注意力的泥沼。

我们一次又一次地看到这种应用于人工智能操作的有缺陷的规则方法崩溃；因此，我们发明了 AIOps，它涉及将 AI 应用于 IT 开发和运营(DevOps)，以管理当今 IT 系统的复杂性，并帮助确保客户体验。这为 AI 接管提供了机会，但在某种程度上，人类也可以管理。团队不会被规则埋没，他们可以使用 AIOps 来决定将最有经验的团队成员的工作集中在哪里。将其应用到可观察性数据，即系统收集的度量、跟踪和日志事件的河流，您可以产生真正的智能可观察性，通过上下文创建可操作性。用户可以在几分钟内简化堆积如山的数据，并轻松发现和解决问题，从而节省总体时间和资源。

## 通过透明、可训练的人工智能建立信任

一场运动正在进行中，为人类配备工具，从日益增加的复杂性中抽象出清晰的理解，并通过简单的 UI 和功能来解释和训练 AI 的决策。透明的人工智能有助于用户更快地解决问题，做出更明智的决策，并信任他们的人工智能系统，因此供应商有责任将这些工具作为他们提供的体验的一部分。一个真正简单的过程增加了用户对人工智能的信任，并使它可以被没有数据科学和数学学位的人训练。

智能可观察性解决方案有助于实现这一目标。例如，这些解决方案可以部署简单的可视化技术，在图上绘制关系、相似性和推论，以清楚地突出人工智能的决策。再加上简单的训练“是/否”按钮，用户可以与数据进行交互，并在训练系统进行改进的同时，有意义地得出关于人工智能如何得出结论的见解。容易绘制的数据和简单的训练选项有助于人类从他们正在训练和利用的人工智能中获得更多价值。它为您的团队开启了持续学习的机会，并在此过程中改进了系统的功能。

有了可解释和可训练的人工智能，人类花一小部分时间做一小部分工作，以获得更好的理解。结果是更信任人工智能，更高的生产力和更好的体验。提供智能可观察性的工具可以在几分钟内产生有用的结果，同时使人工智能对您的团队和业务更加透明和简单。

通过 Pixabay 的特征图像。

<svg xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 0 68 31" version="1.1"><title>Group</title> <desc>Created with Sketch.</desc></svg>