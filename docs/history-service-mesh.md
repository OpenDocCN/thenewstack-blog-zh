# 服务网格的历史

> 原文：<https://thenewstack.io/history-service-mesh/>

[](https://buoyant.io/)

 [威廉·摩根，buppy 的首席执行官兼联合创始人

威廉是 buppy 的联合创始人兼首席执行官，是开源服务网格项目 Conduit 和 Linkerd 的创始人。在 Ruby 之前，他是 Twitter 的基础设施工程师，在那里他帮助 Twitter 从一个失败的单片 Ruby on Rails 应用程序转移到一个高度分布式的容错微服务架构。他是 Powerset、微软和 Adap.tv 的软件工程师，MITRE 的研究科学家，拥有斯坦福大学计算机科学硕士学位。](https://buoyant.io/) [](https://buoyant.io/)

对于大多数人来说，服务网格的概念仍然是一个相当新的概念，所以谈论它的历史似乎有点滑稽。但在这一点上，Linkerd 已经在世界各地的公司中运行了超过 18 个月，这在云原生生态系统中是永恒的，我们可以将它的概念谱系追溯到 2010 年初网络规模公司的发展。因此，肯定有一段历史需要探索和了解。

不过，在我们开始之前，让我们在当下多呆一会儿。什么是服务网格，为什么它突然成为一个热门话题？

服务网格是一个软件基础设施层，用于控制和监控微服务应用中的内部服务到服务流量。它通常采用与应用程序代码一起部署的网络代理的“数据平面”和用于与这些代理交互的“控制平面”的形式。在这种模式中，开发者(“服务所有者”)幸福地意识不到服务网格的存在，而运营商(“平台工程师”)获得了一套新的工具来确保可靠性、安全性和可见性。

那么[服务网格和 Kubernetes](https://thenewstack.io/why-do-you-need-istio-when-you-already-have-kubernetes/) 呢？这怎么突然这么有意思了？简而言之，对于许多公司来说，像 Docker 和 Kubernetes 这样的工具已经“解决了部署”——至少在第一个近似值上。但是他们还没有解决运行时间。这就是服务网格的用武之地。

“解决部署”是什么意思？使用 Docker 和 Kubernetes 之类的工具极大地减轻了部署的运营负担。有了这些工具，部署 100 个应用或服务不再是部署单个应用的 100 倍。这是一个巨大的进步，对于许多公司来说，它可以大幅降低采用微服务的成本。这之所以成为可能，不仅仅是因为 Docker 和 Kubernetes 在所有正确的层次上提供了强大的抽象，还因为它们在整个组织中标准化了打包和部署的模式。

但是一旦应用程序开始运行，接下来会发生什么呢？毕竟，部署不是生产的最后一步；应用程序仍然需要运行。因此，问题变成了:我们能否像 Docker 和 Kubernetes 标准化部署时操作那样标准化应用程序的运行时操作？

为了回答这个问题，我们转向服务网格。在其核心，服务网格提供了统一的全球方法来控制和测量应用程序或服务之间的所有请求流量(用数据中心的说法，即“东西”流量)。对于采用微服务的公司来说，这种请求流量在运行时行为中起着至关重要的作用。因为服务通过响应传入请求和发出传出请求来工作，所以请求流成为应用程序在运行时行为的关键决定因素。因此，标准化这种流量的管理成为标准化应用程序运行时的工具。

通过提供 API 来分析和操作这种流量，服务网格为整个组织的运行时操作提供了一种标准化的机制，包括确保可靠性、安全性和可见性的方法。和任何好的基础设施层一样，服务网格(理想情况下！)的工作与服务的构建方式无关。

## 服务网状是如何形成的？

那么服务网格是从哪里来的呢？通过做一些软件考古，我们发现服务网格提供的核心特性——如请求级负载平衡、电路中断、重试、工具——从根本上说并不是新特性。相反，服务网格最终是功能的重新打包；地点的转变，而不是内容的转变。

服务网格的起源始于大约 2010 年应用程序架构的三层模型的兴起，这是一个简单的架构，曾经为 web 上的绝大多数应用程序提供了动力。在这个模型中，请求流量起了作用(有两跳！)，但本质上是很专业的。应用程序流量首先由“web 层”处理，web 层又与“应用程序层”通信，应用程序层又与“数据库层”通信。web 层中的 web 服务器被设计为非常快速地处理大量的传入请求，将它们小心地移交给相对较慢的应用服务器。(Apache、NGINX 和其他流行的 web 服务器都有非常复杂的逻辑来处理这种情况。)同样，应用程序层使用数据库库与后备存储进行通信。这些库通常处理缓存、负载平衡、路由、流量控制等。，以一种针对此使用情形而优化的方式。

到目前为止还不错，但这种模式在高负载下开始崩溃——特别是在应用程序层，随着时间的推移，它可能会变得非常大。早期的网络规模公司——谷歌、脸书、网飞、推特——学会了将整体分割成许多独立运行的部分，催生了微服务的兴起。引入微服务的同时，也引入了东西向流量。在这个世界上，通信不再是专门化的，而是在每个军种之间。出了问题，网站就瘫痪了。

这些公司都以类似的方式回应——他们编写“胖客户端”库来处理请求流量。这些库——谷歌的 Stubby、网飞的 Hysterix、Twitter 的 Finagle 为所有服务提供了统一的运行时操作方式。开发人员或服务所有者将使用这些库向其他服务发出请求，在幕后，这些库将执行负载平衡、路由、电路中断和遥测。通过为应用程序中的每个服务提供统一的行为、可见性和控制点，这些库形成了表面上的第一个服务网格——没有花哨的名称。

## 代理人的崛起

快进到现代的云原生世界。当然，这些库仍然存在。但是，考虑到进程外代理提供的操作便利性，库的吸引力要小得多——特别是当与容器和编排器的出现使部署复杂性的大幅下降相结合时。

代理避开了图书馆的许多缺点。例如，当一个库发生变化时，这些变化必须跨每个服务进行部署，这个过程通常需要复杂的组织舞蹈。相比之下，代理可以升级，而无需重新编译和重新部署每个应用程序。同样，代理允许多语言系统，在这种系统中，应用程序由用不同语言编写的服务组成——这种方法对于图书馆来说过于昂贵。

对于大型组织来说，也许最重要的是，在代理而不是库中实现服务网格将为运行时操作提供必要功能的责任从服务所有者的手中转移到了该功能的最终消费者——平台工程团队的手中。提供者和消费者的这种联合允许这些团队拥有他们自己的命运，并分离开发和运营之间的复杂依赖。

这些因素都促成了服务网格的兴起，作为一种为运行时操作带来健全性的手段。通过部署可作为底层基础设施而非应用程序本身的一部分进行维护的分布式代理“网格”,并通过提供集中式 API 来分析和操作此流量，服务网格为整个组织的运行时操作提供了标准化机制，包括确保可靠性、安全性和可见性的方法。

### 回到未来

那么，服务网格的下一步是什么？至此，在花了 18 个多月的时间帮助组织采用 Linkerd 之后，我们已经了解了很多关于在运行任务关键型云原生应用程序时什么是对的，什么是错的。在下一篇文章中，我将探索几个具体的例子，并描述是什么导致了专门为 Kubernetes 设计的全新服务网格项目的开发: *Conduit* 。

<svg xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 0 68 31" version="1.1"><title>Group</title> <desc>Created with Sketch.</desc></svg>