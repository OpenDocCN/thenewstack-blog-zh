# 控制容器管理的野火

> 原文：<https://thenewstack.io/controlling-the-wildfire-of-container-management/>

[](https://turbonomic.com/)

[Eva TUC zai](https://turbonomic.com/)

[Eva 在 IT 服务管理方面拥有超过 15 年的经验，在移动应用战略方面横跨应用性能管理、虚拟化优化和企业级持续质量。作为 Turbonomic 高级工程团队的一员，她致力于采用以客户为中心的解决方案来解决影响各地业务的问题。](https://turbonomic.com/)

[](https://turbonomic.com/)[](https://turbonomic.com/)

部署容器的学习曲线很陡。大多数组织在进入生产之前只是刚刚开始试验。容器为组织的基础设施(内部或云中)带来的性能、成本和可伸缩性优势是不可否认的，这可能是为什么 Gartner 的聪明人预测，到 2020 年，超过 50%的全球组织将在生产中运行容器化的应用程序，而今天只有不到 20%。

并做好准备，因为一旦一个组织发现在哪里以及如何最好地部署容器，采用的速度将比从物理到虚拟的转变要快得多。集装箱很容易像野火一样蔓延，因为它们可以在几分钟内突然出现，几乎可以立即为客户服务。这对于敏捷性和弹性来说是极好的，但是这种即时的满足感将会带来挑战——尤其是当涉及到云中的成本超支时。

这一切的主角是 Kubernetes。“Kubernetes，这是我的应用程序—现在为我运行它。”这是谷歌的凯尔西·海塔尔(Kelsey Hightower)倡导的终结游戏。有了 Kubernetes，您可以拥有跨越一个或多个公共云和本地的遗留应用程序、微服务或功能。听起来很简单，对吗？

没那么快！对于最初的几个应用程序来说，这可能足够简单。然而，随着采用的增加，管理许多服务的复杂性也在增加，每个服务都有波动的需求。对复杂性有远见并理解部署容器的所有层面是至关重要的，这样一旦火花击中您的组织，您就可以做好控制野火的准备。

为了确保您的服务运行良好，并且平台能够应对部署的快速增长，管理服务级别目标(SLO)的多个维度是必不可少的。这引发了多个问题。

*   工作负载可以扩展，但是如何在 CPU、Mem 或事务(响应时间、吞吐量)的所有关键维度上优化扩展呢？
*   何时以及应该水平或垂直扩展？
*   如果你在一个维度上进行扩展，你会在另一个维度上冒拥塞的风险吗？
*   服务可能依赖于其他服务、数据或与客户端的距离，那么它们应该在哪里运行——更靠近客户端还是更靠近数据？
*   虽然该平台提供了灵活性，但您应该横向扩展您的本地集群还是突然转向云，您如何确定何时可以节省资金？

这些都是重要的问题。所以，让我们探索一下选择。

## 选项 1:自动扩展工作负载

容器编排平台提供了自动伸缩策略。然而，一个挑战是您需要决定指标(CPU 和内存是默认的)并分别设置静态阈值。这种类型的分析需要用户确定阈值，然后手动维护它并分析趋势，以评估阈值是否仍然足够好。这些策略不能水平扩展，也不能假设容器是资源的最佳配置。考虑到甚至一个容器可能在一个维度上受到约束(比如内存)，但在另一个维度上过度分配(比如 CPU)。水平扩展，没有首先调整大小，意味着您正在传播一个不保证性能的配置。首先，最好的行动可能是调整容器的大小，而不是仅仅依靠水平缩放。任何扩展操作都需要评估节点资源的可用性，如果没有节点资源可用，那么系统应该提供更多资源。

仅仅管理资源是不够的。您可以添加关于事务和响应时间的定制指标，但是首先，您需要添加一个解决方案来生成遥测数据(比如一个服务网格)，然后配置 Prometheus 来收集它。但同样，你正在设法达到一个近视的阈值，而这个阈值不是动态保持的。自我管理系统应该持续关注工作负载需求，在没有人工干预的情况下，确定是否需要垂直或水平扩展，同时确保您可以适应峰值需求。这需要多方面的分析。

即使在工作负载扩展之前，系统也应该确定如何更好地管理波动的工作负载需求，以避免由于嘈杂的邻居或节点性能问题而导致的资源拥塞，无论这些问题是来自一起达到峰值的容器还是底层群集中的计算或存储拥塞。为了确保工作负载能够正确访问可用的资源，通过重新调度 pod 来重新分配工作负载意味着 pod 可以利用其他兼容节点上的可用资源。

您希望高效利用资源，更好地重新分配工作负载应该以效率为目标，以释放更大的资源“块”,减少陷入挂起状态的单元，而不会给性能带来风险。那么，您如何知道移动哪个单元和节点，同时确保不会给另一个单元带来风险呢？这是多维分析优化重新调度和扩展决策的地方，并使它们具有可操作性，这要归功于第三方调度程序与本机调度程序进行交互来执行移动。

## 选项 2:自动扩展基础架构

在开始采用容器时，通常会过度供应。但是，如果您继续以 40%到 60%的利用率运行，这会导致资金浪费，因为您没有更好的方法来评估工作负载扩展的影响。另一方面，您希望自动扩展集群，这应该基于您的需求、环境中看到的增长以及对处于待定状态的 pod 的了解。智能扩展需要根据底层基础架构的可用性来评估需求，如果在公共云中，还需要根据成本来评估需求。一旦您有办法知道额外的节点何时应该向外扩展或向内扩展，那么您就需要考虑如何执行该操作。公共云提供了规模集/规模组，但阈值只关注节点。

拥有一种一致的方式来扩展 Kubernetes 节点将允许多维分析和一致的执行。我在[turbometric](https://turbonomic.com/)的团队正在密切关注 [SIGs 集群 API](https://github.com/kubernetes-sigs/cluster-api) (使用机器组显示了前景)[集群注册表](https://github.com/kubernetes/cluster-registry)和[多集群](https://github.com/kubernetes/community/tree/master/sig-multicluster)的突破，这将使这成为可能。

## 选项 3:多云

虽然您可能还没有实现，但容器化的 Kubernetes 工作负载提供了真正的可移植性，可以在任何地方运行，允许组织利用不同的基础架构提供商来优化成本和访问其他服务或功能。这要求应用服务、架构和正确的模式为多云做好准备。作为分析中的额外维度，多云为 DevOps 带来了位置和服务彼此邻近性方面的挑战。这回避了“下一步是什么？”

它看起来像是利用容器化服务和功能的复合服务，这将进一步推动基于服务级别目标管理性能和效率的需求。但是，那是另一天的话题。

通过 Pixabay 的特征图像。

<svg xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 0 68 31" version="1.1"><title>Group</title> <desc>Created with Sketch.</desc></svg>