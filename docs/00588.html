<html>
<head>
<title>New Algorithm Will Help Supercomputers Simulate Whole-Brain Neural Connections</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">新算法将帮助超级计算机模拟全脑神经连接</h1>
<blockquote>原文：<a href="https://thenewstack.io/new-algorithm-will-help-supercomputers-simulate-whole-brain-neural-connections/#0001-01-01">https://thenewstack.io/new-algorithm-will-help-supercomputers-simulate-whole-brain-neural-connections/#0001-01-01</a></blockquote><div><div id="tns-post-body-content">


<p class="translated">人工智能近年来取得了巨大的飞跃。我们正在看到这项技术被融入到<a href="https://thenewstack.io/deep-learning-algorithm-helps-driverless-cars-recognize-pedestrians-better/" target="_blank" class="local-link">自动驾驶汽车</a>、<a href="https://thenewstack.io/ai-algorithm-social-skills-cooperates-better-humans/" target="_blank" class="local-link">协作机器人</a>和<a href="https://thenewstack.io/new-google-ai-achieves-alien-superhuman-mastery-chess-shogi-go-mere-hours/" target="_blank" class="local-link">多价深度学习系统</a>中，这些系统可以自己掌握各种棋盘游戏，或者<a href="https://thenewstack.io/googles-deepmind-ai-now-capable-deep-neural-reasoning/" target="_blank" class="local-link">绕着地铁地图或家谱树推理</a>。然而，在人工智能从相对专业化过渡到能够像人类一样轻松地掌握各种任务之前，还有一些路要走。</p>
<p class="translated">开发这种<a href="https://en.wikipedia.org/wiki/Artificial_general_intelligence" target="_blank" class="ext-link" rel="external ">人工普通智能</a>的一个步骤是在计算机上模拟人脑的功能，以便为研究人员提供关于智能背后的内部工作的更深入的见解。问题是，人类大脑极其复杂，即使有今天可用的大型超级计算机的能力，也仍然不可能模拟其1000亿个神经元和数万亿个突触之间的所有交互。</p>
<p class="translated">但这一目标现在更近了一步，这要归功于一组国际研究人员，他们现在开发了一种算法，不仅可以加速现有超级计算机上的大脑模拟，还可以在未来的超级计算机(每秒钟能够执行十亿亿次计算的机器)上实现“全脑”模拟。</p>
<h2 class="translated">全脑模拟计算</h2>
<p class="translated">这项研究发表在<em> <a href="https://www.frontiersin.org/articles/10.3389/fninf.2018.00002/full?utm_source=G-BLO&amp;utm_medium=WEXT&amp;utm_campaign=ECO_FNINF_20180302_exascale-brain" target="_blank" rel="noopener external " class="ext-link">神经信息学前沿</a></em>上，概述了研究人员如何在超级计算机上创建神经元网络的新方法。为了说明这项任务有多艰巨，现有的超级计算机，如日本神户高级计算科学研究所的PETA scale K计算机只能复制10%大脑的活动。</p>
<p class="translated">这是因为它受到仿真模型设置方式的限制，这影响了超级计算机的节点如何相互通信。超级计算机可能有超过10万个这样的节点——每个节点都有自己的处理器来执行计算。在较大的模拟中，这些虚拟神经元分布在计算节点上，以有效地平衡处理工作负载，然而，这些较大模拟的挑战之一是神经元网络的高连通性，这需要大量的计算能力来复制。</p>
<p class="translated">“在神经元网络模拟发生之前，神经元及其连接需要被虚拟地创建，这意味着它们需要在节点的内存中被实例化，”论文的作者之一，<a href="https://www.kth.se/en" class="ext-link" rel="external "> KTH皇家理工学院的</a> Susanne Kunkel解释道。在模拟期间，神经元不知道它在哪个节点上有目标神经元，因此，它的短电脉冲需要被发送到所有节点。每个节点然后检查所有这些电脉冲中的哪些与该节点上存在的虚拟神经元相关。”</p>
<p class="translated">更简单地说，这就像给每个节点发送一个完整的干草堆，这样每个节点都需要从干草堆中找到与之相关的针。不用说，这个过程会消耗大量内存，尤其是当虚拟神经元网络的规模增长时。要扩大规模并使用当前技术模拟整个人类大脑，将需要比今天的超级计算机多100倍的处理内存。然而，新算法改变了游戏，因为它优化了这一过程，允许节点首先交换关于哪些节点将向谁发送和接收的信息，这样之后每个节点只需要发送和接收它需要的信息，而不必在整个干草堆中挑选。</p>
<p class="translated">“有了新技术，我们可以比以前更好地利用现代微处理器增加的并行性，这将在万亿次计算机中变得更加重要，”研究作者Jülich研究中心的Jakob Jordan说。</p>
<p class="translated"><img decoding="async" loading="lazy" class="aligncenter size-full wp-image-4709269" src="../Images/f40c422e0091e33a42063cbfe9f103f1.png" alt="" data-original-src="https://storage.googleapis.com/cdn.thenewstack.io/media/2018/05/88e861ec-post-petascale-brain-simulation-algorithm-exascale.jpg"/></p>
<p class="translated">通过改进的算法，研究小组发现，在尤利希的超级计算机JUQUEEN上运行的由5.2亿个神经元通过5.8万亿个突触连接的虚拟网络能够在5.2分钟的计算中模拟一秒钟的生物时间，而不是以前使用传统方法需要的28.5分钟。</p>
<p class="translated">据预测，未来能够进行亿亿次计算的机器的性能将超过当前超级计算机的10到100倍。有了这个团队的算法——它将作为一个开源工具提供——这将意味着探索智能如何整体运作的更大能力。</p>
<p class="translated">毫无疑问，基于这一工具的未来发现不仅将有助于推动人工智能的进一步发展，还将有利于一系列科学学科，研究报告作者、<a href="http://www.fz-juelich.de/inm/EN/Home/home_node.html" class="ext-link" rel="external "> Jülich神经科学和医学研究所所长</a>Markus Diesmann指出:“万亿级硬件和适当软件的结合带来了对大脑功能基本方面的研究，如可塑性和在几分钟生物时间内展开的学习，在我们的能力范围内。”</p>
<p class="attribution translated">图片:Pixabay，神经信息学前沿。</p>


<div class="tns-logo-slug">
<svg xmlns:xlink="http://www.w3.org/1999/xlink" viewbox="0 0 68 31" version="1.1">
<title>Group</title>
<desc>Created with Sketch.</desc>
<g id="Page-1" stroke="none" stroke-width="1" fill="none" fill-rule="evenodd">
<g id="Group">
<path d="M24.002,29.619 L29.77,29.619 L29.77,15.808 C29.77,15.038 29.622,11.265 29.59,10.414 L29.77,10.414 C31.424,14.019 31.473,14.147 32.168,15.322 L39.65,29.618 L44.845,29.618 L44.845,0 L39.075,0 L39.075,11.064 C39.075,12.197 39.075,12.44 39.182,14.472 L39.325,17.468 L39.151,17.468 C39.034,17.267 38.596,16.173 38.467,15.929 C38.164,15.323 37.725,14.512 37.373,13.905 L30.031,0 L24,0 L24,29.619 L24.002,29.619 Z" id="Path-Copy" fill="#FF3287"/>
<path d="M56.948,0 C50.745,0 47.606,3.43 47.606,8.296 C47.606,14.114 51.036,15.404 55.518,17.132 C60.438,18.853 61.782,19.332 61.782,21.539 C61.782,24.225 58.969,24.867 57.401,24.867 C54.579,24.867 52.493,23.342 51.536,20.858 L47,24.185 C49.43,28.937 52.145,30.185 57.713,30.185 C59.364,30.185 62.059,29.74 63.727,28.694 C67.779,26.156 67.779,22.22 67.779,20.898 C67.779,18.129 66.531,16.207 66.178,15.726 C65.049,14.121 63.032,12.918 61.25,12.278 L57.084,10.914 C55.073,10.267 52.928,10.105 52.928,8.019 C52.928,7.707 53.008,5.528 56.288,5.319 L61.465,5.319 L61.465,0 C61.465,0 57.342,0 56.948,0 Z" id="Path-Copy-2" fill="#00AFF4"/>
<polygon id="Path" fill="#00AFF4" points="5.32907052e-15 1.77635684e-15 5.32907052e-15 5.319 7.572 5.319 7.572 29.564 14.132 29.564 14.132 5.319 21.544 5.319 21.544 1.77635684e-15"/>
</g>
</g>
</svg> </div>
</div>
</div>    
</body>
</html>