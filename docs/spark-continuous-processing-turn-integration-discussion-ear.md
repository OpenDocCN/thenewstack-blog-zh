# Spark 2.3 为大数据世界带来了“持续处理”

> 原文：<https://thenewstack.io/spark-continuous-processing-turn-integration-discussion-ear/>

对于一个开源项目，很难保守秘密。编号为 2.3 的最近发布的 [Apache Spark](https://spark.apache.org/) ，将开始数据处理引擎的实验性内置支持，以在 [Kubernetes](/category/kubernetes/) 开源容器编排引擎上部署服务，正式将其自身与数据中心的最大潮流挂钩。

但是正在进行的 Spark 所谓的结构化流 API 的下一阶段将包括被描述为低延迟*连续处理*模式。Spark 的联合创建者 Matei Zaharia 在谈到新的堆栈时表示，加上对流上的 [SQL 和数据帧](https://spark.apache.org/docs/latest/sql-programming-guide.html)的更多支持，新模式有可能使长期存在的批处理过程无需修改即可作为流过程运行。

“传统上，Spark 只关注高吞吐量，”Zaharia 说，“延迟为半秒到一秒。但是现在，如果你愿意损失一点点吞吐量，你也可以获得相同代码的超低延迟、毫秒级执行。因此您可以使用这些设置部署相同的应用程序。”

## 一批要有多小？

回到 2016 年，Spark 有一个相当快的批处理引擎，至少与它已经取代的 Hadoop 引擎相比，如 MapReduce。事实上，它已经开始实施扎哈里称之为*的[结构化流媒体](https://thenewstack.io/spark-2-0-will-offer-interactive-querying-live-data/)* 。起初，它被解释为一种从 Spark API 中删除“微批处理”概念的方法，这种方法试图通过将批处理缩减得非常小来使批处理变得非常快，而实际上并不改变 API 调用本身。

随着“Spark”和“流媒体”在开发人员的讨论中自动配对，Spark 需要一种方法来真正实现流媒体。它的竞争对手，甚至在 Apache 领域，[已经开始击败 Spark](https://www.infoworld.com/article/3101729/big-data/big-data-brawlers-4-challengers-to-spark.html) 。 [Apex](https://apex.apache.org/) (由 DataTorrent 捐赠给 Apache 基金会)和 [Flink](https://flink.apache.org/) 的支持者暗示，Spark 的结构流实际上是一种微批处理的面具——一种让小块数据看起来像流的方法，如果它们通过得足够快。

去年 5 月， [Databricks](https://databricks.com/) 软件工程师[迈克尔·阿姆布鲁斯特](https://www.linkedin.com/in/michaelarmbrust/)在与扎哈里亚和其他两名工程师的一次谈话中受到启发，开始努力为 Spark 开发一种替代处理引擎。我想到的一个用例是针对[卡夫卡](https://kafka.apache.org/)消息的完全流水线式读/写流。你会记得，斯帕克和卡夫卡构成了新兴的“SMACK Stack”的书挡。如果依靠 Kafka 按照流处理发送消息，100 毫秒的延迟也可以是 100 分钟。

如果你曾经从上坡的花园水管中吸过水，你就会熟悉公共工程工程师所认为的“管道工程”，而不是詹金斯工程师。通过管道或软管的流体流动产生吸力，吸引更多的流体来填充真空。这就是 Spark 的工程师们努力追求的流水线类型:自动进料。否则，按照目前的情况，每个微型批次都必须单独推出。因此，处理这些微批次“流”所消耗的时间永远不会比上市时间更快。

“我们知道流媒体系统存在于现实世界中，”阿姆布鲁斯特去年 6 月在 2017 年 Spark 峰会上告诉与会者，“这很混乱。数据到达晚，无序。所以我们想让事件时间成为 API 和引擎的一部分。”

与 Databricks 之前称之为“数据流”的方法相反，真正的数据流对于[机器学习](/category/machine-learning/)应用至关重要，在这种应用中，查询数据的行为必须与识别返回流中错误数据的能力同时运行。如果您可以想象两组进程都受到延迟的限制，那么您就可以想象每个进程在等待另一个进程完成时累积的延迟会比其中任何一个进程自己产生的延迟都要大。

“这意味着，我们已经从 Spark 流中消除了微批处理，”阿姆布鲁斯特解释道，他也是 Databricks 的工程师，负责 Spark 的结构化数据查询语言 [Spark SQL](https://spark.apache.org/sql/) 。"它支持异步检查点，对于某些应用程序，延迟低至亚毫秒级."

## 再构造

从 1.6 版本开始，Spark SQL 的集成需要引入一个集合类型，称为 **DataFrame** 。对于 SQL 来说，这是一种像常规关系表一样组装查询结果的方式，但对于 Spark 来说，要维护关联，它需要超越简单的关系关联。来自 Hadoop 的 Hive 表可以重建为 Spark **数据帧**。

对于 Databricks 来说，要实现其结构化流的目标，它需要将流中携带的结果组合起来，这样它们仍然可以作为 **DataFrame** 对象来处理。

Zaharia 在与我们的讨论中解释道:“您可以使用 DataFrame API 作为编写[*查询*]的编程方式之一，这是许多用户非常熟悉的，尤其是 Python 用户。”。或者您可以使用 SQL 编写一个查询。我们在这个新的流项目中所做的就是说，您作为批处理查询编写的任何应用程序，我们都可以将其增量化，并作为流查询运行。”

这样，一个旧的查询可以突然有一个全新的用途，而无需对代码进行任何转换。根据零售商的客户活动生成的事件报告，如 Zaharia 给我们的一个例子，每晚运行一次，并在第二天早上发送给营销人员，可以立即成为一个仪表板查询，近乎实时地提供客户事件。

“如果你知道如何做批量应用程序，”Zaharia 说，“你只要用同样的方式写，它就会不断地为你学习。您将获得与批处理查询相同的结果，但是它会随着新数据的到来而不断更新。”

## 遗产已经

尽管最初是 Hadoop 将组织从其旧数据仓库的 20 世纪陷阱中解放出来，但许多人后来发现，他们用一个陷阱换了另一个陷阱。虽然它可以并行运行操作系统以前从未做过的进程，并且它可以在客户端/服务器时代不可能的规模上访问卷，但 Hadoop 只是一个中等效率的批处理系统。与现代服务器处理器设定的节奏相比，Hadoop 的原始设备实际上慢得惊人。

因此，组织已经开始投资集成工具，将 Hadoop 的批处理(已经被称为“遗留数据”)与流数据引擎联系起来。例如，一家名为 [Syncsort](http://www.syncsort.com/en/Home) 的公司生产了一个名为 [DMX-h](https://www.syncsort.com/en/Products/BigData/DMXh) 的集成包，最初是作为大型机和 Hadoop 集群之间的桥梁。这个想法是利用一个 GUI，数据工程师可以通过它有效地绘制大型机数据的模式。然后，解释器将该绘图重新设想为对 Syncsort 的 integrator 的一组 API 调用，然后 integrator 向 Hadoop 提供后续查询。后来，DMX-h 扩展到包括火花。

不久，DMX-h 被[解释为一个大数据引擎和另一个](https://www.slideshare.net/Syncsort/use-cases-from-batch-to-streaming-mapreduce-to-spark-mainframe-to-cloud-todays-etl-does-it-all)之间的集成器，Hadoop 和 Spark 都被描述为“框架”，或许借用了一点 Apache Mesos 的词汇。

Syncsort 白皮书让你了解其工程师的目标:“智能执行使组织能够在不同的底层计算环境(如 Hadoop v1、Hadoop v2 或 Apache Spark)上执行用 DMX-h GUI 创建的相同数据管道，而无需进行任何更改，”它写道。“然后，这些作业可以部署在本地或云中。随着其他框架在 Hadoop 社区中的采用，它们将逐渐得到支持。”

但是，如果您的想象中仍然有两个受延迟限制的操作相互依赖的画面，请增加该数字，并考虑接下来可能会发生什么。

2015 年，由苏黎世大学研究人员 [Daniele Dell'Aglio](http://www.dellaglio.org/) 领导的一个团队在一篇论文中预见了这个问题，这篇论文表面上是关于使用通用词汇来生产集成系统。该论文发表在名为 *[普及系统中的数据管理](https://dl.acm.org/citation.cfm?id=2845108)* 的一卷中。

戴尔阿格里奥和他的同事写道，在组织内部，集成系统往往由可能使用它们的个人编写(或者绘制)。这些集成商的产品通常是孤立的数据，被定制来满足集成商自己的独特需求。“不同的商业和法律要求将影响他们各自的数据表示，”该小组写道。“例如，社交网络不太可能记录用户在网站上询问的信息，而基于二维码的系统不太可能记录用户与朋友分享的印象。”

集成商创造了这些数据副产品，除了满足他们各自的查询需求之外，几乎没有或根本没有任何用途，这不是他们自己的错。该团队建议的解决方案是一种通用的概念模型，支持广泛的词汇表来处理来自流的数据，而不需要集成器。

Databricks 对这个问题的解决方案远没有那么哲学，它更符合数据科学家和数据库开发人员已经在 SQL 上实现标准化的事实。现有的语言已经足够了，为什么还要开发一种全新的语言呢？既然 SQL 本质上构建了操作的结果，那么引擎如何获取这些结果对查询语言来说又有什么关系呢？将 microbatch 引擎与流引擎交换不应该影响 SQL 的措辞，或者任何基于 SQL 构建的 API 的措辞。

“在大多数流媒体系统中，你需要学习一个完全不同的编程接口来理解如何以流媒体的方式做事情，”Matei Zaharia 告诉我们。“我如何跟踪状态？如果只有几个事件到达，我如何让事情增量更新？在这里，如果您首先知道如何编写查询，引擎会自动为您完成所有这些工作。”

Bandwagonman 在知识共享 3.0 下发布的 Atta colombica 种切叶蚁的特征图像。

<svg xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 0 68 31" version="1.1"><title>Group</title> <desc>Created with Sketch.</desc></svg>