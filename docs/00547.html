<html>
<head>
<title>Nvidia Embraces Kubernetes for Scalable Deep Learning</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">英伟达采用Kubernetes进行可扩展的深度学习</h1>
<blockquote>原文：<a href="https://thenewstack.io/nvidia-embraces-kubernetes-for-scalable-deep-learning/#0001-01-01">https://thenewstack.io/nvidia-embraces-kubernetes-for-scalable-deep-learning/#0001-01-01</a></blockquote><div><div id="tns-post-body-content">


<p class="translated">GPU制造商<a href="http://www.nvidia.com/page/home.html" class="ext-link" rel="external "> Nvidia </a>已经将开源的Kubernetes容器编排引擎置于其将机器学习引入企业的战略中心。</p>
<p class="translated">在舞台上，Nvidia的<a href="https://www.nvidia.com/en-us/gtc/" class="ext-link" rel="external "> GPU技术会议</a>，本周在加州圣何塞举行。<a href="https://nvidianews.nvidia.com/bios/jensen-huang" class="ext-link" rel="external ">英伟达首席执行官/创始人黄仁勋</a>鼓吹一套新的优化方法来及时执行大型机器学习作业——例如最新版本的<a href="https://developer.nvidia.com/tensorrt" class="ext-link" rel="external "> TensorRT </a>库——这将使ML作业加速100倍。他还推出了"<a href="https://twitter.com/thenewstack/status/978683446242435072" class="ext-link" rel="external ">世界上最大的CPU </a>，它能够执行通常需要六天才能完成的神经网络工作<a href="https://twitter.com/thenewstack/status/978684582999420928" class="ext-link" rel="external ">只需18分钟</a>。但是，在大规模运营中，一个组织如何管理和充分利用所有这些跨越云和数据中心的快速技术呢？</p>
<p class="translated">“事实证明，有一种叫做Kubernetes的东西，”黄说。“Nvidia GPUs上的Kubernetes将带来如此多的欢乐。太开心了。”</p>
<p class="translated">黄指出，这种兴奋的原因是Kubernetes最近对GPU的支持，随着1.8版本的发布引入了测试版。黄说，对于全球最大的GPU制造商Nvidia来说，Kubernetes现在是“GPU感知型”的，这是一个好消息。</p>
<p class="translated">在一次演示中，黄展示了Kubernetes如何扩大工作负载。他从该公司的标准演示开始，演示如何使用单个GPU扫描一组包含花朵的照片，并几乎立即识别出它们是什么类型的花。为了增加工作量，黄的工程师叫来了Kubernetes，为这个基本程序增加了四个副本，这样一来，屏幕上能识别的花的数量立刻增加了许多倍。</p>
<p class="translated"><iframe loading="lazy" title="NVIDIA Press Event at CES 2018 with NVIDIA CEO Jensen Huang" src="https://www.youtube.com/embed/P3BjB5-Y4JM?start=1421&amp;feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="">视频</iframe></p>
<p class="translated">“Kubernetes可以在一个GPU上、一台服务器上的多个GPU上、多台服务器上的多个GPU上分配pod，这是一种基本的服务，可以容纳大量容器。您还可以跨数据中心分配它。所以你可以把一部分放在云中，一部分放在数据中心，”黄告诉听众。“所有这些事情都是在完全看不见的情况下发生的，因为我们让Kubernetes能够感知GPU。”</p>
<p class="translated">演示还展示了Kubernetes提供的弹性。黄的工程师杀死了四个GPU，以展示Kubernetes如何自动找到四个替换单元，尽管K8s在这个演示中找到替换单元的速度如此之快，观众甚至没有注意到所有照片识别的速度变慢。</p>

<p/>
<h2 class="translated">在幕后</h2>
<p class="translated">据该公司称，从4月份开始，任何Kubernetes托管服务都可以提供GPU即服务。该公司特别吹捧亚马逊网络服务和谷歌云平台，但不包括仍在接受英伟达认证的微软Azure。</p>
<p class="translated">在幕后，Nvidia计划向Kubernetes项目贡献GPU支持代码，该项目由<a href="https://www.cncf.io/" class="ext-link" rel="external ">云原生计算基金会管理。Nvidia加速计算软件总监<a href="https://www.linkedin.com/in/karibriski/" class="ext-link" rel="external ">卡莉·布里斯基</a>解释道:</a>该公司首先在内部开发技术，然后将其提供给上游社区的其他人采用。</p>
<p class="translated">容器支持背后的想法是Kubernetes将识别系统中的GPU，并能够为它们分配工作负载。Nvidia已经通过<a href="https://github.com/NVIDIA/nvidia-container-runtime" class="ext-link" rel="external "> Nvidia容器运行时</a>支持基于容器的操作，这是一个识别GPU的<a href="https://thenewstack.io/ready-docker-containers-runc-runtime-riddler/" class="local-link"> runc </a>的修改版本。</p>
<p class="translated">Kubernetes首先在1.7版本中开始实验性地支持GPU，尽管它需要手动安装pod规范中的卷，并且它不提供任何监控或健康检查。从Kubernetes版本1.8开始，用户可以通过使用Nvidia容器运行时，为Kubernetes使用alpha <a href="https://github.com/NVIDIA/k8s-device-plugin" class="ext-link" rel="external "> Nvidia插件，Nvidia GPU云计算软件总监Viraj Chavan </a>在一次技术会议上解释了更多关于Kubernetes的工作。这个插件在本周被升级为测试版。</p>
<p class="translated">Chavan说，该插件“将GPU作为一级资源暴露给栈顶的其他软件组件”。</p>
<p class="translated">Chavan说，现在该公司正在努力进一步完善这种支持。它希望看到适当的GPU运行状况检查和监控，以及对拓扑感知和不同类型GPU的支持，以便用户可以通过特定的GPU类型指定工作负载。愿望清单上的另一项是允许用户切换到不同的容器运行时间，比如<a href="https://thenewstack.io/cri-o-project-run-containers-without-docker-reaches-1-0/" class="local-link"> CRI-O </a>。</p>
<p class="translated">“我们希望增加这些功能，这样您就可以根据这些限制来安排您的工作。例如，你可以选择说‘我的应用需要这种GPU和这种内存’”，Chavan说。</p>
<p class="translated">尽管如此，现代企业在使用GPU进行生产规模的工作时，仍然面临着其他挑战。一个是将技术与持续集成和部署实践相协调。Nvidia应用工程解决方案经理<a href="https://github.com/mike-wendt" class="ext-link" rel="external "> Michael Wendt </a>在会议的另一场技术会议上指出，基于云的CI/CD系统，如<a href="https://travis-ci.org/" class="ext-link" rel="external "> Travis CI </a>和<a href="https://circleci.com/" class="ext-link" rel="external "> CircleCI </a>还不支持GPU。Wendt自己正在开发一个支持Docker容器运行时的Jenkins插件。他说，它适用于Docker Swarm，但还不支持Kubernetes。</p>
<p class="attribution translated">CircleCI和Cloud Native Computing Foundation是这个新堆栈的赞助商。</p>
<p class="attribution translated">专题图片:英伟达首席执行官黄仁勋，在GTC 2018的舞台上，演示用于机器学习工作的Kubernetes。</p>


<div class="tns-logo-slug">
<svg xmlns:xlink="http://www.w3.org/1999/xlink" viewbox="0 0 68 31" version="1.1">
<title>Group</title>
<desc>Created with Sketch.</desc>
<g id="Page-1" stroke="none" stroke-width="1" fill="none" fill-rule="evenodd">
<g id="Group">
<path d="M24.002,29.619 L29.77,29.619 L29.77,15.808 C29.77,15.038 29.622,11.265 29.59,10.414 L29.77,10.414 C31.424,14.019 31.473,14.147 32.168,15.322 L39.65,29.618 L44.845,29.618 L44.845,0 L39.075,0 L39.075,11.064 C39.075,12.197 39.075,12.44 39.182,14.472 L39.325,17.468 L39.151,17.468 C39.034,17.267 38.596,16.173 38.467,15.929 C38.164,15.323 37.725,14.512 37.373,13.905 L30.031,0 L24,0 L24,29.619 L24.002,29.619 Z" id="Path-Copy" fill="#FF3287"/>
<path d="M56.948,0 C50.745,0 47.606,3.43 47.606,8.296 C47.606,14.114 51.036,15.404 55.518,17.132 C60.438,18.853 61.782,19.332 61.782,21.539 C61.782,24.225 58.969,24.867 57.401,24.867 C54.579,24.867 52.493,23.342 51.536,20.858 L47,24.185 C49.43,28.937 52.145,30.185 57.713,30.185 C59.364,30.185 62.059,29.74 63.727,28.694 C67.779,26.156 67.779,22.22 67.779,20.898 C67.779,18.129 66.531,16.207 66.178,15.726 C65.049,14.121 63.032,12.918 61.25,12.278 L57.084,10.914 C55.073,10.267 52.928,10.105 52.928,8.019 C52.928,7.707 53.008,5.528 56.288,5.319 L61.465,5.319 L61.465,0 C61.465,0 57.342,0 56.948,0 Z" id="Path-Copy-2" fill="#00AFF4"/>
<polygon id="Path" fill="#00AFF4" points="5.32907052e-15 1.77635684e-15 5.32907052e-15 5.319 7.572 5.319 7.572 29.564 14.132 29.564 14.132 5.319 21.544 5.319 21.544 1.77635684e-15"/>
</g>
</g>
</svg> </div>

</div>
</div>    
</body>
</html>