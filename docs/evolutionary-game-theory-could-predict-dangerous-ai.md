# 进化博弈论可以预测危险的人工智能

> 原文：<https://thenewstack.io/evolutionary-game-theory-could-predict-dangerous-ai/>

没有一天不听说人工智能研究的一些令人着迷的发展，无论是能够以类似人类的方式处理和产生语言的人工智能，还是能够解开蛋白质内部秘密的人工智能，或者是自动做出科学发现的人工智能。

但是，在匆忙寻找下一个突破的过程中，人们有理由担心“人工智能竞赛”的竞争性质可能意味着安全和[伦理](https://thenewstack.io/google-grapples-with-ethical-ai/)等问题被无意中忽视，导致类似[算法偏差](https://thenewstack.io/hidden-gender-racial-biases-algorithms-can-big-deal/)或[竞争军事大国之间不断升级的人工智能军备竞赛](https://venturebeat.com/2021/04/19/the-ai-arms-race-has-us-on-the-road-to-armageddon/)等现象，以制造致命的自主武器。

所有这些最近的发展都表明，当涉及到工程和实施人工智能时，需要更好的监管。当然，过多的监管可能会扼杀创新，但过少的监管也可能带来本可以预防的灾难。正如来自[蒂塞德大学](https://www.tees.ac.uk/)、[新葡京大学](https://www.unl.pt/en)和[布鲁塞尔自由大学](https://www.ulb.be/en)的一个国际研究团队现在所建议的那样，人工智能也可以用来通过确定哪些类型的人工智能研究项目可能比其他项目需要更多的监管来导航这种微妙的平衡。

“不管真实与否，这种通过人工智能争夺领域霸权的信念可以简单地从其后果中使其成为现实，”该团队在发表在人工智能研究杂志的论文中写道。“这些后果可能是负面的，因为对技术优势的争夺创造了一个复杂的选择生态，可能会推动利益相关者低估甚至忽视道德和安全程序。”

## 运用进化博弈理论

为了找出哪些人工智能比赛应该优先进行监管监督，研究人员创建了一个人工智能模型，模拟了人工智能比赛的各种假设场景。由于团队的工作必须模拟所有潜在的复杂选择，当没有单一的、预先确定的路径时，团队的模型因此整合了从生物学和数学中收集的各种概念，如进化、[非线性动力学](https://en.wikipedia.org/wiki/Nonlinear_system)和博弈论。

“该模型本身是基于[进化博弈论](https://plato.stanford.edu/entries/game-evolutionary/)，该理论在过去被用于理解行为如何在社会、人、甚至我们的基因范围内进化，”该团队在[的一篇帖子](https://theconversation.com/ai-developers-often-ignore-safety-in-the-pursuit-of-a-breakthrough-so-how-do-we-regulate-them-without-blocking-progress-155825)中解释道。“该模型假设特定游戏中的赢家——在我们的例子中是人工智能竞赛——获得所有好处，正如生物学家认为在进化中发生的那样。通过在我们的模拟中引入法规——制裁不安全行为并奖励安全行为——我们可以观察到哪些法规成功地实现了利益最大化，而哪些法规最终扼杀了创新。”

该团队运行这些模拟数百次，修改这些实验中的变量，以便他们可以看到随着时间的推移会发生什么。该模型包括各种虚拟代理，在这些模拟的人工智能竞赛中充当竞争对手。每个虚拟代理都被随机分配了可能在现实世界中发生的行为，这意味着一些虚拟代理可能会更加谨慎和小心，而其他虚拟代理可能会倾向于承担更多风险，最终匆忙生产未经适当测试的人工智能产品，或者容易受到黑客攻击和数据泄露的影响。

特别是，研究人员发现，最重要的变量是“[人工智能]竞赛的长度”——换句话说，模拟竞赛达到生产功能性人工智能产品的目标所需的时间。

“当人工智能比赛迅速达到目标时，我们发现我们编码为总是忽略安全预防措施的参赛者总是获胜，”该团队说。“在这些快速的人工智能比赛中，竞争优势是通过快速获得的，而那些停下来考虑安全和道德的人总是会失败。监管这些‘人工智能冲刺’是有意义的，这样它们得出的人工智能产品才是安全和符合道德的。”

相比之下，该研究小组的工作表明，较长期的人工智能计划——或“人工智能马拉松”——可能不需要太多的监管监督，因为这些项目往往优先考虑安全和道德问题。此外，该团队表示，监管“人工智能马拉松”实际上可能会扼杀创新，监管应该“聪明、灵活”，并根据项目类型量身定制，以防止不道德人工智能的出现，同时鼓励有益人工智能的发展。

“鉴于这些发现，监管机构确定不同的人工智能竞赛可能持续多长时间将是重要的，并根据它们的预期时间表应用不同的法规，”该团队说。“我们的发现表明，适用于所有人工智能比赛的一个规则——从短跑到马拉松——将导致一些远非理想的结果。但这种监管可能是紧迫的:我们的模拟表明，那些即将结束的人工智能竞赛将是最需要监管的。”

<svg xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 0 68 31" version="1.1"><title>Group</title> <desc>Created with Sketch.</desc></svg>